{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smd7hIM_zcLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3531582-3c93-44e4-ad98-1282534fc554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nnsplit'...\n",
            "warning: redirecting to https://github.com/bminixhofer/nnsplit.git/\n",
            "remote: Enumerating objects: 2873, done.\u001b[K\n",
            "remote: Counting objects: 100% (719/719), done.\u001b[K\n",
            "remote: Compressing objects: 100% (302/302), done.\u001b[K\n",
            "remote: Total 2873 (delta 403), reused 706 (delta 392), pack-reused 2154\u001b[K\n",
            "Receiving objects: 100% (2873/2873), 89.36 MiB | 37.66 MiB/s, done.\n",
            "Resolving deltas: 100% (1540/1540), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://www.github.com/bminixhofer/nnsplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uabNv05OneLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7464333f-8846-475a-d643-b68cb2e8a743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 08:08:57--  https://www.dropbox.com/s/cnrhd11zdtc1pic/enwiki-20181001-corpus.xml.bz2?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/cnrhd11zdtc1pic/enwiki-20181001-corpus.xml.bz2 [following]\n",
            "--2022-06-27 08:08:57--  https://www.dropbox.com/s/dl/cnrhd11zdtc1pic/enwiki-20181001-corpus.xml.bz2\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6307bfd9e590ea9c5911e04d3a.dl.dropboxusercontent.com/cd/0/get/Bn_YBJmWbo5tMidOUKoEYcEvo5NdcOQNXVXzsrZ_rowWPVPBRMPIuXYAo8lvEqQ_9T0ZypPC6eoN4AA2AVHYqDPLU8hPfXnuvJMVpIjlM7SR2LGEIfVPhr82D9NhYEjyFTVekQfZO63poN6pFgxKKTiEOZd128pBYLyxg84SYbZgbQ/file?dl=1# [following]\n",
            "--2022-06-27 08:08:57--  https://uc6307bfd9e590ea9c5911e04d3a.dl.dropboxusercontent.com/cd/0/get/Bn_YBJmWbo5tMidOUKoEYcEvo5NdcOQNXVXzsrZ_rowWPVPBRMPIuXYAo8lvEqQ_9T0ZypPC6eoN4AA2AVHYqDPLU8hPfXnuvJMVpIjlM7SR2LGEIfVPhr82D9NhYEjyFTVekQfZO63poN6pFgxKKTiEOZd128pBYLyxg84SYbZgbQ/file?dl=1\n",
            "Resolving uc6307bfd9e590ea9c5911e04d3a.dl.dropboxusercontent.com (uc6307bfd9e590ea9c5911e04d3a.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc6307bfd9e590ea9c5911e04d3a.dl.dropboxusercontent.com (uc6307bfd9e590ea9c5911e04d3a.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5983744447 (5.6G) [application/binary]\n",
            "Saving to: ‘enwiki-20181001-corpus.xml.bz2?dl=1’\n",
            "\n",
            "enwiki-20181001-cor 100%[===================>]   5.57G  25.8MB/s    in 5m 17s  \n",
            "\n",
            "2022-06-27 08:14:16 (18.0 MB/s) - ‘enwiki-20181001-corpus.xml.bz2?dl=1’ saved [5983744447/5983744447]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/cnrhd11zdtc1pic/enwiki-20181001-corpus.xml.bz2?dl=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74lGj78HszTo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"nnsplit/train\")\n",
        "from text_data import MemoryMapDataset, xml_dump_iter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ4Cedjws7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "28583e35-4a15-4e8a-c464-7d5a7924f616"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-a468ae9c3955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                          \u001b[0mmin_text_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          max_text_length=5000)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ],
      "source": [
        "xml_iter = xml_dump_iter(\"data.xml\", \n",
        "                         min_text_length=10, \n",
        "                         max_text_length=5000)\n",
        "next(xml_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMazX62Pe66B"
      },
      "source": [
        "`MemoryMapDataset` is another convient built-in class, but not specific to the Wikipedia dump. It is a `torch.utils.data.Dataset` which can be created using a `texts.txt` and `slices.pkl` file. The `texts.txt` file is [memory-mapped](https://en.wikipedia.org/wiki/Memory-mapped_file) and `slices.pkl` contains a Python array with indices that determine at which position in the dataset which range of the text should be loaded. This allows accessing each text without ever loading all the data into memory.\n",
        "\n",
        "To create `texts.txt` and `slices.pkl` from an iterator over text, use `MemoryMapDataset.iterator_to_text_and_slices`.\n",
        "\n",
        "Note that this will be quite slow since iterating over the XML dump takes a significant amount of time, so I would recommend caching `texts.txt` and `slices.pkl` somewhere.\n",
        "\n",
        "`max_n_texts=10_000_000` is only needed in Colab to keep disk usage in check, feel free to remove this otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlRunloks4RU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "91738573d9d8429e975ec2124f071e63",
            "ebd82baee98b434fa5956bbb0e1e586b",
            "86e2242e118e494d910fed5a642d76ea",
            "20f649ce029d4bd0904b482c1bb21455",
            "3a34bb6a60f2444ca680c42064924497",
            "e11a9a46706e4279991d9c8b8ce486d6",
            "de11f652d7e74418aedfef88d61b269a",
            "0ff5c245c8774b779ab643dc963fc516",
            "6d305eaf63ea4461827be333723f3a8b",
            "7ff51286e3e24b5a9cf29b9c67227aa5",
            "13909ae0cd764729962756800e8b9859"
          ]
        },
        "outputId": "7cfab54e-a983-4eed-cbd8-fb59d7bab4b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91738573d9d8429e975ec2124f071e63"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "xml_iter = xml_dump_iter(\"data.xml\", \n",
        "                         min_text_length=10,\n",
        "                         max_text_length=5000)\n",
        "MemoryMapDataset.iterator_to_text_and_slices(xml_iter, \n",
        "                                             \"texts.txt\", \n",
        "                                             \"slices.pkl\",\n",
        "                                             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1BvQ894gvKJ"
      },
      "source": [
        "Here, I am saving the outputs to my Drive, you will have to adjust these paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQs7qQHHtXVH"
      },
      "outputs": [],
      "source": [
        "!cp -a slices.pkl \"/content/drive/My Drive/Projects/nnsplit/slices.pkl\"\n",
        "!cp -a texts.txt \"/content/drive/My Drive/Projects/nnsplit/texts.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1GBLTXPRpW4",
        "outputId": "80ef41b0-05f4-4b8d-c665-73a0692710f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZpLGc_kPlOq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh9UKxN4hFuw"
      },
      "source": [
        "Now we can get started with training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju0AhUATnvRx"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"nnsplit/train\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ll9Ej9R58e",
        "outputId": "6d872528-280d-44fe-e54f-2ebbfa8d0bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n",
            "  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-4qusdskv\n",
            "  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-4qusdskv\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (3.17.3)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (4.64.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (2.8.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.7.0.dev0) (21.3)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 48.0 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.7.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch-lightning==1.7.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (1.46.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (3.3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.7.0.dev0) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.0.dev0) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Building wheels for collected packages: pytorch-lightning\n",
            "  Building wheel for pytorch-lightning (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-1.7.0.dev0-py3-none-any.whl size=607067 sha256=f4f4a69a667e7178e9fcfb293f7bf975de88851005ae03e472ce4906224e3649\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9ai5x5e5/wheels/18/24/dd/8e13b7dfcda990eb2b099a57bb6d705f6d43fb53ecb4ed07bf\n",
            "Successfully built pytorch-lightning\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.7.0.dev0 torchmetrics-0.9.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI5vP1oWSiq0",
        "outputId": "49de3c29-1948-4e41-b8fb-40ed3b390629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X96MCCfQRBDG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pytorch_lightning.trainer import Trainer\n",
        "from tqdm.auto import tqdm\n",
        "from model import Network\n",
        "from text_data import MemoryMapDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogqWNcZkhKEB"
      },
      "source": [
        "NNSplit has a `Network` class which is a `pl.LightningModule` specifying network architecture, data loading logic etc. To instantiate a new network, we need to first get the default hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKNM1sVpR-Lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7424da16-cc7c-4eb0-90dd-5b94520c69ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(accelerator=None, accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=128, benchmark=None, check_val_every_n_epoch=1, default_root_dir=None, detect_anomaly=False, deterministic=None, devices=None, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, gpus=None, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, level_weights=[], limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, max_epochs=1, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, predict_indices=[], profiler=None, reload_dataloaders_every_epoch=True, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, strategy=None, sync_batchnorm=False, test_size=50000, tpu_cores=None, track_grad_norm=-1, train_size=1000000, val_check_interval=None, weights_save_path=None)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "parser = Network.get_parser()\n",
        "hparams = parser.parse_args([])\n",
        "hparams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMldDgFkS3ZU"
      },
      "source": [
        "## Load text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE2YMQOrhy24"
      },
      "source": [
        "Next, we can load the text data created previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADW2U60kSnOf"
      },
      "outputs": [],
      "source": [
        "text_dataset = 'data.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YOPVi2vh2dG"
      },
      "source": [
        "Keep in mind that this can be any `torch.utils.data.Dataset` with `str` entries, so you can completely customize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS-KFyiOS8Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4a4ca34-74aa-41a4-d0d0-2d0219efca61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'d'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "text_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5cVdSTFiE9o"
      },
      "source": [
        "Next, create a `Labeler`, which is used to annotate the text from above. Any SpaCy model which supports sentencization can be used. You will have to install the appropriate SpaCy model with `python -m spacy ...` when running this in Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install diskcache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6svIUnRVjf4",
        "outputId": "809e09e3-1fab-4d20-88d9-174bbe34cee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting diskcache\n",
            "  Downloading diskcache-5.4.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: diskcache\n",
            "Successfully installed diskcache-5.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SoMaJo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13rb2OtyVqsF",
        "outputId": "e1eb6761-a0e4-4eb2-cbd8-4f3275c2a805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SoMaJo\n",
            "  Downloading SoMaJo-2.2.1-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2019.02.18 in /usr/local/lib/python3.7/dist-packages (from SoMaJo) (2022.6.2)\n",
            "Installing collected packages: SoMaJo\n",
            "Successfully installed SoMaJo-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkwjwBPiCUPl"
      },
      "outputs": [],
      "source": [
        "from labeler import Labeler, SpacySentenceTokenizer, SpacyWordTokenizer\n",
        "from spacy.tokenizer import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q568uRViSHco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "7a411252-a76b-4b6c-aeca-a2344f192ae4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-a17bb674c67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         SpacySentenceTokenizer(\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_start_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_end_punct_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         ),\n\u001b[1;32m      6\u001b[0m         \u001b[0mSpacyWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'punctuation'"
          ]
        }
      ],
      "source": [
        "labeler = Labeler(\n",
        "    [\n",
        "        SpacySentenceTokenizer(\n",
        "            \"en_core_web_sm\", lower_start_prob=0.7, remove_end_punct_prob=0.7\n",
        "        ),\n",
        "        SpacyWordTokenizer(\"en_core_web_sm\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aps02am6iio_"
      },
      "source": [
        "`Labeler.visualize` shows you what the network sees: \n",
        "- `byte` is the UTF-8 encoded text. This has changed in the newest version of NNSplit. Previously characters where used, but using bytes allows NNSplit to work for any language regardless of the characters used to represent it.\n",
        "- The other rows depend on the `Labeler` and determine what the neural networks tries to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL5-_awsSfYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "adb7b0d6-1d69-404a-b57f-860918e90288"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-531da06d1c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabeler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a test. This is another test.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'labeler' is not defined"
          ]
        }
      ],
      "source": [
        "labeler.visualize(\"This is a test. This is another test.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL7gZKuITDYA"
      },
      "source": [
        "## Start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_cI7PJ0jNfH"
      },
      "source": [
        "Now we can finally start training. \n",
        "\n",
        "`train_size` determines how many entries in the dataset to sample for each epoch. \n",
        "\n",
        "Using SpaCy with multiprocessing leaks memory, so the memory usage will continously increase during each epoch and reset at the end. So you will have to set `train_size` to a size that corresponds to how much memory is available. `500_000` works well in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D14-MKkTUL3"
      },
      "outputs": [],
      "source": [
        "hparams.gpus = 1\n",
        "hparams.max_epochs = 4\n",
        "hparams.train_size = 500_000\n",
        "hparams.predict_indices = [0, 1] # which split levels of the labeler to predict\n",
        "# how to weigh the selected indices\n",
        "# in general sentence boundary detection should be weighed the highest\n",
        "hparams.level_weights = [0.1, 2.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq2u1s6Cj5sT"
      },
      "source": [
        "Instantiate the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV385cJtTNVN"
      },
      "outputs": [],
      "source": [
        "model = Network(\n",
        "  text_dataset,\n",
        "  labeler,\n",
        "  hparams,\n",
        ")\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHDW5wbKj8xz"
      },
      "source": [
        "Instantiate the `pl.trainer.Trainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzV01atSTjKe"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer.from_argparse_args(hparams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6_n-DuNkD0o"
      },
      "source": [
        "And fit the model. Each row of the f1 and precision scores corresponds to each tokenizer of the `Labeler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awa3ZO5oTl7X"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq16P_pqklch"
      },
      "source": [
        "Finally, store the trained model somewhere. This saves a `.onnx` export of the model in the specified directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tSj4DGoYfL"
      },
      "outputs": [],
      "source": [
        "# onnx metadata which determines how to use the prediction indices to split text\n",
        "metadata = {\n",
        "    \"split_sequence\": json.dumps(\n",
        "        {\n",
        "            \"instructions\": [\n",
        "                [\"Sentence\", {\"PredictionIndex\": 0}],\n",
        "                [\"Token\", {\"PredictionIndex\": 1}],\n",
        "                [\"_Whitespace\", {\"Function\": \"whitespace\"}],\n",
        "            ]\n",
        "        }\n",
        "    )\n",
        "}\n",
        "model.store(\"en\", metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiAxbt37YFYP"
      },
      "source": [
        "# Load the model in NNSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynlr1bYuk_ZV"
      },
      "source": [
        "First, install NNSplit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXL7NTSmLi_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cea5e8-7705-41e9-f4cb-379f2c5fea37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nnsplit\n",
            "  Downloading nnsplit-0.5.8_post0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting onnxruntime==1.7\n",
            "  Downloading onnxruntime-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4 in /usr/local/lib/python3.7/dist-packages (from nnsplit) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.7->nnsplit) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.7->nnsplit) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime==1.7->nnsplit) (1.15.0)\n",
            "Installing collected packages: onnxruntime, nnsplit\n",
            "Successfully installed nnsplit-0.5.8.post0 onnxruntime-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nnsplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y8mTjA9YRXH"
      },
      "outputs": [],
      "source": [
        "from nnsplit import NNSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7tfpxtplE8S"
      },
      "source": [
        "Instantiate the splitter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EeDhEjoYj-a"
      },
      "outputs": [],
      "source": [
        "splitter = NNSplit(\"/content/nnsplit/models/en/model.onnx\", use_cuda=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrjzXPnPlPDs"
      },
      "source": [
        "And split a text!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERhaXDUlYmcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96939f45-a6fe-49ae-8339-7bb2e3d45661"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Split(Split(Split('This', ' '), Split('is', ' '), Split('a', ' '), Split('test', ' ')), Split(Split('This', ' '), Split('is', ' '), Split('another', ' '), Split('test', ''), Split('.', '')))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "splits = splitter.split([\"This is a test This is another test.\"])[0]\n",
        "splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOi2xVTllSjv"
      },
      "source": [
        "The public API of NNSplit has changed significantly, making it much easier to use now. Everything is a `nnsplit.Split` which can be iterated over or stringified with `str(...)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5DRnwAJY5Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f86a6c1-b59d-469c-a22c-fed68292b56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a test                 <class 'builtins.Split'>\n",
            "This is another test.          <class 'builtins.Split'>\n"
          ]
        }
      ],
      "source": [
        "for sentence in splits:\n",
        "    print(str(sentence).ljust(30), type(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRt37H-hlmqf"
      },
      "source": [
        "Or if you want to go token-level:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mKlF78WY-31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0df4815-b7be-4c56-dc4d-f10f66337b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This       Split('This', ' ')             <class 'builtins.Split'>\n",
            "is         Split('is', ' ')               <class 'builtins.Split'>\n",
            "a          Split('a', ' ')                <class 'builtins.Split'>\n",
            "test       Split('test', ' ')             <class 'builtins.Split'>\n",
            "\n",
            "This       Split('This', ' ')             <class 'builtins.Split'>\n",
            "is         Split('is', ' ')               <class 'builtins.Split'>\n",
            "another    Split('another', ' ')          <class 'builtins.Split'>\n",
            "test       Split('test', '')              <class 'builtins.Split'>\n",
            ".          Split('.', '')                 <class 'builtins.Split'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sentence in splits:\n",
        "    for token in sentence:\n",
        "        print(str(token).ljust(10), repr(token).ljust(30), type(token))\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyVn5FHdluOQ"
      },
      "source": [
        "Until the smallest unit, which then returns a `str` instead of an `nnsplit.Split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTgFJU1uZgnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579d52bb-496c-4602-982d-8b66a3780dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This       <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "is         <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "a          <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "test       <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "This       <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "is         <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "another    <class 'str'>\n",
            "\" \"        <class 'str'>\n",
            "\n",
            "test       <class 'str'>\n",
            "\"\"         <class 'str'>\n",
            "\n",
            ".          <class 'str'>\n",
            "\"\"         <class 'str'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sentence in splits:\n",
        "    for [text, whitespace] in sentence:\n",
        "        print(text.ljust(10), type(text))\n",
        "        print(f'\"{whitespace}\"'.ljust(10), type(whitespace))\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrN4T1lYl3is"
      },
      "source": [
        "Finally, for some benchmarks: If you are running `NNSplit` on GPU, you can increase the speed on large datasets by using a big batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYHT8F79bP89"
      },
      "outputs": [],
      "source": [
        "splitter = NNSplit(\"/content/nnsplit/models/en/model.onnx\", use_cuda=False, batch_size=2**14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BSrcu55bDQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a61c9c3-a7f7-4c41-c3bf-93e1aba4fc12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 loops, best of 5: 1.59 ms per loop\n",
            "10 loops, best of 5: 86.2 ms per loop\n",
            "1 loop, best of 5: 919 ms per loop\n",
            "1 loop, best of 5: 9.51 s per loop\n"
          ]
        }
      ],
      "source": [
        "text = \"This is a test This is another test.\"\n",
        "\n",
        "%timeit splitter.split([text])[0]\n",
        "%timeit splitter.split([text] * 100)[0]\n",
        "%timeit splitter.split([text] * 1000)[0]\n",
        "%timeit splitter.split([text] * 10_000)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTGnTBrqmAFh"
      },
      "source": [
        "And voilà! Splitting 10000 short texts in less than 400 milliseconds."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NNSplit Custom data training and interfacing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91738573d9d8429e975ec2124f071e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebd82baee98b434fa5956bbb0e1e586b",
              "IPY_MODEL_86e2242e118e494d910fed5a642d76ea",
              "IPY_MODEL_20f649ce029d4bd0904b482c1bb21455"
            ],
            "layout": "IPY_MODEL_3a34bb6a60f2444ca680c42064924497"
          }
        },
        "ebd82baee98b434fa5956bbb0e1e586b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11a9a46706e4279991d9c8b8ce486d6",
            "placeholder": "​",
            "style": "IPY_MODEL_de11f652d7e74418aedfef88d61b269a",
            "value": ""
          }
        },
        "86e2242e118e494d910fed5a642d76ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff5c245c8774b779ab643dc963fc516",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d305eaf63ea4461827be333723f3a8b",
            "value": 0
          }
        },
        "20f649ce029d4bd0904b482c1bb21455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff51286e3e24b5a9cf29b9c67227aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_13909ae0cd764729962756800e8b9859",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "3a34bb6a60f2444ca680c42064924497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11a9a46706e4279991d9c8b8ce486d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de11f652d7e74418aedfef88d61b269a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ff5c245c8774b779ab643dc963fc516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6d305eaf63ea4461827be333723f3a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ff51286e3e24b5a9cf29b9c67227aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13909ae0cd764729962756800e8b9859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}