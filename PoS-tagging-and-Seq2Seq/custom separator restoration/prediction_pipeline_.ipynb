{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction pipeline .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e46e788563942368aa4268796b37209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87c44209487045869981cd6ea1646f93",
              "IPY_MODEL_6d2c130ae93249fcb90521bce9776b12",
              "IPY_MODEL_e6cd9cb824e64ddca7956aca7620b660"
            ],
            "layout": "IPY_MODEL_b483abde3f6d42b5b6478f13f2b59d59"
          }
        },
        "87c44209487045869981cd6ea1646f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c76b0a46a7402e8d238dea302757f8",
            "placeholder": "​",
            "style": "IPY_MODEL_c1312ed0cbed40e9a93037ea10915c10",
            "value": "100%"
          }
        },
        "6d2c130ae93249fcb90521bce9776b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a698a1824a4ecd812b30a80575a9e6",
            "max": 2205,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f5fcfd7a51f4cb6a0a079717cc0f397",
            "value": 2205
          }
        },
        "e6cd9cb824e64ddca7956aca7620b660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1de2fdb8d84c7b8fc0067d5c254cf0",
            "placeholder": "​",
            "style": "IPY_MODEL_3f81f3c4da1d430d8c3c4fb6579fade2",
            "value": " 2205/2205 [00:02&lt;00:00, 1001.86it/s]"
          }
        },
        "b483abde3f6d42b5b6478f13f2b59d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c76b0a46a7402e8d238dea302757f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1312ed0cbed40e9a93037ea10915c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29a698a1824a4ecd812b30a80575a9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5fcfd7a51f4cb6a0a079717cc0f397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a1de2fdb8d84c7b8fc0067d5c254cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f81f3c4da1d430d8c3c4fb6579fade2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8985aa807e744719a21ad17e32df5cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd24641c2c0a46878772032222c1c6c2",
              "IPY_MODEL_d6c9e6140a524c90aff5bd8421fba980",
              "IPY_MODEL_de32358ff88440b2bfcbaf349c7c3dfc"
            ],
            "layout": "IPY_MODEL_fdff1b3b09b64914b63d2fab05c18ce6"
          }
        },
        "bd24641c2c0a46878772032222c1c6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f303d416bce14e708301ecc026e5ee53",
            "placeholder": "​",
            "style": "IPY_MODEL_3f80613053b543bca17b3180e64ba10f",
            "value": "100%"
          }
        },
        "d6c9e6140a524c90aff5bd8421fba980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d5d9acbc114b0d9a4e02935b6c1f2c",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0a7349c01b948229c5d1dd6bd5944e9",
            "value": 8
          }
        },
        "de32358ff88440b2bfcbaf349c7c3dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5eb2374126044dbb40f3c2cff8f6761",
            "placeholder": "​",
            "style": "IPY_MODEL_9524ed50e8a74221bf92b0c5493ba0a5",
            "value": " 8/8 [00:01&lt;00:00,  6.73it/s]"
          }
        },
        "fdff1b3b09b64914b63d2fab05c18ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f303d416bce14e708301ecc026e5ee53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f80613053b543bca17b3180e64ba10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d5d9acbc114b0d9a4e02935b6c1f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a7349c01b948229c5d1dd6bd5944e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5eb2374126044dbb40f3c2cff8f6761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9524ed50e8a74221bf92b0c5493ba0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04dd675754114a42aa062665419c6560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97c5873d03c04b019b2e0c80616f9d65",
              "IPY_MODEL_8d35afbb49a743a6bb035099bfa77787",
              "IPY_MODEL_0b6a449d433d4f048f7c070df1373a6b"
            ],
            "layout": "IPY_MODEL_e5728e454a03401c8aa7c361feab549e"
          }
        },
        "97c5873d03c04b019b2e0c80616f9d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e04e9874e3df4d0e85c2b7ac7a11d6f5",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6d5fbe230c45acbd4be3d45b453339",
            "value": "100%"
          }
        },
        "8d35afbb49a743a6bb035099bfa77787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0eac7854344517bb65c805633cdba0",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a59581a4d2f4403be9ba8fc8b761860",
            "value": 11
          }
        },
        "0b6a449d433d4f048f7c070df1373a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53cc763fceec4ec4a3f4025d6d9b57ac",
            "placeholder": "​",
            "style": "IPY_MODEL_bee891b436cf4be4a625ee96fb0462e4",
            "value": " 11/11 [00:01&lt;00:00,  7.83it/s]"
          }
        },
        "e5728e454a03401c8aa7c361feab549e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e04e9874e3df4d0e85c2b7ac7a11d6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6d5fbe230c45acbd4be3d45b453339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec0eac7854344517bb65c805633cdba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a59581a4d2f4403be9ba8fc8b761860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53cc763fceec4ec4a3f4025d6d9b57ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee891b436cf4be4a625ee96fb0462e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import re"
      ],
      "metadata": {
        "id": "FczWV-MI5eEC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/\"\n",
        "file_path = data_path + \"IWSLT12.TALK.dev2010.en-fr.en.xml\""
      ],
      "metadata": {
        "id": "iyS1A9qk5g8B"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xmlp = ET.XMLParser(encoding=\"utf-8\")\n",
        "tree = ET.parse(file_path, parser=xmlp)\n",
        "root = tree.getroot()"
      ],
      "metadata": {
        "id": "8oReb8P_5sNg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for child in root:\n",
        "    print(child.tag, child.attrib)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix9uIoAd5t6R",
        "outputId": "ea996b47-d8b9-4e8d-fc83-1e4122313b38"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "srcset {'setid': 'iwslt2012-dev2010', 'srclang': 'english'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "\n",
        "for doc_id in range(len(root[0])):\n",
        "    doc_segs = []\n",
        "    doc = root[0][doc_id]\n",
        "    for seg in doc.iter('seg'):\n",
        "        doc_segs.append(seg.text)\n",
        "    docs.append(doc_segs)"
      ],
      "metadata": {
        "id": "ch7BzJM95v7p"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_texts = [re.sub(r'\\s+', ' ', ''.join(d)).strip() for d in docs]"
      ],
      "metadata": {
        "id": "Vvt_p2XS5yWg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path + 'dev_texts.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in dev_texts:\n",
        "        f.write(text + '\\n')"
      ],
      "metadata": {
        "id": "Ah-SQYYu50jY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = data_path + \"IWSLT12.TED.MT.tst2012.en-fr.en.xml\"\n",
        "\n",
        "xmlp = ET.XMLParser(encoding=\"utf-8\")\n",
        "tree = ET.parse(file_path, parser=xmlp)\n",
        "root = tree.getroot()"
      ],
      "metadata": {
        "id": "rcgvqIVG56f7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "\n",
        "for doc_id in range(len(root[0])):\n",
        "    doc_segs = []\n",
        "    doc = root[0][doc_id]\n",
        "    for seg in doc.iter('seg'):\n",
        "        doc_segs.append(seg.text)\n",
        "    docs.append(doc_segs)\n",
        "\n",
        "test_texts_2012 = [re.sub(r'\\s+', ' ', ''.join(d)).strip() for d in docs]\n",
        "\n",
        "with open(data_path + 'test_texts_2012.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in test_texts_2012:\n",
        "        f.write(text + '\\n')\n"
      ],
      "metadata": {
        "id": "4JvH_vwp5-tp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = data_path + \"train.tags.en-fr.en\"\n",
        "xmlp = ET.XMLParser(encoding=\"UTF-8\")\n",
        "tree = ET.parse(file_path, parser=xmlp)\n",
        "root = tree.getroot()"
      ],
      "metadata": {
        "id": "4uhlP-_16Bqp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "\n",
        "for doc in root.iter('transcript'):\n",
        "    docs.append(doc.text)"
      ],
      "metadata": {
        "id": "8SYIP3WZ6OgQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = [re.sub(r'\\s+', ' ', d.replace('\\n', ' ')).strip() for d in docs]\n",
        "\n",
        "with open(data_path + 'train_texts.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in train_texts:\n",
        "        f.write(text + '\\n')"
      ],
      "metadata": {
        "id": "lEvP9AiE6PY5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from transformers import AutoTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "a_Z-gO-w9Qu1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'bert-base-uncased' #albert-base-v1, bert-base-cased, bert-base-uncased\n",
        "data_path = \"/content/\"\n",
        "\n",
        "with open(data_path + 'data1.txt', 'r', encoding='utf-8') as f:\n",
        "    train_text = f.readlines()\n",
        "with open(data_path + 'dev_texts.txt', 'r', encoding='utf-8') as f:\n",
        "    valid_text = f.readlines()\n",
        "with open(data_path + 'test_texts_2012.txt', 'r', encoding='utf-8') as f:\n",
        "    test_text = f.readlines()"
      ],
      "metadata": {
        "id": "h70xu_u19gjS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = train_text, valid_text, test_text"
      ],
      "metadata": {
        "id": "f_rU-CXu9mS6"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[len(ds) for ds in datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py95TNaV9o-I",
        "outputId": "ebea2ff0-366d-44a9-f9bb-411df9c80ec5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2205, 8, 11]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace('!', '/')\n",
        "    text = text.replace(':', ',')\n",
        "    text = text.replace('--', ',')\n",
        "    text = text.replace('?', '/')\n",
        "    reg = \"(?<=[a-zA-Z])-(?=[a-zA-Z]{2,})\"\n",
        "    r = re.compile(reg, re.DOTALL)\n",
        "    text = r.sub(' ', text)\n",
        "    \n",
        "    text = re.sub(r'\\s-\\s', ' , ', text)\n",
        "    \n",
        "#     text = text.replace('-', ',')\n",
        "    text = text.replace(';', '.')\n",
        "    text = text.replace(' ,', ',')\n",
        "    text = text.replace('♫', '')\n",
        "    text = text.replace('...', '')\n",
        "    text = text.replace('.\\\"', ',')\n",
        "    text = text.replace('\"', ',')\n",
        "    text = re.sub(r'--\\s?--', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    text = re.sub(r',\\s?,', ',', text)\n",
        "    text = re.sub(r',\\s?\\.', '.', text)\n",
        "    text = re.sub(r'\\?\\s?\\.', '?', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    text = re.sub(r'\\s+\\?', '?', text)\n",
        "    text = re.sub(r'\\s+,', ',', text)\n",
        "    text = re.sub(r'\\.[\\s+\\.]+', '. ', text)\n",
        "    text = re.sub(r'\\s+\\.', '.', text)\n",
        "    \n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "id": "TN3o0KSA-CpR"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [[clean_text(text) for text in ds] for ds in datasets]"
      ],
      "metadata": {
        "id": "-2cP-22LIYzH"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[len([t for t in ds if len(t)>0]) for ds in datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVMDQ4UcId3u",
        "outputId": "129fb4ee-dd02-4541-da23-61e6f09a8681"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2205, 8, 11]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[len(' '.join(ds).split(' ')) for ds in datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8BDx9jpIfio",
        "outputId": "fa1c5095-ab95-4e0b-826c-86ab23c77086"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31261, 17347, 18477]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ8hK6kxJX21",
        "outputId": "83f7b6bd-51e0-47b7-a8f9-64dc366e0ae7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_type)"
      ],
      "metadata": {
        "id": "fe6OQhjcIipl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_ids = tokenizer.encode(\"./,\")[1:-1]\n",
        "target_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aStYAcH_JndR",
        "outputId": "c7b31eaa-067a-4ada-fb76-62781afb874c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1012, 1013, 1010]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_token2id = {t: tokenizer.encode(t)[-2] for t in \"./,\"}\n",
        "target_token2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65hZ3f33Jsa1",
        "outputId": "80289dca-88b4-4f38-acf1-09085d4cc214"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 1010, '.': 1012, '/': 1013}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_ids = list(target_token2id.values())\n",
        "target_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-d81Y58JyJd",
        "outputId": "f0f034df-8a86-4860-9d1f-f64079f22d6d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1012, 1013, 1010]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2target = {\n",
        "    0: 0,\n",
        "    -1: -1,\n",
        "}\n",
        "for i, ti in enumerate(target_ids):\n",
        "    id2target[ti] = i+1\n",
        "target2id = {value: key for key, value in id2target.items()}\n",
        "\n",
        "def create_target(text):\n",
        "    encoded_words, targets = [], []\n",
        "    \n",
        "    words = text.split(' ')\n",
        "\n",
        "    for word in words:\n",
        "        target = 0\n",
        "        for target_token, target_id in target_token2id.items():\n",
        "            if word.endswith(target_token):\n",
        "                word = word.rstrip(target_token)\n",
        "                target = id2target[target_id]\n",
        "\n",
        "        encoded_word = tokenizer.encode(word, add_special_tokens=False)\n",
        "        \n",
        "        for w in encoded_word:\n",
        "            encoded_words.append(w)\n",
        "        for _ in range(len(encoded_word)-1):\n",
        "            targets.append(-1)\n",
        "        targets.append(target)\n",
        "        \n",
        "#         print([tokenizer._convert_id_to_token(ew) for ew in encoded_word], target)\n",
        "        \n",
        "\n",
        "    encoded_words = [tokenizer.cls_token_id or tokenizer.bos_token_id] +\\\n",
        "                    encoded_words +\\\n",
        "                    [tokenizer.sep_token_id or tokenizer.eos_token_id]\n",
        "    targets = [-1] + targets + [-1]\n",
        "    \n",
        "    return encoded_words, targets"
      ],
      "metadata": {
        "id": "XlpekdIEJ01V"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Tyranosaurus: kill me? Not enough,/ -- said the co-pilot -- ...\"\n",
        "print(s)\n",
        "s = clean_text(s)\n",
        "print(s)\n",
        "data, targets = create_target(s)\n",
        "print(targets)\n",
        "[tokenizer._convert_id_to_token(d) for d in data[1:-1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26dVXBpnJ34t",
        "outputId": "6bb5b5fd-5166-4946-e393-77a7ec6ea7f4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tyranosaurus: kill me? Not enough,/ -- said the co-pilot -- ...\n",
            "tyranosaurus, kill me/ not enough,/, said the co pilot,\n",
            "[-1, -1, -1, 3, 0, 2, 0, -1, -1, 3, 0, 0, 0, 3, -1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ty',\n",
              " '##rano',\n",
              " '##saurus',\n",
              " 'kill',\n",
              " 'me',\n",
              " 'not',\n",
              " 'enough',\n",
              " ',',\n",
              " '/',\n",
              " 'said',\n",
              " 'the',\n",
              " 'co',\n",
              " 'pilot']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts, targets = [], []\n",
        "\n",
        "for ds in datasets:\n",
        "    x = list(zip(*(create_target(ts) for ts in tqdm(ds))))\n",
        "    encoded_texts.append(x[0])\n",
        "    targets.append(x[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8e46e788563942368aa4268796b37209",
            "87c44209487045869981cd6ea1646f93",
            "6d2c130ae93249fcb90521bce9776b12",
            "e6cd9cb824e64ddca7956aca7620b660",
            "b483abde3f6d42b5b6478f13f2b59d59",
            "32c76b0a46a7402e8d238dea302757f8",
            "c1312ed0cbed40e9a93037ea10915c10",
            "29a698a1824a4ecd812b30a80575a9e6",
            "2f5fcfd7a51f4cb6a0a079717cc0f397",
            "9a1de2fdb8d84c7b8fc0067d5c254cf0",
            "3f81f3c4da1d430d8c3c4fb6579fade2",
            "8985aa807e744719a21ad17e32df5cc2",
            "bd24641c2c0a46878772032222c1c6c2",
            "d6c9e6140a524c90aff5bd8421fba980",
            "de32358ff88440b2bfcbaf349c7c3dfc",
            "fdff1b3b09b64914b63d2fab05c18ce6",
            "f303d416bce14e708301ecc026e5ee53",
            "3f80613053b543bca17b3180e64ba10f",
            "62d5d9acbc114b0d9a4e02935b6c1f2c",
            "c0a7349c01b948229c5d1dd6bd5944e9",
            "f5eb2374126044dbb40f3c2cff8f6761",
            "9524ed50e8a74221bf92b0c5493ba0a5",
            "04dd675754114a42aa062665419c6560",
            "97c5873d03c04b019b2e0c80616f9d65",
            "8d35afbb49a743a6bb035099bfa77787",
            "0b6a449d433d4f048f7c070df1373a6b",
            "e5728e454a03401c8aa7c361feab549e",
            "e04e9874e3df4d0e85c2b7ac7a11d6f5",
            "dc6d5fbe230c45acbd4be3d45b453339",
            "ec0eac7854344517bb65c805633cdba0",
            "0a59581a4d2f4403be9ba8fc8b761860",
            "53cc763fceec4ec4a3f4025d6d9b57ac",
            "bee891b436cf4be4a625ee96fb0462e4"
          ]
        },
        "id": "HNATZSx-KJX9",
        "outputId": "4e72f917-9608-4ec5-e249-4a6953190c21"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2205 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e46e788563942368aa4268796b37209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8985aa807e744719a21ad17e32df5cc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04dd675754114a42aa062665419c6560"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for te, ta in zip(encoded_texts[0][0], targets[0][0]):\n",
        "    print(f\"{tokenizer._convert_id_to_token(te):15}\\t{ta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmd_hAFkKdXl",
        "outputId": "5fcd3ec7-0ad1-416a-a1c2-b9cea663864d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]          \t-1\n",
            "finally        \t0\n",
            "tonight        \t3\n",
            "it             \t-1\n",
            "'              \t-1\n",
            "s              \t0\n",
            "prom           \t0\n",
            "season         \t0\n",
            "and            \t2\n",
            "steve          \t0\n",
            "hartman        \t0\n",
            "met            \t0\n",
            "the            \t0\n",
            "queen          \t0\n",
            "and            \t0\n",
            "her            \t0\n",
            "king           \t0\n",
            "on             \t3\n",
            "the            \t2\n",
            "road           \t0\n",
            "[SEP]          \t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(data_path + model_type, exist_ok=True)\n",
        "\n",
        "for i, name in enumerate(('train', 'valid', 'test')):\n",
        "    with open(data_path + f'{model_type}/{name}_data.pkl', 'wb') as f:\n",
        "        pickle.dump((encoded_texts[i], targets[i]), f)"
      ],
      "metadata": {
        "id": "76Zhr4flLwaG"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "for ds_targets in targets:\n",
        "    c = Counter((target for t in ds_targets for target in t))\n",
        "    print('\\t'.join([str(c[i]) for i in (1,2,3,0,-1)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGWPxT9YL3lO",
        "outputId": "a9b34c3a-675b-4269-d34b-45c281a7b3da"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\t5661\t1496\t24101\t6904\n",
            "6\t974\t1225\t15142\t1928\n",
            "9\t1138\t1120\t16210\t2129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = []\n",
        "i = 0\n",
        "\n",
        "raw_words = datasets[1][2].split(' ')\n",
        "\n",
        "for te, ta in zip(encoded_texts[1][2], targets[1][2]):\n",
        "    if ta == -1:\n",
        "        e.append(te)\n",
        "    else:\n",
        "        e.append(te)\n",
        "        print(f\"{tokenizer.decode(e):15}\\t{tokenizer.decode(target2id[ta]):10}\\t{raw_words[i]}\")\n",
        "        e = []\n",
        "        i += 1\n",
        "print(f\"{tokenizer.decode(e):15}\\t{tokenizer.decode(target2id[ta]):10}\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AN230OmfL63M",
        "outputId": "865d98eb-415b-43af-ee77-d01eea03c4e4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] you      \t[PAD]     \tyou\n",
            "know           \t,         \tknow,\n",
            "i've           \t[PAD]     \ti've\n",
            "talked         \t[PAD]     \ttalked\n",
            "about          \t[PAD]     \tabout\n",
            "some           \t[PAD]     \tsome\n",
            "of             \t[PAD]     \tof\n",
            "these          \t[PAD]     \tthese\n",
            "projects       \t[PAD]     \tprojects\n",
            "before         \t,         \tbefore,\n",
            "about          \t[PAD]     \tabout\n",
            "the            \t[PAD]     \tthe\n",
            "human          \t[PAD]     \thuman\n",
            "genome         \t[PAD]     \tgenome\n",
            "and            \t[PAD]     \tand\n",
            "what           \t[PAD]     \twhat\n",
            "that           \t[PAD]     \tthat\n",
            "might          \t[PAD]     \tmight\n",
            "mean           \t,         \tmean,\n",
            "and            \t[PAD]     \tand\n",
            "discovering    \t[PAD]     \tdiscovering\n",
            "new            \t[PAD]     \tnew\n",
            "sets           \t[PAD]     \tsets\n",
            "of             \t[PAD]     \tof\n",
            "genes          \t/         \tgenes/\n",
            "we're          \t[PAD]     \twe're\n",
            "actually       \t[PAD]     \tactually\n",
            "starting       \t[PAD]     \tstarting\n",
            "at             \t[PAD]     \tat\n",
            "a              \t[PAD]     \ta\n",
            "new            \t[PAD]     \tnew\n",
            "point          \t,         \tpoint,\n",
            "we've          \t[PAD]     \twe've\n",
            "been           \t[PAD]     \tbeen\n",
            "digitizing     \t[PAD]     \tdigitizing\n",
            "biology        \t,         \tbiology,\n",
            "and            \t[PAD]     \tand\n",
            "now            \t[PAD]     \tnow\n",
            "we're          \t[PAD]     \twe're\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "go             \t[PAD]     \tgo\n",
            "from           \t[PAD]     \tfrom\n",
            "that           \t[PAD]     \tthat\n",
            "digital        \t[PAD]     \tdigital\n",
            "code           \t[PAD]     \tcode\n",
            "into           \t[PAD]     \tinto\n",
            "a              \t[PAD]     \ta\n",
            "new            \t[PAD]     \tnew\n",
            "phase          \t[PAD]     \tphase\n",
            "of             \t[PAD]     \tof\n",
            "biology        \t,         \tbiology,\n",
            "with           \t[PAD]     \twith\n",
            "designing      \t[PAD]     \tdesigning\n",
            "and            \t[PAD]     \tand\n",
            "synthesizing   \t[PAD]     \tsynthesizing\n",
            "life           \t/         \tlife/\n",
            "so             \t,         \tso,\n",
            "we've          \t[PAD]     \twe've\n",
            "always         \t[PAD]     \talways\n",
            "been           \t[PAD]     \tbeen\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "ask            \t[PAD]     \task\n",
            "big            \t[PAD]     \tbig\n",
            "questions /, what\t[PAD]     \tquestions/,what\n",
            "is             \t[PAD]     \tis\n",
            "life /         \t,         \tlife/,\n",
            "is             \t[PAD]     \tis\n",
            "something      \t[PAD]     \tsomething\n",
            "that           \t[PAD]     \tthat\n",
            "i              \t[PAD]     \ti\n",
            "think          \t[PAD]     \tthink\n",
            "many           \t[PAD]     \tmany\n",
            "biologists     \t[PAD]     \tbiologists\n",
            "have           \t[PAD]     \thave\n",
            "been           \t[PAD]     \tbeen\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "understand     \t[PAD]     \tunderstand\n",
            "at             \t[PAD]     \tat\n",
            "various        \t[PAD]     \tvarious\n",
            "levels         \t/         \tlevels/\n",
            "we've          \t[PAD]     \twe've\n",
            "tried          \t[PAD]     \ttried\n",
            "various        \t[PAD]     \tvarious\n",
            "approaches     \t,         \tapproaches,\n",
            "paring         \t[PAD]     \tparing\n",
            "it             \t[PAD]     \tit\n",
            "down           \t[PAD]     \tdown\n",
            "to             \t[PAD]     \tto\n",
            "minimal        \t[PAD]     \tminimal\n",
            "components     \t/         \tcomponents/\n",
            "we've          \t[PAD]     \twe've\n",
            "been           \t[PAD]     \tbeen\n",
            "digitizing     \t[PAD]     \tdigitizing\n",
            "it             \t[PAD]     \tit\n",
            "now            \t[PAD]     \tnow\n",
            "for            \t[PAD]     \tfor\n",
            "almost         \t[PAD]     \talmost\n",
            "20             \t[PAD]     \t20\n",
            "years          \t/         \tyears/\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "sequenced      \t[PAD]     \tsequenced\n",
            "the            \t[PAD]     \tthe\n",
            "human          \t[PAD]     \thuman\n",
            "genome         \t,         \tgenome,\n",
            "it             \t[PAD]     \tit\n",
            "was            \t[PAD]     \twas\n",
            "going          \t[PAD]     \tgoing\n",
            "from           \t[PAD]     \tfrom\n",
            "the            \t[PAD]     \tthe\n",
            "analog         \t[PAD]     \tanalog\n",
            "world          \t[PAD]     \tworld\n",
            "of             \t[PAD]     \tof\n",
            "biology        \t[PAD]     \tbiology\n",
            "into           \t[PAD]     \tinto\n",
            "the            \t[PAD]     \tthe\n",
            "digital        \t[PAD]     \tdigital\n",
            "world          \t[PAD]     \tworld\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "computer       \t/         \tcomputer/\n",
            "now            \t[PAD]     \tnow\n",
            "we're          \t[PAD]     \twe're\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "ask            \t,         \task,\n",
            "can            \t[PAD]     \tcan\n",
            "we             \t[PAD]     \twe\n",
            "regenerate     \t[PAD]     \tregenerate\n",
            "life           \t,         \tlife,\n",
            "or             \t[PAD]     \tor\n",
            "can            \t[PAD]     \tcan\n",
            "we             \t[PAD]     \twe\n",
            "create         \t[PAD]     \tcreate\n",
            "new            \t[PAD]     \tnew\n",
            "life           \t,         \tlife,\n",
            "out            \t[PAD]     \tout\n",
            "of             \t[PAD]     \tof\n",
            "this           \t[PAD]     \tthis\n",
            "digital        \t[PAD]     \tdigital\n",
            "universe       \t/         \tuniverse/\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "the            \t[PAD]     \tthe\n",
            "map            \t[PAD]     \tmap\n",
            "of             \t[PAD]     \tof\n",
            "a              \t[PAD]     \ta\n",
            "small          \t[PAD]     \tsmall\n",
            "organism       \t,         \torganism,\n",
            "mycoplasma     \t[PAD]     \tmycoplasma\n",
            "genitalium     \t,         \tgenitalium,\n",
            "that           \t[PAD]     \tthat\n",
            "has            \t[PAD]     \thas\n",
            "the            \t[PAD]     \tthe\n",
            "smallest       \t[PAD]     \tsmallest\n",
            "genome         \t[PAD]     \tgenome\n",
            "for            \t[PAD]     \tfor\n",
            "a              \t[PAD]     \ta\n",
            "species        \t[PAD]     \tspecies\n",
            "that           \t[PAD]     \tthat\n",
            "can            \t[PAD]     \tcan\n",
            "self           \t[PAD]     \tself\n",
            "replicate      \t[PAD]     \treplicate\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "laboratory     \t/         \tlaboratory/\n",
            "and            \t[PAD]     \tand\n",
            "we've          \t[PAD]     \twe've\n",
            "been           \t[PAD]     \tbeen\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "just           \t[PAD]     \tjust\n",
            "see            \t[PAD]     \tsee\n",
            "if             \t[PAD]     \tif\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "come           \t[PAD]     \tcome\n",
            "up             \t[PAD]     \tup\n",
            "with           \t[PAD]     \twith\n",
            "an             \t[PAD]     \tan\n",
            "even           \t[PAD]     \teven\n",
            "smaller        \t[PAD]     \tsmaller\n",
            "genome         \t/         \tgenome/\n",
            "we're          \t[PAD]     \twe're\n",
            "able           \t[PAD]     \table\n",
            "to             \t[PAD]     \tto\n",
            "knock          \t[PAD]     \tknock\n",
            "out            \t[PAD]     \tout\n",
            "on             \t[PAD]     \ton\n",
            "the            \t[PAD]     \tthe\n",
            "order          \t[PAD]     \torder\n",
            "of             \t[PAD]     \tof\n",
            "a              \t[PAD]     \ta\n",
            "hundred        \t[PAD]     \thundred\n",
            "genes          \t[PAD]     \tgenes\n",
            "out            \t[PAD]     \tout\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "500            \t[PAD]     \t500\n",
            "or             \t[PAD]     \tor\n",
            "so             \t[PAD]     \tso\n",
            "that           \t[PAD]     \tthat\n",
            "are            \t[PAD]     \tare\n",
            "here           \t/         \there/\n",
            "but            \t[PAD]     \tbut\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "look           \t[PAD]     \tlook\n",
            "at             \t[PAD]     \tat\n",
            "its            \t[PAD]     \tits\n",
            "metabolic      \t[PAD]     \tmetabolic\n",
            "map            \t,         \tmap,\n",
            "it's           \t[PAD]     \tit's\n",
            "relatively     \t[PAD]     \trelatively\n",
            "simple         \t[PAD]     \tsimple\n",
            "compared       \t[PAD]     \tcompared\n",
            "to             \t[PAD]     \tto\n",
            "ours           \t/         \tours/\n",
            "trust          \t[PAD]     \ttrust\n",
            "me             \t,         \tme,\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "simple         \t/         \tsimple/\n",
            "but            \t[PAD]     \tbut\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "look           \t[PAD]     \tlook\n",
            "at             \t[PAD]     \tat\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "genes          \t[PAD]     \tgenes\n",
            "that           \t[PAD]     \tthat\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "knock          \t[PAD]     \tknock\n",
            "out            \t[PAD]     \tout\n",
            "one            \t[PAD]     \tone\n",
            "at             \t[PAD]     \tat\n",
            "a              \t[PAD]     \ta\n",
            "time           \t,         \ttime,\n",
            "it's           \t[PAD]     \tit's\n",
            "very           \t[PAD]     \tvery\n",
            "unlikely       \t[PAD]     \tunlikely\n",
            "that           \t[PAD]     \tthat\n",
            "this           \t[PAD]     \tthis\n",
            "would          \t[PAD]     \twould\n",
            "yield          \t[PAD]     \tyield\n",
            "a              \t[PAD]     \ta\n",
            "living         \t[PAD]     \tliving\n",
            "cell           \t/         \tcell/\n",
            "so             \t,         \tso,\n",
            "we             \t[PAD]     \twe\n",
            "decided        \t[PAD]     \tdecided\n",
            "the            \t[PAD]     \tthe\n",
            "only           \t[PAD]     \tonly\n",
            "way            \t[PAD]     \tway\n",
            "forward        \t[PAD]     \tforward\n",
            "was            \t[PAD]     \twas\n",
            "to             \t[PAD]     \tto\n",
            "actually       \t[PAD]     \tactually\n",
            "synthesize     \t[PAD]     \tsynthesize\n",
            "this           \t[PAD]     \tthis\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "could          \t[PAD]     \tcould\n",
            "vary           \t[PAD]     \tvary\n",
            "the            \t[PAD]     \tthe\n",
            "components     \t[PAD]     \tcomponents\n",
            "to             \t[PAD]     \tto\n",
            "ask            \t[PAD]     \task\n",
            "some           \t[PAD]     \tsome\n",
            "of             \t[PAD]     \tof\n",
            "these          \t[PAD]     \tthese\n",
            "most           \t[PAD]     \tmost\n",
            "fundamental    \t[PAD]     \tfundamental\n",
            "questions      \t/         \tquestions/\n",
            "and            \t[PAD]     \tand\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "started        \t[PAD]     \tstarted\n",
            "down           \t[PAD]     \tdown\n",
            "the            \t[PAD]     \tthe\n",
            "road           \t[PAD]     \troad\n",
            "of, can        \t[PAD]     \tof,can\n",
            "we             \t[PAD]     \twe\n",
            "synthesize     \t[PAD]     \tsynthesize\n",
            "a              \t[PAD]     \ta\n",
            "chromosome /   \t,         \tchromosome/,\n",
            "can            \t[PAD]     \tcan\n",
            "chemistry      \t[PAD]     \tchemistry\n",
            "permit         \t[PAD]     \tpermit\n",
            "making         \t[PAD]     \tmaking\n",
            "these          \t[PAD]     \tthese\n",
            "really         \t[PAD]     \treally\n",
            "large          \t[PAD]     \tlarge\n",
            "molecules      \t[PAD]     \tmolecules\n",
            "where          \t[PAD]     \twhere\n",
            "we've          \t[PAD]     \twe've\n",
            "never          \t[PAD]     \tnever\n",
            "been           \t[PAD]     \tbeen\n",
            "before         \t/         \tbefore/\n",
            "and            \t,         \tand,\n",
            "if             \t[PAD]     \tif\n",
            "we             \t[PAD]     \twe\n",
            "do             \t,         \tdo,\n",
            "can            \t[PAD]     \tcan\n",
            "we             \t[PAD]     \twe\n",
            "boot           \t[PAD]     \tboot\n",
            "up             \t[PAD]     \tup\n",
            "a              \t[PAD]     \ta\n",
            "chromosome     \t/         \tchromosome/\n",
            "a              \t[PAD]     \ta\n",
            "chromosome     \t,         \tchromosome,\n",
            "by             \t[PAD]     \tby\n",
            "the            \t[PAD]     \tthe\n",
            "way            \t,         \tway,\n",
            "is             \t[PAD]     \tis\n",
            "just           \t[PAD]     \tjust\n",
            "a              \t[PAD]     \ta\n",
            "piece          \t[PAD]     \tpiece\n",
            "of             \t[PAD]     \tof\n",
            "inert          \t[PAD]     \tinert\n",
            "chemical       \t[PAD]     \tchemical\n",
            "material       \t/         \tmaterial/\n",
            "so             \t,         \tso,\n",
            "our            \t[PAD]     \tour\n",
            "pace           \t[PAD]     \tpace\n",
            "of             \t[PAD]     \tof\n",
            "digitizing     \t[PAD]     \tdigitizing\n",
            "life           \t[PAD]     \tlife\n",
            "has            \t[PAD]     \thas\n",
            "been           \t[PAD]     \tbeen\n",
            "increasing     \t[PAD]     \tincreasing\n",
            "at             \t[PAD]     \tat\n",
            "an             \t[PAD]     \tan\n",
            "exponential    \t[PAD]     \texponential\n",
            "pace           \t/         \tpace/\n",
            "our            \t[PAD]     \tour\n",
            "ability        \t[PAD]     \tability\n",
            "to             \t[PAD]     \tto\n",
            "write          \t[PAD]     \twrite\n",
            "the            \t[PAD]     \tthe\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t[PAD]     \tcode\n",
            "has            \t[PAD]     \thas\n",
            "been           \t[PAD]     \tbeen\n",
            "moving         \t[PAD]     \tmoving\n",
            "pretty         \t[PAD]     \tpretty\n",
            "slowly         \t,         \tslowly,\n",
            "but            \t[PAD]     \tbut\n",
            "has            \t[PAD]     \thas\n",
            "been           \t[PAD]     \tbeen\n",
            "increasing     \t/         \tincreasing/\n",
            "and            \t[PAD]     \tand\n",
            "our            \t[PAD]     \tour\n",
            "latest         \t[PAD]     \tlatest\n",
            "point          \t[PAD]     \tpoint\n",
            "would          \t[PAD]     \twould\n",
            "put            \t[PAD]     \tput\n",
            "it             \t[PAD]     \tit\n",
            "on             \t[PAD]     \ton\n",
            "now            \t[PAD]     \tnow\n",
            "an             \t[PAD]     \tan\n",
            "exponential    \t[PAD]     \texponential\n",
            "curve          \t/         \tcurve/\n",
            "we             \t[PAD]     \twe\n",
            "started        \t[PAD]     \tstarted\n",
            "this           \t[PAD]     \tthis\n",
            "over           \t[PAD]     \tover\n",
            "15             \t[PAD]     \t15\n",
            "years          \t[PAD]     \tyears\n",
            "ago            \t/         \tago/\n",
            "it             \t[PAD]     \tit\n",
            "took           \t[PAD]     \ttook\n",
            "several        \t[PAD]     \tseveral\n",
            "stages         \t,         \tstages,\n",
            "in             \t[PAD]     \tin\n",
            "fact           \t,         \tfact,\n",
            "starting       \t[PAD]     \tstarting\n",
            "with           \t[PAD]     \twith\n",
            "a              \t[PAD]     \ta\n",
            "bioethical     \t[PAD]     \tbioethical\n",
            "review         \t[PAD]     \treview\n",
            "before         \t[PAD]     \tbefore\n",
            "we             \t[PAD]     \twe\n",
            "did            \t[PAD]     \tdid\n",
            "the            \t[PAD]     \tthe\n",
            "first          \t[PAD]     \tfirst\n",
            "experiments    \t/         \texperiments/\n",
            "but            \t[PAD]     \tbut\n",
            "it             \t[PAD]     \tit\n",
            "turns          \t[PAD]     \tturns\n",
            "out            \t[PAD]     \tout\n",
            "synthesizing   \t[PAD]     \tsynthesizing\n",
            "dna            \t[PAD]     \tdna\n",
            "is             \t[PAD]     \tis\n",
            "very           \t[PAD]     \tvery\n",
            "difficult      \t/         \tdifficult/\n",
            "there's        \t[PAD]     \tthere's\n",
            "tens           \t[PAD]     \ttens\n",
            "of             \t[PAD]     \tof\n",
            "thousands      \t[PAD]     \tthousands\n",
            "of             \t[PAD]     \tof\n",
            "machines       \t[PAD]     \tmachines\n",
            "around         \t[PAD]     \taround\n",
            "the            \t[PAD]     \tthe\n",
            "world          \t[PAD]     \tworld\n",
            "that           \t[PAD]     \tthat\n",
            "make           \t[PAD]     \tmake\n",
            "small          \t[PAD]     \tsmall\n",
            "pieces         \t[PAD]     \tpieces\n",
            "of             \t[PAD]     \tof\n",
            "dna            \t,         \tdna,\n",
            "30             \t[PAD]     \t30\n",
            "to             \t[PAD]     \tto\n",
            "50             \t[PAD]     \t50\n",
            "letters        \t[PAD]     \tletters\n",
            "in             \t[PAD]     \tin\n",
            "length         \t,         \tlength,\n",
            "and            \t[PAD]     \tand\n",
            "it's           \t[PAD]     \tit's\n",
            "a              \t[PAD]     \ta\n",
            "degenerate     \t[PAD]     \tdegenerate\n",
            "process        \t,         \tprocess,\n",
            "so             \t[PAD]     \tso\n",
            "the            \t[PAD]     \tthe\n",
            "longer         \t[PAD]     \tlonger\n",
            "you            \t[PAD]     \tyou\n",
            "make           \t[PAD]     \tmake\n",
            "the            \t[PAD]     \tthe\n",
            "piece          \t,         \tpiece,\n",
            "the            \t[PAD]     \tthe\n",
            "more           \t[PAD]     \tmore\n",
            "errors         \t[PAD]     \terrors\n",
            "there          \t[PAD]     \tthere\n",
            "are            \t/         \tare/\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "had            \t[PAD]     \thad\n",
            "to             \t[PAD]     \tto\n",
            "create         \t[PAD]     \tcreate\n",
            "a              \t[PAD]     \ta\n",
            "new            \t[PAD]     \tnew\n",
            "method         \t[PAD]     \tmethod\n",
            "for            \t[PAD]     \tfor\n",
            "putting        \t[PAD]     \tputting\n",
            "these          \t[PAD]     \tthese\n",
            "little         \t[PAD]     \tlittle\n",
            "pieces         \t[PAD]     \tpieces\n",
            "together       \t[PAD]     \ttogether\n",
            "and            \t[PAD]     \tand\n",
            "correct        \t[PAD]     \tcorrect\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "errors         \t/         \terrors/\n",
            "and            \t[PAD]     \tand\n",
            "this           \t[PAD]     \tthis\n",
            "was            \t[PAD]     \twas\n",
            "our            \t[PAD]     \tour\n",
            "first          \t[PAD]     \tfirst\n",
            "attempt        \t,         \tattempt,\n",
            "starting       \t[PAD]     \tstarting\n",
            "with           \t[PAD]     \twith\n",
            "the            \t[PAD]     \tthe\n",
            "digital        \t[PAD]     \tdigital\n",
            "information    \t[PAD]     \tinformation\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "genome         \t[PAD]     \tgenome\n",
            "of             \t[PAD]     \tof\n",
            "phi            \t[PAD]     \tphi\n",
            "x              \t[PAD]     \tx\n",
            "174            \t/         \t174/\n",
            "it's           \t[PAD]     \tit's\n",
            "a              \t[PAD]     \ta\n",
            "small          \t[PAD]     \tsmall\n",
            "virus          \t[PAD]     \tvirus\n",
            "that           \t[PAD]     \tthat\n",
            "kills          \t[PAD]     \tkills\n",
            "bacteria       \t/         \tbacteria/\n",
            "we             \t[PAD]     \twe\n",
            "designed       \t[PAD]     \tdesigned\n",
            "the            \t[PAD]     \tthe\n",
            "pieces         \t,         \tpieces,\n",
            "went           \t[PAD]     \twent\n",
            "through        \t[PAD]     \tthrough\n",
            "our            \t[PAD]     \tour\n",
            "error          \t[PAD]     \terror\n",
            "correction     \t,         \tcorrection,\n",
            "and            \t[PAD]     \tand\n",
            "had            \t[PAD]     \thad\n",
            "a              \t[PAD]     \ta\n",
            "dna            \t[PAD]     \tdna\n",
            "molecule       \t[PAD]     \tmolecule\n",
            "of             \t[PAD]     \tof\n",
            "about          \t[PAD]     \tabout\n",
            "5, 000         \t[PAD]     \t5,000\n",
            "letters        \t/         \tletters/\n",
            "the            \t[PAD]     \tthe\n",
            "exciting       \t[PAD]     \texciting\n",
            "phase          \t[PAD]     \tphase\n",
            "came           \t[PAD]     \tcame\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "took           \t[PAD]     \ttook\n",
            "this           \t[PAD]     \tthis\n",
            "piece          \t[PAD]     \tpiece\n",
            "of             \t[PAD]     \tof\n",
            "inert          \t[PAD]     \tinert\n",
            "chemical       \t[PAD]     \tchemical\n",
            "and            \t[PAD]     \tand\n",
            "put            \t[PAD]     \tput\n",
            "it             \t[PAD]     \tit\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "bacteria       \t,         \tbacteria,\n",
            "and            \t[PAD]     \tand\n",
            "the            \t[PAD]     \tthe\n",
            "bacteria       \t[PAD]     \tbacteria\n",
            "started        \t[PAD]     \tstarted\n",
            "to             \t[PAD]     \tto\n",
            "read           \t[PAD]     \tread\n",
            "this           \t[PAD]     \tthis\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t,         \tcode,\n",
            "made           \t[PAD]     \tmade\n",
            "the            \t[PAD]     \tthe\n",
            "viral          \t[PAD]     \tviral\n",
            "particles      \t/         \tparticles/\n",
            "the            \t[PAD]     \tthe\n",
            "viral          \t[PAD]     \tviral\n",
            "particles      \t[PAD]     \tparticles\n",
            "then           \t[PAD]     \tthen\n",
            "were           \t[PAD]     \twere\n",
            "released       \t[PAD]     \treleased\n",
            "from           \t[PAD]     \tfrom\n",
            "the            \t[PAD]     \tthe\n",
            "cells          \t,         \tcells,\n",
            "then           \t[PAD]     \tthen\n",
            "came           \t[PAD]     \tcame\n",
            "back           \t[PAD]     \tback\n",
            "and            \t[PAD]     \tand\n",
            "killed         \t[PAD]     \tkilled\n",
            "the            \t[PAD]     \tthe\n",
            "e              \t/         \te/\n",
            "coli           \t/         \tcoli/\n",
            "i              \t[PAD]     \ti\n",
            "was            \t[PAD]     \twas\n",
            "talking        \t[PAD]     \ttalking\n",
            "to             \t[PAD]     \tto\n",
            "the            \t[PAD]     \tthe\n",
            "oil            \t[PAD]     \toil\n",
            "industry       \t[PAD]     \tindustry\n",
            "recently       \t,         \trecently,\n",
            "and            \t[PAD]     \tand\n",
            "i              \t[PAD]     \ti\n",
            "said           \t[PAD]     \tsaid\n",
            "they           \t[PAD]     \tthey\n",
            "clearly        \t[PAD]     \tclearly\n",
            "understood     \t[PAD]     \tunderstood\n",
            "that           \t[PAD]     \tthat\n",
            "model          \t/         \tmodel/\n",
            "they           \t[PAD]     \tthey\n",
            "laughed        \t[PAD]     \tlaughed\n",
            "more           \t[PAD]     \tmore\n",
            "than           \t[PAD]     \tthan\n",
            "you            \t[PAD]     \tyou\n",
            "guys           \t[PAD]     \tguys\n",
            "are            \t/         \tare/\n",
            "and            \t[PAD]     \tand\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "think          \t[PAD]     \tthink\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "a              \t[PAD]     \ta\n",
            "situation      \t[PAD]     \tsituation\n",
            "where          \t[PAD]     \twhere\n",
            "the            \t[PAD]     \tthe\n",
            "software       \t[PAD]     \tsoftware\n",
            "can            \t[PAD]     \tcan\n",
            "actually       \t[PAD]     \tactually\n",
            "build          \t[PAD]     \tbuild\n",
            "its            \t[PAD]     \tits\n",
            "own            \t[PAD]     \town\n",
            "hardware       \t[PAD]     \thardware\n",
            "in             \t[PAD]     \tin\n",
            "a              \t[PAD]     \ta\n",
            "biological     \t[PAD]     \tbiological\n",
            "system         \t/         \tsystem/\n",
            "but            \t[PAD]     \tbut\n",
            "we             \t[PAD]     \twe\n",
            "wanted         \t[PAD]     \twanted\n",
            "to             \t[PAD]     \tto\n",
            "go             \t[PAD]     \tgo\n",
            "much           \t[PAD]     \tmuch\n",
            "larger         \t/         \tlarger/\n",
            "we             \t[PAD]     \twe\n",
            "wanted         \t[PAD]     \twanted\n",
            "to             \t[PAD]     \tto\n",
            "build          \t[PAD]     \tbuild\n",
            "the            \t[PAD]     \tthe\n",
            "entire         \t[PAD]     \tentire\n",
            "bacterial      \t[PAD]     \tbacterial\n",
            "chromosome     \t/         \tchromosome/\n",
            "it's           \t[PAD]     \tit's\n",
            "over           \t[PAD]     \tover\n",
            "580, 000       \t[PAD]     \t580,000\n",
            "letters        \t[PAD]     \tletters\n",
            "of             \t[PAD]     \tof\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t/         \tcode/\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "thought        \t[PAD]     \tthought\n",
            "we'd           \t[PAD]     \twe'd\n",
            "build          \t[PAD]     \tbuild\n",
            "them           \t[PAD]     \tthem\n",
            "in             \t[PAD]     \tin\n",
            "cassettes      \t[PAD]     \tcassettes\n",
            "the            \t[PAD]     \tthe\n",
            "size           \t[PAD]     \tsize\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "viruses        \t,         \tviruses,\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "could          \t[PAD]     \tcould\n",
            "actually       \t[PAD]     \tactually\n",
            "vary           \t[PAD]     \tvary\n",
            "the            \t[PAD]     \tthe\n",
            "cassettes      \t[PAD]     \tcassettes\n",
            "to             \t[PAD]     \tto\n",
            "understand     \t[PAD]     \tunderstand\n",
            "what           \t[PAD]     \twhat\n",
            "the            \t[PAD]     \tthe\n",
            "actual         \t[PAD]     \tactual\n",
            "components     \t[PAD]     \tcomponents\n",
            "of             \t[PAD]     \tof\n",
            "a              \t[PAD]     \ta\n",
            "living         \t[PAD]     \tliving\n",
            "cell           \t[PAD]     \tcell\n",
            "are            \t/         \tare/\n",
            "design         \t[PAD]     \tdesign\n",
            "is             \t[PAD]     \tis\n",
            "critical       \t,         \tcritical,\n",
            "and            \t[PAD]     \tand\n",
            "if             \t[PAD]     \tif\n",
            "you're         \t[PAD]     \tyou're\n",
            "starting       \t[PAD]     \tstarting\n",
            "with           \t[PAD]     \twith\n",
            "digital        \t[PAD]     \tdigital\n",
            "information    \t[PAD]     \tinformation\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "computer       \t,         \tcomputer,\n",
            "that           \t[PAD]     \tthat\n",
            "digital        \t[PAD]     \tdigital\n",
            "information    \t[PAD]     \tinformation\n",
            "has            \t[PAD]     \thas\n",
            "to             \t[PAD]     \tto\n",
            "be             \t[PAD]     \tbe\n",
            "really         \t[PAD]     \treally\n",
            "accurate       \t/         \taccurate/\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "first          \t[PAD]     \tfirst\n",
            "sequenced      \t[PAD]     \tsequenced\n",
            "this           \t[PAD]     \tthis\n",
            "genome         \t[PAD]     \tgenome\n",
            "in             \t[PAD]     \tin\n",
            "1995           \t,         \t1995,\n",
            "the            \t[PAD]     \tthe\n",
            "standard       \t[PAD]     \tstandard\n",
            "of             \t[PAD]     \tof\n",
            "accuracy       \t[PAD]     \taccuracy\n",
            "was            \t[PAD]     \twas\n",
            "one            \t[PAD]     \tone\n",
            "error          \t[PAD]     \terror\n",
            "per            \t[PAD]     \tper\n",
            "10, 000        \t[PAD]     \t10,000\n",
            "base           \t[PAD]     \tbase\n",
            "pairs          \t/         \tpairs/\n",
            "we             \t[PAD]     \twe\n",
            "actually       \t[PAD]     \tactually\n",
            "found          \t,         \tfound,\n",
            "on             \t[PAD]     \ton\n",
            "resequencing   \t[PAD]     \tresequencing\n",
            "it             \t,         \tit,\n",
            "30             \t[PAD]     \t30\n",
            "errors         \t/         \terrors/\n",
            "had            \t[PAD]     \thad\n",
            "we             \t[PAD]     \twe\n",
            "used           \t[PAD]     \tused\n",
            "that           \t[PAD]     \tthat\n",
            "original       \t[PAD]     \toriginal\n",
            "sequence       \t,         \tsequence,\n",
            "it             \t[PAD]     \tit\n",
            "never          \t[PAD]     \tnever\n",
            "would          \t[PAD]     \twould\n",
            "have           \t[PAD]     \thave\n",
            "been           \t[PAD]     \tbeen\n",
            "able           \t[PAD]     \table\n",
            "to             \t[PAD]     \tto\n",
            "be             \t[PAD]     \tbe\n",
            "booted         \t[PAD]     \tbooted\n",
            "up             \t/         \tup/\n",
            "part           \t[PAD]     \tpart\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "design         \t[PAD]     \tdesign\n",
            "is             \t[PAD]     \tis\n",
            "designing      \t[PAD]     \tdesigning\n",
            "pieces         \t[PAD]     \tpieces\n",
            "that           \t[PAD]     \tthat\n",
            "are            \t[PAD]     \tare\n",
            "50             \t[PAD]     \t50\n",
            "letters        \t[PAD]     \tletters\n",
            "long           \t[PAD]     \tlong\n",
            "that           \t[PAD]     \tthat\n",
            "have           \t[PAD]     \thave\n",
            "to             \t[PAD]     \tto\n",
            "overlap        \t[PAD]     \toverlap\n",
            "with           \t[PAD]     \twith\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "other          \t[PAD]     \tother\n",
            "50 - letter    \t[PAD]     \t50-letter\n",
            "pieces         \t[PAD]     \tpieces\n",
            "to             \t[PAD]     \tto\n",
            "build          \t[PAD]     \tbuild\n",
            "smaller        \t[PAD]     \tsmaller\n",
            "sub            \t[PAD]     \tsub\n",
            "units          \t[PAD]     \tunits\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "to             \t[PAD]     \tto\n",
            "design         \t[PAD]     \tdesign\n",
            "so             \t[PAD]     \tso\n",
            "they           \t[PAD]     \tthey\n",
            "can            \t[PAD]     \tcan\n",
            "go             \t[PAD]     \tgo\n",
            "together       \t/         \ttogether/\n",
            "we             \t[PAD]     \twe\n",
            "design         \t[PAD]     \tdesign\n",
            "unique         \t[PAD]     \tunique\n",
            "elements       \t[PAD]     \telements\n",
            "into           \t[PAD]     \tinto\n",
            "this           \t/         \tthis/\n",
            "you            \t[PAD]     \tyou\n",
            "may            \t[PAD]     \tmay\n",
            "have           \t[PAD]     \thave\n",
            "read           \t[PAD]     \tread\n",
            "that           \t[PAD]     \tthat\n",
            "we             \t[PAD]     \twe\n",
            "put            \t[PAD]     \tput\n",
            "watermarks     \t[PAD]     \twatermarks\n",
            "in             \t/         \tin/\n",
            "think          \t[PAD]     \tthink\n",
            "of             \t[PAD]     \tof\n",
            "this           \t,         \tthis,\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "a              \t[PAD]     \ta\n",
            "four           \t[PAD]     \tfour\n",
            "letter         \t[PAD]     \tletter\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t,         \tcode,\n",
            "a              \t,         \ta,\n",
            "c              \t,         \tc,\n",
            "g              \t[PAD]     \tg\n",
            "and            \t[PAD]     \tand\n",
            "t              \t/         \tt/\n",
            "triplets       \t[PAD]     \ttriplets\n",
            "of             \t[PAD]     \tof\n",
            "that           \t[PAD]     \tthat\n",
            "letter         \t,         \tletter,\n",
            "those          \t[PAD]     \tthose\n",
            "letters        \t[PAD]     \tletters\n",
            "code           \t[PAD]     \tcode\n",
            "for            \t[PAD]     \tfor\n",
            "roughly        \t[PAD]     \troughly\n",
            "20             \t[PAD]     \t20\n",
            "amino          \t[PAD]     \tamino\n",
            "acids          \t,         \tacids,\n",
            "that           \t[PAD]     \tthat\n",
            "there's        \t[PAD]     \tthere's\n",
            "a              \t[PAD]     \ta\n",
            "single         \t[PAD]     \tsingle\n",
            "letter         \t[PAD]     \tletter\n",
            "designation    \t[PAD]     \tdesignation\n",
            "for            \t[PAD]     \tfor\n",
            "each           \t[PAD]     \teach\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "amino          \t[PAD]     \tamino\n",
            "acids          \t/         \tacids/\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "use            \t[PAD]     \tuse\n",
            "the            \t[PAD]     \tthe\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t[PAD]     \tcode\n",
            "to             \t[PAD]     \tto\n",
            "write          \t[PAD]     \twrite\n",
            "out            \t[PAD]     \tout\n",
            "words          \t,         \twords,\n",
            "sentences      \t,         \tsentences,\n",
            "thoughts       \t/         \tthoughts/\n",
            "initially      \t,         \tinitially,\n",
            "all            \t[PAD]     \tall\n",
            "we             \t[PAD]     \twe\n",
            "did            \t[PAD]     \tdid\n",
            "was            \t[PAD]     \twas\n",
            "autograph      \t[PAD]     \tautograph\n",
            "it             \t/         \tit/\n",
            "some           \t[PAD]     \tsome\n",
            "people         \t[PAD]     \tpeople\n",
            "were           \t[PAD]     \twere\n",
            "disappointed   \t[PAD]     \tdisappointed\n",
            "there          \t[PAD]     \tthere\n",
            "was            \t[PAD]     \twas\n",
            "not            \t[PAD]     \tnot\n",
            "poetry         \t/         \tpoetry/\n",
            "we             \t[PAD]     \twe\n",
            "designed       \t[PAD]     \tdesigned\n",
            "these          \t[PAD]     \tthese\n",
            "pieces         \t[PAD]     \tpieces\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "just           \t[PAD]     \tjust\n",
            "chew           \t[PAD]     \tchew\n",
            "back           \t[PAD]     \tback\n",
            "with           \t[PAD]     \twith\n",
            "enzymes        \t/         \tenzymes/\n",
            "there's        \t[PAD]     \tthere's\n",
            "enzymes        \t[PAD]     \tenzymes\n",
            "that           \t[PAD]     \tthat\n",
            "repair         \t[PAD]     \trepair\n",
            "them           \t[PAD]     \tthem\n",
            "and            \t[PAD]     \tand\n",
            "put            \t[PAD]     \tput\n",
            "them           \t[PAD]     \tthem\n",
            "together       \t/         \ttogether/\n",
            "and            \t[PAD]     \tand\n",
            "we             \t[PAD]     \twe\n",
            "started        \t[PAD]     \tstarted\n",
            "making         \t[PAD]     \tmaking\n",
            "pieces         \t,         \tpieces,\n",
            "starting       \t[PAD]     \tstarting\n",
            "with           \t[PAD]     \twith\n",
            "pieces         \t[PAD]     \tpieces\n",
            "that           \t[PAD]     \tthat\n",
            "were           \t[PAD]     \twere\n",
            "five           \t[PAD]     \tfive\n",
            "to             \t[PAD]     \tto\n",
            "7, 000         \t[PAD]     \t7,000\n",
            "letters        \t,         \tletters,\n",
            "fit            \t[PAD]     \tfit\n",
            "those          \t[PAD]     \tthose\n",
            "together       \t[PAD]     \ttogether\n",
            "to             \t[PAD]     \tto\n",
            "make           \t[PAD]     \tmake\n",
            "24, 000 - letter\t[PAD]     \t24,000-letter\n",
            "pieces         \t,         \tpieces,\n",
            "then           \t[PAD]     \tthen\n",
            "put            \t[PAD]     \tput\n",
            "sets           \t[PAD]     \tsets\n",
            "of             \t[PAD]     \tof\n",
            "those          \t,         \tthose,\n",
            "going          \t[PAD]     \tgoing\n",
            "up             \t[PAD]     \tup\n",
            "to             \t[PAD]     \tto\n",
            "72, 000        \t/         \t72,000/\n",
            "at             \t[PAD]     \tat\n",
            "each           \t[PAD]     \teach\n",
            "stage          \t,         \tstage,\n",
            "we             \t[PAD]     \twe\n",
            "grew           \t[PAD]     \tgrew\n",
            "up             \t[PAD]     \tup\n",
            "these          \t[PAD]     \tthese\n",
            "pieces         \t[PAD]     \tpieces\n",
            "in             \t[PAD]     \tin\n",
            "abundance      \t[PAD]     \tabundance\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "could          \t[PAD]     \tcould\n",
            "sequence       \t[PAD]     \tsequence\n",
            "them           \t[PAD]     \tthem\n",
            "because        \t[PAD]     \tbecause\n",
            "we're          \t[PAD]     \twe're\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "create         \t[PAD]     \tcreate\n",
            "a              \t[PAD]     \ta\n",
            "process        \t[PAD]     \tprocess\n",
            "that's         \t[PAD]     \tthat's\n",
            "extremely      \t[PAD]     \textremely\n",
            "robust         \t,         \trobust,\n",
            "that           \t[PAD]     \tthat\n",
            "you            \t[PAD]     \tyou\n",
            "can            \t[PAD]     \tcan\n",
            "see            \t[PAD]     \tsee\n",
            "in             \t[PAD]     \tin\n",
            "a              \t[PAD]     \ta\n",
            "minute         \t/         \tminute/\n",
            "we're          \t[PAD]     \twe're\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "get            \t[PAD]     \tget\n",
            "to             \t[PAD]     \tto\n",
            "the            \t[PAD]     \tthe\n",
            "point          \t[PAD]     \tpoint\n",
            "of             \t[PAD]     \tof\n",
            "automation     \t/         \tautomation/\n",
            "so             \t,         \tso,\n",
            "this           \t[PAD]     \tthis\n",
            "looks          \t[PAD]     \tlooks\n",
            "like           \t[PAD]     \tlike\n",
            "a              \t[PAD]     \ta\n",
            "basketball     \t[PAD]     \tbasketball\n",
            "playoff        \t/         \tplayoff/\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "get            \t[PAD]     \tget\n",
            "into           \t[PAD]     \tinto\n",
            "these          \t[PAD]     \tthese\n",
            "really         \t[PAD]     \treally\n",
            "large          \t[PAD]     \tlarge\n",
            "pieces         \t,         \tpieces,\n",
            "over           \t[PAD]     \tover\n",
            "100, 000       \t[PAD]     \t100,000\n",
            "base           \t[PAD]     \tbase\n",
            "pairs          \t,         \tpairs,\n",
            "they           \t[PAD]     \tthey\n",
            "won't          \t[PAD]     \twon't\n",
            "any            \t[PAD]     \tany\n",
            "longer         \t[PAD]     \tlonger\n",
            "grow           \t[PAD]     \tgrow\n",
            "readily        \t[PAD]     \treadily\n",
            "in             \t[PAD]     \tin\n",
            "e              \t/         \te/\n",
            "coli           \t/         \tcoli/\n",
            "it             \t[PAD]     \tit\n",
            "exhausts       \t[PAD]     \texhausts\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "modern         \t[PAD]     \tmodern\n",
            "tools          \t[PAD]     \ttools\n",
            "of             \t[PAD]     \tof\n",
            "molecular      \t[PAD]     \tmolecular\n",
            "biology        \t/         \tbiology/\n",
            "and            \t[PAD]     \tand\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "turned         \t[PAD]     \tturned\n",
            "to             \t[PAD]     \tto\n",
            "other          \t[PAD]     \tother\n",
            "mechanisms     \t/         \tmechanisms/\n",
            "we             \t[PAD]     \twe\n",
            "knew           \t[PAD]     \tknew\n",
            "there's        \t[PAD]     \tthere's\n",
            "a              \t[PAD]     \ta\n",
            "mechanism      \t[PAD]     \tmechanism\n",
            "called         \t[PAD]     \tcalled\n",
            "homologous     \t[PAD]     \thomologous\n",
            "recombination  \t,         \trecombination,\n",
            "that           \t[PAD]     \tthat\n",
            "biology        \t[PAD]     \tbiology\n",
            "uses           \t[PAD]     \tuses\n",
            "to             \t[PAD]     \tto\n",
            "repair         \t[PAD]     \trepair\n",
            "dna            \t,         \tdna,\n",
            "that           \t[PAD]     \tthat\n",
            "can            \t[PAD]     \tcan\n",
            "put            \t[PAD]     \tput\n",
            "pieces         \t[PAD]     \tpieces\n",
            "together       \t/         \ttogether/\n",
            "here's         \t[PAD]     \there's\n",
            "an             \t[PAD]     \tan\n",
            "example        \t[PAD]     \texample\n",
            "of             \t[PAD]     \tof\n",
            "it             \t/         \tit/\n",
            "there's        \t[PAD]     \tthere's\n",
            "an             \t[PAD]     \tan\n",
            "organism       \t[PAD]     \torganism\n",
            "called         \t[PAD]     \tcalled\n",
            "deinococcus    \t[PAD]     \tdeinococcus\n",
            "radiodurans    \t[PAD]     \tradiodurans\n",
            "that           \t[PAD]     \tthat\n",
            "can            \t[PAD]     \tcan\n",
            "take           \t[PAD]     \ttake\n",
            "three          \t[PAD]     \tthree\n",
            "millions       \t[PAD]     \tmillions\n",
            "rads           \t[PAD]     \trads\n",
            "of             \t[PAD]     \tof\n",
            "radiation      \t/         \tradiation/\n",
            "you            \t[PAD]     \tyou\n",
            "can            \t[PAD]     \tcan\n",
            "see            \t[PAD]     \tsee\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "top            \t[PAD]     \ttop\n",
            "panel          \t,         \tpanel,\n",
            "its            \t[PAD]     \tits\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "just           \t[PAD]     \tjust\n",
            "gets           \t[PAD]     \tgets\n",
            "blown          \t[PAD]     \tblown\n",
            "apart          \t/         \tapart/\n",
            "12             \t[PAD]     \t12\n",
            "to             \t[PAD]     \tto\n",
            "24             \t[PAD]     \t24\n",
            "hours          \t[PAD]     \thours\n",
            "later          \t,         \tlater,\n",
            "it             \t[PAD]     \tit\n",
            "put            \t[PAD]     \tput\n",
            "it             \t[PAD]     \tit\n",
            "back           \t[PAD]     \tback\n",
            "together       \t[PAD]     \ttogether\n",
            "exactly        \t[PAD]     \texactly\n",
            "as             \t[PAD]     \tas\n",
            "it             \t[PAD]     \tit\n",
            "was            \t[PAD]     \twas\n",
            "before         \t/         \tbefore/\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "thousands      \t[PAD]     \tthousands\n",
            "of             \t[PAD]     \tof\n",
            "organisms      \t[PAD]     \torganisms\n",
            "that           \t[PAD]     \tthat\n",
            "can            \t[PAD]     \tcan\n",
            "do             \t[PAD]     \tdo\n",
            "this           \t/         \tthis/\n",
            "these          \t[PAD]     \tthese\n",
            "organisms      \t[PAD]     \torganisms\n",
            "can            \t[PAD]     \tcan\n",
            "be             \t[PAD]     \tbe\n",
            "totally        \t[PAD]     \ttotally\n",
            "desiccated     \t/         \tdesiccated/\n",
            "they           \t[PAD]     \tthey\n",
            "can            \t[PAD]     \tcan\n",
            "live           \t[PAD]     \tlive\n",
            "in             \t[PAD]     \tin\n",
            "a              \t[PAD]     \ta\n",
            "vacuum         \t/         \tvacuum/\n",
            "i              \t[PAD]     \ti\n",
            "am             \t[PAD]     \tam\n",
            "absolutely     \t[PAD]     \tabsolutely\n",
            "certain        \t[PAD]     \tcertain\n",
            "that           \t[PAD]     \tthat\n",
            "life           \t[PAD]     \tlife\n",
            "can            \t[PAD]     \tcan\n",
            "exist          \t[PAD]     \texist\n",
            "in             \t[PAD]     \tin\n",
            "outer          \t[PAD]     \touter\n",
            "space          \t,         \tspace,\n",
            "move           \t[PAD]     \tmove\n",
            "around         \t,         \taround,\n",
            "find           \t[PAD]     \tfind\n",
            "a              \t[PAD]     \ta\n",
            "new            \t[PAD]     \tnew\n",
            "aqueous        \t[PAD]     \taqueous\n",
            "environment    \t/         \tenvironment/\n",
            "in             \t[PAD]     \tin\n",
            "fact           \t,         \tfact,\n",
            "nasa           \t[PAD]     \tnasa\n",
            "has            \t[PAD]     \thas\n",
            "shown          \t[PAD]     \tshown\n",
            "a              \t[PAD]     \ta\n",
            "lot            \t[PAD]     \tlot\n",
            "of             \t[PAD]     \tof\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "out            \t[PAD]     \tout\n",
            "there          \t/         \tthere/\n",
            "here's         \t[PAD]     \there's\n",
            "an             \t[PAD]     \tan\n",
            "actual         \t[PAD]     \tactual\n",
            "micrograph     \t[PAD]     \tmicrograph\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "molecule       \t[PAD]     \tmolecule\n",
            "we             \t[PAD]     \twe\n",
            "built          \t[PAD]     \tbuilt\n",
            "using          \t[PAD]     \tusing\n",
            "these          \t[PAD]     \tthese\n",
            "processes      \t,         \tprocesses,\n",
            "actually       \t[PAD]     \tactually\n",
            "just           \t[PAD]     \tjust\n",
            "using          \t[PAD]     \tusing\n",
            "yeast          \t[PAD]     \tyeast\n",
            "mechanisms     \t[PAD]     \tmechanisms\n",
            "with           \t[PAD]     \twith\n",
            "the            \t[PAD]     \tthe\n",
            "right          \t[PAD]     \tright\n",
            "design         \t[PAD]     \tdesign\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "pieces         \t[PAD]     \tpieces\n",
            "we             \t[PAD]     \twe\n",
            "put            \t[PAD]     \tput\n",
            "them           \t[PAD]     \tthem\n",
            "in             \t/         \tin/\n",
            "yeast          \t[PAD]     \tyeast\n",
            "puts           \t[PAD]     \tputs\n",
            "them           \t[PAD]     \tthem\n",
            "together       \t[PAD]     \ttogether\n",
            "automatically  \t/         \tautomatically/\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "not            \t[PAD]     \tnot\n",
            "an             \t[PAD]     \tan\n",
            "electron       \t[PAD]     \telectron\n",
            "micrograph     \t.         \tmicrograph.\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "just           \t[PAD]     \tjust\n",
            "a              \t[PAD]     \ta\n",
            "regular        \t[PAD]     \tregular\n",
            "photomicrograph\t/         \tphotomicrograph/\n",
            "it's           \t[PAD]     \tit's\n",
            "such           \t[PAD]     \tsuch\n",
            "a              \t[PAD]     \ta\n",
            "large          \t[PAD]     \tlarge\n",
            "molecule       \t[PAD]     \tmolecule\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "see            \t[PAD]     \tsee\n",
            "it             \t[PAD]     \tit\n",
            "with           \t[PAD]     \twith\n",
            "a              \t[PAD]     \ta\n",
            "light          \t[PAD]     \tlight\n",
            "microscope     \t/         \tmicroscope/\n",
            "these          \t[PAD]     \tthese\n",
            "are            \t[PAD]     \tare\n",
            "pictures       \t[PAD]     \tpictures\n",
            "over           \t[PAD]     \tover\n",
            "about          \t[PAD]     \tabout\n",
            "a              \t[PAD]     \ta\n",
            "six            \t[PAD]     \tsix\n",
            "second         \t[PAD]     \tsecond\n",
            "period         \t/         \tperiod/\n",
            "so             \t[PAD]     \tso\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "the            \t[PAD]     \tthe\n",
            "publication    \t[PAD]     \tpublication\n",
            "we             \t[PAD]     \twe\n",
            "had            \t[PAD]     \thad\n",
            "just           \t[PAD]     \tjust\n",
            "a              \t[PAD]     \ta\n",
            "short          \t[PAD]     \tshort\n",
            "while          \t[PAD]     \twhile\n",
            "ago            \t/         \tago/\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "over           \t[PAD]     \tover\n",
            "580, 000       \t[PAD]     \t580,000\n",
            "letters        \t[PAD]     \tletters\n",
            "of             \t[PAD]     \tof\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t/         \tcode/\n",
            "it's           \t[PAD]     \tit's\n",
            "the            \t[PAD]     \tthe\n",
            "largest        \t[PAD]     \tlargest\n",
            "molecule       \t[PAD]     \tmolecule\n",
            "ever           \t[PAD]     \tever\n",
            "made           \t[PAD]     \tmade\n",
            "by             \t[PAD]     \tby\n",
            "humans         \t[PAD]     \thumans\n",
            "of             \t[PAD]     \tof\n",
            "a              \t[PAD]     \ta\n",
            "defined        \t[PAD]     \tdefined\n",
            "structure      \t/         \tstructure/\n",
            "it's           \t[PAD]     \tit's\n",
            "over           \t[PAD]     \tover\n",
            "300            \t[PAD]     \t300\n",
            "million        \t[PAD]     \tmillion\n",
            "molecular      \t[PAD]     \tmolecular\n",
            "weight         \t/         \tweight/\n",
            "if             \t[PAD]     \tif\n",
            "we             \t[PAD]     \twe\n",
            "printed        \t[PAD]     \tprinted\n",
            "out            \t[PAD]     \tout\n",
            "at             \t[PAD]     \tat\n",
            "a              \t[PAD]     \ta\n",
            "10             \t[PAD]     \t10\n",
            "font           \t[PAD]     \tfont\n",
            "with           \t[PAD]     \twith\n",
            "no             \t[PAD]     \tno\n",
            "spacing        \t,         \tspacing,\n",
            "it             \t[PAD]     \tit\n",
            "takes          \t[PAD]     \ttakes\n",
            "142            \t[PAD]     \t142\n",
            "pages          \t[PAD]     \tpages\n",
            "just           \t[PAD]     \tjust\n",
            "to             \t[PAD]     \tto\n",
            "print          \t[PAD]     \tprint\n",
            "this           \t[PAD]     \tthis\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t/         \tcode/\n",
            "well           \t,         \twell,\n",
            "how            \t[PAD]     \thow\n",
            "do             \t[PAD]     \tdo\n",
            "we             \t[PAD]     \twe\n",
            "boot           \t[PAD]     \tboot\n",
            "up             \t[PAD]     \tup\n",
            "a              \t[PAD]     \ta\n",
            "chromosome     \t/         \tchromosome/\n",
            "how            \t[PAD]     \thow\n",
            "do             \t[PAD]     \tdo\n",
            "we             \t[PAD]     \twe\n",
            "activate       \t[PAD]     \tactivate\n",
            "this           \t/         \tthis/\n",
            "obviously      \t,         \tobviously,\n",
            "with           \t[PAD]     \twith\n",
            "a              \t[PAD]     \ta\n",
            "virus          \t[PAD]     \tvirus\n",
            "it's           \t[PAD]     \tit's\n",
            "pretty         \t[PAD]     \tpretty\n",
            "simple         \t/         \tsimple/\n",
            "it's           \t[PAD]     \tit's\n",
            "much           \t[PAD]     \tmuch\n",
            "more           \t[PAD]     \tmore\n",
            "complicated    \t[PAD]     \tcomplicated\n",
            "dealing        \t[PAD]     \tdealing\n",
            "with           \t[PAD]     \twith\n",
            "bacteria       \t/         \tbacteria/\n",
            "it's           \t[PAD]     \tit's\n",
            "also           \t[PAD]     \talso\n",
            "simpler        \t[PAD]     \tsimpler\n",
            "when           \t[PAD]     \twhen\n",
            "you            \t[PAD]     \tyou\n",
            "go             \t[PAD]     \tgo\n",
            "into           \t[PAD]     \tinto\n",
            "eukaryotes     \t[PAD]     \teukaryotes\n",
            "like           \t[PAD]     \tlike\n",
            "ourselves      \t,         \tourselves,\n",
            "you            \t[PAD]     \tyou\n",
            "can            \t[PAD]     \tcan\n",
            "just           \t[PAD]     \tjust\n",
            "pop            \t[PAD]     \tpop\n",
            "out            \t[PAD]     \tout\n",
            "the            \t[PAD]     \tthe\n",
            "nucleus        \t[PAD]     \tnucleus\n",
            "and            \t[PAD]     \tand\n",
            "pop            \t[PAD]     \tpop\n",
            "in             \t[PAD]     \tin\n",
            "another        \t[PAD]     \tanother\n",
            "one            \t,         \tone,\n",
            "and            \t[PAD]     \tand\n",
            "that's         \t[PAD]     \tthat's\n",
            "what           \t[PAD]     \twhat\n",
            "you've         \t[PAD]     \tyou've\n",
            "all            \t[PAD]     \tall\n",
            "heard          \t[PAD]     \theard\n",
            "about          \t[PAD]     \tabout\n",
            "with           \t[PAD]     \twith\n",
            "cloning        \t/         \tcloning/\n",
            "with           \t[PAD]     \twith\n",
            "bacteria       \t[PAD]     \tbacteria\n",
            "archaea        \t,         \tarchaea,\n",
            "the            \t[PAD]     \tthe\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "is             \t[PAD]     \tis\n",
            "integrated     \t[PAD]     \tintegrated\n",
            "into           \t[PAD]     \tinto\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t,         \tcell,\n",
            "but            \t[PAD]     \tbut\n",
            "we             \t[PAD]     \twe\n",
            "recently       \t[PAD]     \trecently\n",
            "showed         \t[PAD]     \tshowed\n",
            "that           \t[PAD]     \tthat\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "do             \t[PAD]     \tdo\n",
            "a              \t[PAD]     \ta\n",
            "complete       \t[PAD]     \tcomplete\n",
            "transplant     \t[PAD]     \ttransplant\n",
            "of             \t[PAD]     \tof\n",
            "a              \t[PAD]     \ta\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "from           \t[PAD]     \tfrom\n",
            "one            \t[PAD]     \tone\n",
            "cell           \t[PAD]     \tcell\n",
            "to             \t[PAD]     \tto\n",
            "another        \t[PAD]     \tanother\n",
            "and            \t[PAD]     \tand\n",
            "activate       \t[PAD]     \tactivate\n",
            "it             \t/         \tit/\n",
            "we             \t[PAD]     \twe\n",
            "purified       \t[PAD]     \tpurified\n",
            "a              \t[PAD]     \ta\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "from           \t[PAD]     \tfrom\n",
            "one            \t[PAD]     \tone\n",
            "microbial      \t[PAD]     \tmicrobial\n",
            "species        \t/         \tspecies/\n",
            "roughly        \t,         \troughly,\n",
            "these          \t[PAD]     \tthese\n",
            "two            \t[PAD]     \ttwo\n",
            "are            \t[PAD]     \tare\n",
            "as             \t[PAD]     \tas\n",
            "distant        \t[PAD]     \tdistant\n",
            "as             \t[PAD]     \tas\n",
            "human          \t[PAD]     \thuman\n",
            "and            \t[PAD]     \tand\n",
            "mice           \t/         \tmice/\n",
            "we             \t[PAD]     \twe\n",
            "added          \t[PAD]     \tadded\n",
            "a              \t[PAD]     \ta\n",
            "few            \t[PAD]     \tfew\n",
            "extra          \t[PAD]     \textra\n",
            "genes          \t[PAD]     \tgenes\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "could          \t[PAD]     \tcould\n",
            "select         \t[PAD]     \tselect\n",
            "for            \t[PAD]     \tfor\n",
            "this           \t[PAD]     \tthis\n",
            "chromosome     \t/         \tchromosome/\n",
            "we             \t[PAD]     \twe\n",
            "digested       \t[PAD]     \tdigested\n",
            "it             \t[PAD]     \tit\n",
            "with           \t[PAD]     \twith\n",
            "enzymes        \t[PAD]     \tenzymes\n",
            "to             \t[PAD]     \tto\n",
            "kill           \t[PAD]     \tkill\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "proteins       \t/         \tproteins/\n",
            "and            \t[PAD]     \tand\n",
            "it             \t[PAD]     \tit\n",
            "was            \t[PAD]     \twas\n",
            "pretty         \t[PAD]     \tpretty\n",
            "stunning       \t[PAD]     \tstunning\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "put            \t[PAD]     \tput\n",
            "this           \t[PAD]     \tthis\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t,         \tcell,\n",
            "and            \t[PAD]     \tand\n",
            "you'll         \t[PAD]     \tyou'll\n",
            "appreciate     \t[PAD]     \tappreciate\n",
            "our            \t[PAD]     \tour\n",
            "very           \t[PAD]     \tvery\n",
            "sophisticated  \t[PAD]     \tsophisticated\n",
            "graphics       \t[PAD]     \tgraphics\n",
            "here           \t,         \there,\n",
            "the            \t[PAD]     \tthe\n",
            "new            \t[PAD]     \tnew\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "went           \t[PAD]     \twent\n",
            "into           \t[PAD]     \tinto\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t/         \tcell/\n",
            "in             \t[PAD]     \tin\n",
            "fact           \t,         \tfact,\n",
            "we             \t[PAD]     \twe\n",
            "thought        \t[PAD]     \tthought\n",
            "this           \t[PAD]     \tthis\n",
            "might          \t[PAD]     \tmight\n",
            "be             \t[PAD]     \tbe\n",
            "as             \t[PAD]     \tas\n",
            "far            \t[PAD]     \tfar\n",
            "as             \t[PAD]     \tas\n",
            "it             \t[PAD]     \tit\n",
            "went           \t,         \twent,\n",
            "but            \t[PAD]     \tbut\n",
            "we             \t[PAD]     \twe\n",
            "tried          \t[PAD]     \ttried\n",
            "to             \t[PAD]     \tto\n",
            "design         \t[PAD]     \tdesign\n",
            "the            \t[PAD]     \tthe\n",
            "process        \t[PAD]     \tprocess\n",
            "a              \t[PAD]     \ta\n",
            "little         \t[PAD]     \tlittle\n",
            "bit            \t[PAD]     \tbit\n",
            "further        \t/         \tfurther/\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "a              \t[PAD]     \ta\n",
            "major          \t[PAD]     \tmajor\n",
            "mechanism      \t[PAD]     \tmechanism\n",
            "of             \t[PAD]     \tof\n",
            "evolution      \t[PAD]     \tevolution\n",
            "right          \t[PAD]     \tright\n",
            "here           \t/         \there/\n",
            "we             \t[PAD]     \twe\n",
            "find           \t[PAD]     \tfind\n",
            "all            \t[PAD]     \tall\n",
            "kinds          \t[PAD]     \tkinds\n",
            "of             \t[PAD]     \tof\n",
            "species        \t[PAD]     \tspecies\n",
            "that           \t[PAD]     \tthat\n",
            "have           \t[PAD]     \thave\n",
            "taken          \t[PAD]     \ttaken\n",
            "up             \t[PAD]     \tup\n",
            "a              \t[PAD]     \ta\n",
            "second         \t[PAD]     \tsecond\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "or             \t[PAD]     \tor\n",
            "a              \t[PAD]     \ta\n",
            "third          \t[PAD]     \tthird\n",
            "one            \t[PAD]     \tone\n",
            "from           \t[PAD]     \tfrom\n",
            "somewhere      \t,         \tsomewhere,\n",
            "adding         \t[PAD]     \tadding\n",
            "thousands      \t[PAD]     \tthousands\n",
            "of             \t[PAD]     \tof\n",
            "new            \t[PAD]     \tnew\n",
            "traits         \t[PAD]     \ttraits\n",
            "in             \t[PAD]     \tin\n",
            "a              \t[PAD]     \ta\n",
            "second         \t[PAD]     \tsecond\n",
            "to             \t[PAD]     \tto\n",
            "that           \t[PAD]     \tthat\n",
            "species        \t/         \tspecies/\n",
            "so             \t[PAD]     \tso\n",
            "people         \t[PAD]     \tpeople\n",
            "who            \t[PAD]     \twho\n",
            "think          \t[PAD]     \tthink\n",
            "of             \t[PAD]     \tof\n",
            "evolution      \t[PAD]     \tevolution\n",
            "as             \t[PAD]     \tas\n",
            "just           \t[PAD]     \tjust\n",
            "one            \t[PAD]     \tone\n",
            "gene           \t[PAD]     \tgene\n",
            "changing       \t[PAD]     \tchanging\n",
            "at             \t[PAD]     \tat\n",
            "a              \t[PAD]     \ta\n",
            "time           \t[PAD]     \ttime\n",
            "have           \t[PAD]     \thave\n",
            "missed         \t[PAD]     \tmissed\n",
            "much           \t[PAD]     \tmuch\n",
            "of             \t[PAD]     \tof\n",
            "biology        \t/         \tbiology/\n",
            "there's        \t[PAD]     \tthere's\n",
            "enzymes        \t[PAD]     \tenzymes\n",
            "called         \t[PAD]     \tcalled\n",
            "restriction    \t[PAD]     \trestriction\n",
            "enzymes        \t[PAD]     \tenzymes\n",
            "that           \t[PAD]     \tthat\n",
            "actually       \t[PAD]     \tactually\n",
            "digest         \t[PAD]     \tdigest\n",
            "dna            \t/         \tdna/\n",
            "the            \t[PAD]     \tthe\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "that           \t[PAD]     \tthat\n",
            "was            \t[PAD]     \twas\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t[PAD]     \tcell\n",
            "doesn't        \t[PAD]     \tdoesn't\n",
            "have           \t[PAD]     \thave\n",
            "one            \t/         \tone/\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t,         \tcell,\n",
            "the            \t[PAD]     \tthe\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "we             \t[PAD]     \twe\n",
            "put            \t[PAD]     \tput\n",
            "in             \t,         \tin,\n",
            "does           \t/         \tdoes/\n",
            "it             \t[PAD]     \tit\n",
            "got            \t[PAD]     \tgot\n",
            "expressed      \t,         \texpressed,\n",
            "and            \t[PAD]     \tand\n",
            "it             \t[PAD]     \tit\n",
            "recognized     \t[PAD]     \trecognized\n",
            "the            \t[PAD]     \tthe\n",
            "other          \t[PAD]     \tother\n",
            "chromosome     \t[PAD]     \tchromosome\n",
            "as             \t[PAD]     \tas\n",
            "foreign        \t[PAD]     \tforeign\n",
            "material       \t,         \tmaterial,\n",
            "chewed         \t[PAD]     \tchewed\n",
            "it             \t[PAD]     \tit\n",
            "up             \t,         \tup,\n",
            "and            \t[PAD]     \tand\n",
            "so             \t[PAD]     \tso\n",
            "we             \t[PAD]     \twe\n",
            "ended          \t[PAD]     \tended\n",
            "up             \t[PAD]     \tup\n",
            "just           \t[PAD]     \tjust\n",
            "with           \t[PAD]     \twith\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t[PAD]     \tcell\n",
            "with           \t[PAD]     \twith\n",
            "the            \t[PAD]     \tthe\n",
            "new            \t[PAD]     \tnew\n",
            "chromosome     \t/         \tchromosome/\n",
            "it             \t[PAD]     \tit\n",
            "turned         \t[PAD]     \tturned\n",
            "blue           \t[PAD]     \tblue\n",
            "because        \t[PAD]     \tbecause\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "genes          \t[PAD]     \tgenes\n",
            "we             \t[PAD]     \twe\n",
            "put            \t[PAD]     \tput\n",
            "in             \t[PAD]     \tin\n",
            "it             \t/         \tit/\n",
            "and            \t[PAD]     \tand\n",
            "with           \t[PAD]     \twith\n",
            "a              \t[PAD]     \ta\n",
            "very           \t[PAD]     \tvery\n",
            "short          \t[PAD]     \tshort\n",
            "period         \t[PAD]     \tperiod\n",
            "of             \t[PAD]     \tof\n",
            "time           \t,         \ttime,\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "characteristics\t[PAD]     \tcharacteristics\n",
            "of             \t[PAD]     \tof\n",
            "one            \t[PAD]     \tone\n",
            "species        \t[PAD]     \tspecies\n",
            "were           \t[PAD]     \twere\n",
            "lost           \t,         \tlost,\n",
            "and            \t[PAD]     \tand\n",
            "it             \t[PAD]     \tit\n",
            "converted      \t[PAD]     \tconverted\n",
            "totally        \t[PAD]     \ttotally\n",
            "into           \t[PAD]     \tinto\n",
            "the            \t[PAD]     \tthe\n",
            "new            \t[PAD]     \tnew\n",
            "species        \t,         \tspecies,\n",
            "based          \t[PAD]     \tbased\n",
            "on             \t[PAD]     \ton\n",
            "the            \t[PAD]     \tthe\n",
            "new            \t[PAD]     \tnew\n",
            "software       \t[PAD]     \tsoftware\n",
            "that           \t[PAD]     \tthat\n",
            "we             \t[PAD]     \twe\n",
            "put            \t[PAD]     \tput\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "cell           \t/         \tcell/\n",
            "all            \t[PAD]     \tall\n",
            "the            \t[PAD]     \tthe\n",
            "proteins       \t[PAD]     \tproteins\n",
            "changed        \t,         \tchanged,\n",
            "the            \t[PAD]     \tthe\n",
            "membranes      \t[PAD]     \tmembranes\n",
            "changed        \t,         \tchanged,\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "read           \t[PAD]     \tread\n",
            "the            \t[PAD]     \tthe\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t,         \tcode,\n",
            "it's           \t[PAD]     \tit's\n",
            "exactly        \t[PAD]     \texactly\n",
            "what           \t[PAD]     \twhat\n",
            "we             \t[PAD]     \twe\n",
            "had            \t[PAD]     \thad\n",
            "transferred    \t[PAD]     \ttransferred\n",
            "in             \t/         \tin/\n",
            "so             \t[PAD]     \tso\n",
            "this           \t[PAD]     \tthis\n",
            "may            \t[PAD]     \tmay\n",
            "sound          \t[PAD]     \tsound\n",
            "like           \t[PAD]     \tlike\n",
            "genomic        \t[PAD]     \tgenomic\n",
            "alchemy        \t,         \talchemy,\n",
            "but            \t[PAD]     \tbut\n",
            "we             \t[PAD]     \twe\n",
            "can            \t,         \tcan,\n",
            "by             \t[PAD]     \tby\n",
            "moving         \t[PAD]     \tmoving\n",
            "the            \t[PAD]     \tthe\n",
            "software       \t[PAD]     \tsoftware\n",
            "dna            \t[PAD]     \tdna\n",
            "around         \t,         \taround,\n",
            "change         \t[PAD]     \tchange\n",
            "things         \t[PAD]     \tthings\n",
            "quite          \t[PAD]     \tquite\n",
            "dramatically   \t/         \tdramatically/\n",
            "now            \t,         \tnow,\n",
            "i've           \t[PAD]     \ti've\n",
            "argued         \t,         \targued,\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "not            \t[PAD]     \tnot\n",
            "genesis        \t,         \tgenesis,\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "building       \t[PAD]     \tbuilding\n",
            "on             \t[PAD]     \ton\n",
            "three          \t[PAD]     \tthree\n",
            "and            \t[PAD]     \tand\n",
            "a              \t[PAD]     \ta\n",
            "half           \t[PAD]     \thalf\n",
            "billion        \t[PAD]     \tbillion\n",
            "years          \t[PAD]     \tyears\n",
            "of             \t[PAD]     \tof\n",
            "evolution      \t,         \tevolution,\n",
            "and            \t[PAD]     \tand\n",
            "i've           \t[PAD]     \ti've\n",
            "argued         \t[PAD]     \targued\n",
            "that           \t[PAD]     \tthat\n",
            "we're          \t[PAD]     \twe're\n",
            "about          \t[PAD]     \tabout\n",
            "to             \t[PAD]     \tto\n",
            "perhaps        \t[PAD]     \tperhaps\n",
            "create         \t[PAD]     \tcreate\n",
            "a              \t[PAD]     \ta\n",
            "new            \t[PAD]     \tnew\n",
            "version        \t[PAD]     \tversion\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "cambrian       \t[PAD]     \tcambrian\n",
            "explosion      \t[PAD]     \texplosion\n",
            "where          \t[PAD]     \twhere\n",
            "there's        \t[PAD]     \tthere's\n",
            "massive        \t[PAD]     \tmassive\n",
            "new            \t[PAD]     \tnew\n",
            "speciation     \t[PAD]     \tspeciation\n",
            "based          \t[PAD]     \tbased\n",
            "on             \t[PAD]     \ton\n",
            "this           \t[PAD]     \tthis\n",
            "digital        \t[PAD]     \tdigital\n",
            "design         \t/         \tdesign/\n",
            "why            \t[PAD]     \twhy\n",
            "do             \t[PAD]     \tdo\n",
            "this           \t/         \tthis/\n",
            "i              \t[PAD]     \ti\n",
            "think          \t[PAD]     \tthink\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "pretty         \t[PAD]     \tpretty\n",
            "obvious        \t[PAD]     \tobvious\n",
            "in             \t[PAD]     \tin\n",
            "terms          \t[PAD]     \tterms\n",
            "of             \t[PAD]     \tof\n",
            "some           \t[PAD]     \tsome\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "needs          \t/         \tneeds/\n",
            "we're          \t[PAD]     \twe're\n",
            "about          \t[PAD]     \tabout\n",
            "to             \t[PAD]     \tto\n",
            "go             \t[PAD]     \tgo\n",
            "from           \t[PAD]     \tfrom\n",
            "six            \t[PAD]     \tsix\n",
            "and            \t[PAD]     \tand\n",
            "a              \t[PAD]     \ta\n",
            "half           \t[PAD]     \thalf\n",
            "to             \t[PAD]     \tto\n",
            "9              \t[PAD]     \t9\n",
            "billion        \t[PAD]     \tbillion\n",
            "people         \t[PAD]     \tpeople\n",
            "over           \t[PAD]     \tover\n",
            "the            \t[PAD]     \tthe\n",
            "next           \t[PAD]     \tnext\n",
            "40             \t[PAD]     \t40\n",
            "years          \t/         \tyears/\n",
            "to             \t[PAD]     \tto\n",
            "put            \t[PAD]     \tput\n",
            "it             \t[PAD]     \tit\n",
            "in             \t[PAD]     \tin\n",
            "context        \t[PAD]     \tcontext\n",
            "for            \t[PAD]     \tfor\n",
            "myself         \t,         \tmyself,\n",
            "i              \t[PAD]     \ti\n",
            "was            \t[PAD]     \twas\n",
            "born           \t[PAD]     \tborn\n",
            "in             \t[PAD]     \tin\n",
            "1946           \t/         \t1946/\n",
            "there's        \t[PAD]     \tthere's\n",
            "now            \t[PAD]     \tnow\n",
            "three          \t[PAD]     \tthree\n",
            "people         \t[PAD]     \tpeople\n",
            "on             \t[PAD]     \ton\n",
            "the            \t[PAD]     \tthe\n",
            "planet         \t[PAD]     \tplanet\n",
            "for            \t[PAD]     \tfor\n",
            "every          \t[PAD]     \tevery\n",
            "one            \t[PAD]     \tone\n",
            "of             \t[PAD]     \tof\n",
            "us             \t[PAD]     \tus\n",
            "that           \t[PAD]     \tthat\n",
            "existed        \t[PAD]     \texisted\n",
            "in             \t[PAD]     \tin\n",
            "1946           \t.         \t1946.\n",
            "within         \t[PAD]     \twithin\n",
            "40             \t[PAD]     \t40\n",
            "years          \t,         \tyears,\n",
            "there'll       \t[PAD]     \tthere'll\n",
            "be             \t[PAD]     \tbe\n",
            "four           \t/         \tfour/\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "trouble        \t[PAD]     \ttrouble\n",
            "feeding        \t,         \tfeeding,\n",
            "providing      \t[PAD]     \tproviding\n",
            "fresh          \t,         \tfresh,\n",
            "clean          \t[PAD]     \tclean\n",
            "water          \t,         \twater,\n",
            "medicines      \t,         \tmedicines,\n",
            "fuel           \t[PAD]     \tfuel\n",
            "for            \t[PAD]     \tfor\n",
            "the            \t[PAD]     \tthe\n",
            "six            \t[PAD]     \tsix\n",
            "and            \t[PAD]     \tand\n",
            "a              \t[PAD]     \ta\n",
            "half           \t[PAD]     \thalf\n",
            "billion        \t/         \tbillion/\n",
            "it's           \t[PAD]     \tit's\n",
            "going          \t[PAD]     \tgoing\n",
            "to             \t[PAD]     \tto\n",
            "be             \t[PAD]     \tbe\n",
            "a              \t[PAD]     \ta\n",
            "stretch        \t[PAD]     \tstretch\n",
            "to             \t[PAD]     \tto\n",
            "do             \t[PAD]     \tdo\n",
            "it             \t[PAD]     \tit\n",
            "for            \t[PAD]     \tfor\n",
            "nine           \t/         \tnine/\n",
            "we             \t[PAD]     \twe\n",
            "use            \t[PAD]     \tuse\n",
            "over           \t[PAD]     \tover\n",
            "5              \t[PAD]     \t5\n",
            "billion        \t[PAD]     \tbillion\n",
            "tons           \t[PAD]     \ttons\n",
            "of             \t[PAD]     \tof\n",
            "coal           \t,         \tcoal,\n",
            "30             \t[PAD]     \t30\n",
            "billion        \t[PAD]     \tbillion\n",
            "plus           \t[PAD]     \tplus\n",
            "barrels        \t[PAD]     \tbarrels\n",
            "of             \t[PAD]     \tof\n",
            "oil            \t/         \toil/\n",
            "that's         \t[PAD]     \tthat's\n",
            "a              \t[PAD]     \ta\n",
            "hundred        \t[PAD]     \thundred\n",
            "million        \t[PAD]     \tmillion\n",
            "barrels        \t[PAD]     \tbarrels\n",
            "a              \t[PAD]     \ta\n",
            "day            \t/         \tday/\n",
            "when           \t[PAD]     \twhen\n",
            "we             \t[PAD]     \twe\n",
            "try            \t[PAD]     \ttry\n",
            "to             \t[PAD]     \tto\n",
            "think          \t[PAD]     \tthink\n",
            "of             \t[PAD]     \tof\n",
            "biological     \t[PAD]     \tbiological\n",
            "processes      \t[PAD]     \tprocesses\n",
            "or             \t[PAD]     \tor\n",
            "any            \t[PAD]     \tany\n",
            "process        \t[PAD]     \tprocess\n",
            "to             \t[PAD]     \tto\n",
            "replace        \t[PAD]     \treplace\n",
            "that           \t,         \tthat,\n",
            "it's           \t[PAD]     \tit's\n",
            "going          \t[PAD]     \tgoing\n",
            "to             \t[PAD]     \tto\n",
            "be             \t[PAD]     \tbe\n",
            "a              \t[PAD]     \ta\n",
            "huge           \t[PAD]     \thuge\n",
            "challenge      \t/         \tchallenge/\n",
            "then           \t,         \tthen,\n",
            "of             \t[PAD]     \tof\n",
            "course         \t,         \tcourse,\n",
            "there's        \t[PAD]     \tthere's\n",
            "all            \t[PAD]     \tall\n",
            "that           \t[PAD]     \tthat\n",
            "co2            \t[PAD]     \tco2\n",
            "from           \t[PAD]     \tfrom\n",
            "this           \t[PAD]     \tthis\n",
            "material       \t[PAD]     \tmaterial\n",
            "that           \t[PAD]     \tthat\n",
            "ends           \t[PAD]     \tends\n",
            "up             \t[PAD]     \tup\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "atmosphere     \t/         \tatmosphere/\n",
            "we             \t[PAD]     \twe\n",
            "now            \t,         \tnow,\n",
            "from           \t[PAD]     \tfrom\n",
            "our            \t[PAD]     \tour\n",
            "discovery      \t[PAD]     \tdiscovery\n",
            "around         \t[PAD]     \taround\n",
            "the            \t[PAD]     \tthe\n",
            "world          \t,         \tworld,\n",
            "have           \t[PAD]     \thave\n",
            "a              \t[PAD]     \ta\n",
            "database       \t[PAD]     \tdatabase\n",
            "with           \t[PAD]     \twith\n",
            "about          \t[PAD]     \tabout\n",
            "20             \t[PAD]     \t20\n",
            "million        \t[PAD]     \tmillion\n",
            "genes          \t,         \tgenes,\n",
            "and            \t[PAD]     \tand\n",
            "i              \t[PAD]     \ti\n",
            "like           \t[PAD]     \tlike\n",
            "to             \t[PAD]     \tto\n",
            "think          \t[PAD]     \tthink\n",
            "of             \t[PAD]     \tof\n",
            "these          \t[PAD]     \tthese\n",
            "as             \t[PAD]     \tas\n",
            "the            \t[PAD]     \tthe\n",
            "design         \t[PAD]     \tdesign\n",
            "components     \t[PAD]     \tcomponents\n",
            "of             \t[PAD]     \tof\n",
            "the            \t[PAD]     \tthe\n",
            "future         \t/         \tfuture/\n",
            "the            \t[PAD]     \tthe\n",
            "electronics    \t[PAD]     \telectronics\n",
            "industry       \t[PAD]     \tindustry\n",
            "only           \t[PAD]     \tonly\n",
            "had            \t[PAD]     \thad\n",
            "a              \t[PAD]     \ta\n",
            "dozen          \t[PAD]     \tdozen\n",
            "or             \t[PAD]     \tor\n",
            "so             \t[PAD]     \tso\n",
            "components     \t,         \tcomponents,\n",
            "and            \t[PAD]     \tand\n",
            "look           \t[PAD]     \tlook\n",
            "at             \t[PAD]     \tat\n",
            "the            \t[PAD]     \tthe\n",
            "diversity      \t[PAD]     \tdiversity\n",
            "that           \t[PAD]     \tthat\n",
            "came           \t[PAD]     \tcame\n",
            "out            \t[PAD]     \tout\n",
            "of             \t[PAD]     \tof\n",
            "that           \t/         \tthat/\n",
            "we're          \t[PAD]     \twe're\n",
            "limited        \t[PAD]     \tlimited\n",
            "here           \t[PAD]     \there\n",
            "primarily      \t[PAD]     \tprimarily\n",
            "by             \t[PAD]     \tby\n",
            "a              \t[PAD]     \ta\n",
            "biological     \t[PAD]     \tbiological\n",
            "reality        \t[PAD]     \treality\n",
            "and            \t[PAD]     \tand\n",
            "our            \t[PAD]     \tour\n",
            "imagination    \t/         \timagination/\n",
            "we             \t[PAD]     \twe\n",
            "now            \t[PAD]     \tnow\n",
            "have           \t[PAD]     \thave\n",
            "techniques     \t,         \ttechniques,\n",
            "because        \t[PAD]     \tbecause\n",
            "of             \t[PAD]     \tof\n",
            "these          \t[PAD]     \tthese\n",
            "rapid          \t[PAD]     \trapid\n",
            "methods        \t[PAD]     \tmethods\n",
            "of             \t[PAD]     \tof\n",
            "synthesis      \t,         \tsynthesis,\n",
            "to             \t[PAD]     \tto\n",
            "do             \t[PAD]     \tdo\n",
            "what           \t[PAD]     \twhat\n",
            "we're          \t[PAD]     \twe're\n",
            "calling        \t[PAD]     \tcalling\n",
            "combinatorial  \t[PAD]     \tcombinatorial\n",
            "genomics       \t/         \tgenomics/\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "the            \t[PAD]     \tthe\n",
            "ability        \t[PAD]     \tability\n",
            "now            \t[PAD]     \tnow\n",
            "to             \t[PAD]     \tto\n",
            "build          \t[PAD]     \tbuild\n",
            "a              \t[PAD]     \ta\n",
            "large          \t[PAD]     \tlarge\n",
            "robot          \t[PAD]     \trobot\n",
            "that           \t[PAD]     \tthat\n",
            "can            \t[PAD]     \tcan\n",
            "make           \t[PAD]     \tmake\n",
            "a              \t[PAD]     \ta\n",
            "million        \t[PAD]     \tmillion\n",
            "chromosomes    \t[PAD]     \tchromosomes\n",
            "a              \t[PAD]     \ta\n",
            "day            \t/         \tday/\n",
            "when           \t[PAD]     \twhen\n",
            "you            \t[PAD]     \tyou\n",
            "think          \t[PAD]     \tthink\n",
            "of             \t[PAD]     \tof\n",
            "processing     \t[PAD]     \tprocessing\n",
            "these          \t[PAD]     \tthese\n",
            "20             \t[PAD]     \t20\n",
            "million        \t[PAD]     \tmillion\n",
            "different      \t[PAD]     \tdifferent\n",
            "genes          \t,         \tgenes,\n",
            "or             \t[PAD]     \tor\n",
            "trying         \t[PAD]     \ttrying\n",
            "to             \t[PAD]     \tto\n",
            "optimize       \t[PAD]     \toptimize\n",
            "processes      \t[PAD]     \tprocesses\n",
            "to             \t[PAD]     \tto\n",
            "produce        \t[PAD]     \tproduce\n",
            "octane         \t[PAD]     \toctane\n",
            "or             \t[PAD]     \tor\n",
            "to             \t[PAD]     \tto\n",
            "produce        \t[PAD]     \tproduce\n",
            "pharmaceuticals\t,         \tpharmaceuticals,\n",
            "new            \t[PAD]     \tnew\n",
            "vaccines       \t,         \tvaccines,\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "change         \t,         \tchange,\n",
            "just           \t[PAD]     \tjust\n",
            "with           \t[PAD]     \twith\n",
            "a              \t[PAD]     \ta\n",
            "small          \t[PAD]     \tsmall\n",
            "team           \t,         \tteam,\n",
            "do             \t[PAD]     \tdo\n",
            "more           \t[PAD]     \tmore\n",
            "molecular      \t[PAD]     \tmolecular\n",
            "biology        \t[PAD]     \tbiology\n",
            "than           \t[PAD]     \tthan\n",
            "the            \t[PAD]     \tthe\n",
            "last           \t[PAD]     \tlast\n",
            "20             \t[PAD]     \t20\n",
            "years          \t[PAD]     \tyears\n",
            "of             \t[PAD]     \tof\n",
            "all            \t[PAD]     \tall\n",
            "science        \t/         \tscience/\n",
            "and            \t[PAD]     \tand\n",
            "it's           \t[PAD]     \tit's\n",
            "just           \t[PAD]     \tjust\n",
            "standard       \t[PAD]     \tstandard\n",
            "selection      \t/         \tselection/\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "select         \t[PAD]     \tselect\n",
            "for            \t[PAD]     \tfor\n",
            "viability      \t,         \tviability,\n",
            "chemical       \t[PAD]     \tchemical\n",
            "or             \t[PAD]     \tor\n",
            "fuel           \t[PAD]     \tfuel\n",
            "production     \t,         \tproduction,\n",
            "vaccine        \t[PAD]     \tvaccine\n",
            "production     \t,         \tproduction,\n",
            "et             \t[PAD]     \tet\n",
            "cetera         \t/         \tcetera/\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "a              \t[PAD]     \ta\n",
            "screen         \t[PAD]     \tscreen\n",
            "snapshot       \t[PAD]     \tsnapshot\n",
            "of             \t[PAD]     \tof\n",
            "some           \t[PAD]     \tsome\n",
            "true           \t[PAD]     \ttrue\n",
            "design         \t[PAD]     \tdesign\n",
            "software       \t[PAD]     \tsoftware\n",
            "that           \t[PAD]     \tthat\n",
            "we're          \t[PAD]     \twe're\n",
            "working        \t[PAD]     \tworking\n",
            "on             \t[PAD]     \ton\n",
            "to             \t[PAD]     \tto\n",
            "actually       \t[PAD]     \tactually\n",
            "be             \t[PAD]     \tbe\n",
            "able           \t[PAD]     \table\n",
            "to             \t[PAD]     \tto\n",
            "sit            \t[PAD]     \tsit\n",
            "down           \t[PAD]     \tdown\n",
            "and            \t[PAD]     \tand\n",
            "design         \t[PAD]     \tdesign\n",
            "species        \t[PAD]     \tspecies\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "computer       \t/         \tcomputer/\n",
            "you            \t[PAD]     \tyou\n",
            "know           \t,         \tknow,\n",
            "we             \t[PAD]     \twe\n",
            "don't          \t[PAD]     \tdon't\n",
            "know           \t[PAD]     \tknow\n",
            "necessarily    \t[PAD]     \tnecessarily\n",
            "what           \t[PAD]     \twhat\n",
            "it'll          \t[PAD]     \tit'll\n",
            "look           \t[PAD]     \tlook\n",
            "like           \t/         \tlike/\n",
            "we             \t[PAD]     \twe\n",
            "know           \t[PAD]     \tknow\n",
            "exactly        \t[PAD]     \texactly\n",
            "what           \t[PAD]     \twhat\n",
            "their          \t[PAD]     \ttheir\n",
            "genetic        \t[PAD]     \tgenetic\n",
            "code           \t[PAD]     \tcode\n",
            "looks          \t[PAD]     \tlooks\n",
            "like           \t/         \tlike/\n",
            "we're          \t[PAD]     \twe're\n",
            "focusing       \t[PAD]     \tfocusing\n",
            "on             \t[PAD]     \ton\n",
            "now            \t[PAD]     \tnow\n",
            "fourth         \t[PAD]     \tfourth\n",
            "generation     \t[PAD]     \tgeneration\n",
            "fuels          \t/         \tfuels/\n",
            "you've         \t[PAD]     \tyou've\n",
            "seen           \t[PAD]     \tseen\n",
            "recently       \t[PAD]     \trecently\n",
            "corn           \t[PAD]     \tcorn\n",
            "to             \t[PAD]     \tto\n",
            "ethanol        \t[PAD]     \tethanol\n",
            "is             \t[PAD]     \tis\n",
            "just           \t[PAD]     \tjust\n",
            "a              \t[PAD]     \ta\n",
            "bad            \t[PAD]     \tbad\n",
            "experiment     \t/         \texperiment/\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "second -       \t[PAD]     \tsecond-\n",
            "and            \t[PAD]     \tand\n",
            "third          \t[PAD]     \tthird\n",
            "generation     \t[PAD]     \tgeneration\n",
            "fuels          \t[PAD]     \tfuels\n",
            "that           \t[PAD]     \tthat\n",
            "will           \t[PAD]     \twill\n",
            "be             \t[PAD]     \tbe\n",
            "coming         \t[PAD]     \tcoming\n",
            "out            \t[PAD]     \tout\n",
            "relatively     \t[PAD]     \trelatively\n",
            "soon           \t[PAD]     \tsoon\n",
            "that           \t[PAD]     \tthat\n",
            "are            \t[PAD]     \tare\n",
            "sugar          \t,         \tsugar,\n",
            "to             \t[PAD]     \tto\n",
            "much           \t[PAD]     \tmuch\n",
            "higher         \t[PAD]     \thigher\n",
            "value          \t[PAD]     \tvalue\n",
            "fuels          \t[PAD]     \tfuels\n",
            "like           \t[PAD]     \tlike\n",
            "octane         \t[PAD]     \toctane\n",
            "or             \t[PAD]     \tor\n",
            "different      \t[PAD]     \tdifferent\n",
            "types          \t[PAD]     \ttypes\n",
            "of             \t[PAD]     \tof\n",
            "butanol        \t/         \tbutanol/\n",
            "but            \t[PAD]     \tbut\n",
            "the            \t[PAD]     \tthe\n",
            "only           \t[PAD]     \tonly\n",
            "way            \t[PAD]     \tway\n",
            "we             \t[PAD]     \twe\n",
            "think          \t[PAD]     \tthink\n",
            "that           \t[PAD]     \tthat\n",
            "biology        \t[PAD]     \tbiology\n",
            "can            \t[PAD]     \tcan\n",
            "have           \t[PAD]     \thave\n",
            "a              \t[PAD]     \ta\n",
            "major          \t[PAD]     \tmajor\n",
            "impact         \t[PAD]     \timpact\n",
            "without        \t[PAD]     \twithout\n",
            "further        \t[PAD]     \tfurther\n",
            "increasing     \t[PAD]     \tincreasing\n",
            "the            \t[PAD]     \tthe\n",
            "cost           \t[PAD]     \tcost\n",
            "of             \t[PAD]     \tof\n",
            "food           \t[PAD]     \tfood\n",
            "and            \t[PAD]     \tand\n",
            "limiting       \t[PAD]     \tlimiting\n",
            "its            \t[PAD]     \tits\n",
            "availability   \t[PAD]     \tavailability\n",
            "is             \t[PAD]     \tis\n",
            "if             \t[PAD]     \tif\n",
            "we             \t[PAD]     \twe\n",
            "start          \t[PAD]     \tstart\n",
            "with           \t[PAD]     \twith\n",
            "co2            \t[PAD]     \tco2\n",
            "as             \t[PAD]     \tas\n",
            "its            \t[PAD]     \tits\n",
            "feedstock      \t,         \tfeedstock,\n",
            "and            \t[PAD]     \tand\n",
            "so             \t[PAD]     \tso\n",
            "we're          \t[PAD]     \twe're\n",
            "working        \t[PAD]     \tworking\n",
            "with           \t[PAD]     \twith\n",
            "designing      \t[PAD]     \tdesigning\n",
            "cells          \t[PAD]     \tcells\n",
            "to             \t[PAD]     \tto\n",
            "go             \t[PAD]     \tgo\n",
            "down           \t[PAD]     \tdown\n",
            "this           \t[PAD]     \tthis\n",
            "road           \t,         \troad,\n",
            "and            \t[PAD]     \tand\n",
            "we             \t[PAD]     \twe\n",
            "think          \t[PAD]     \tthink\n",
            "we'll          \t[PAD]     \twe'll\n",
            "have           \t[PAD]     \thave\n",
            "the            \t[PAD]     \tthe\n",
            "first          \t[PAD]     \tfirst\n",
            "fourth         \t[PAD]     \tfourth\n",
            "generation     \t[PAD]     \tgeneration\n",
            "fuels          \t[PAD]     \tfuels\n",
            "in             \t[PAD]     \tin\n",
            "about          \t[PAD]     \tabout\n",
            "18             \t[PAD]     \t18\n",
            "months         \t/         \tmonths/\n",
            "sunlight       \t[PAD]     \tsunlight\n",
            "and            \t[PAD]     \tand\n",
            "co2            \t[PAD]     \tco2\n",
            "is             \t[PAD]     \tis\n",
            "one            \t[PAD]     \tone\n",
            "method         \t,         \tmethod,\n",
            "but            \t[PAD]     \tbut\n",
            "in             \t[PAD]     \tin\n",
            "our            \t[PAD]     \tour\n",
            "discovery      \t[PAD]     \tdiscovery\n",
            "around         \t[PAD]     \taround\n",
            "the            \t[PAD]     \tthe\n",
            "world          \t,         \tworld,\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "all            \t[PAD]     \tall\n",
            "kinds          \t[PAD]     \tkinds\n",
            "of             \t[PAD]     \tof\n",
            "other          \t[PAD]     \tother\n",
            "methods        \t/         \tmethods/\n",
            "this           \t[PAD]     \tthis\n",
            "is             \t[PAD]     \tis\n",
            "an             \t[PAD]     \tan\n",
            "organism       \t[PAD]     \torganism\n",
            "we             \t[PAD]     \twe\n",
            "described      \t[PAD]     \tdescribed\n",
            "in             \t[PAD]     \tin\n",
            "1996           \t/         \t1996/\n",
            "it             \t[PAD]     \tit\n",
            "lives          \t[PAD]     \tlives\n",
            "in             \t[PAD]     \tin\n",
            "the            \t[PAD]     \tthe\n",
            "deep           \t[PAD]     \tdeep\n",
            "ocean          \t,         \tocean,\n",
            "about          \t[PAD]     \tabout\n",
            "a              \t[PAD]     \ta\n",
            "mile           \t[PAD]     \tmile\n",
            "and            \t[PAD]     \tand\n",
            "a              \t[PAD]     \ta\n",
            "half           \t[PAD]     \thalf\n",
            "deep           \t,         \tdeep,\n",
            "almost         \t[PAD]     \talmost\n",
            "at             \t[PAD]     \tat\n",
            "boiling        \t[PAD]     \tboiling\n",
            "water          \t[PAD]     \twater\n",
            "temperatures   \t/         \ttemperatures/\n",
            "it             \t[PAD]     \tit\n",
            "takes          \t[PAD]     \ttakes\n",
            "co2            \t[PAD]     \tco2\n",
            "to             \t[PAD]     \tto\n",
            "methane        \t[PAD]     \tmethane\n",
            "using          \t[PAD]     \tusing\n",
            "molecular      \t[PAD]     \tmolecular\n",
            "hydrogen       \t[PAD]     \thydrogen\n",
            "as             \t[PAD]     \tas\n",
            "its            \t[PAD]     \tits\n",
            "energy         \t[PAD]     \tenergy\n",
            "source         \t/         \tsource/\n",
            "we're          \t[PAD]     \twe're\n",
            "looking        \t[PAD]     \tlooking\n",
            "to             \t[PAD]     \tto\n",
            "see            \t[PAD]     \tsee\n",
            "if             \t[PAD]     \tif\n",
            "we             \t[PAD]     \twe\n",
            "can            \t[PAD]     \tcan\n",
            "take           \t[PAD]     \ttake\n",
            "captured       \t[PAD]     \tcaptured\n",
            "co2            \t,         \tco2,\n",
            "which          \t[PAD]     \twhich\n",
            "can            \t[PAD]     \tcan\n",
            "easily         \t[PAD]     \teasily\n",
            "be             \t[PAD]     \tbe\n",
            "piped          \t[PAD]     \tpiped\n",
            "to             \t[PAD]     \tto\n",
            "sites          \t,         \tsites,\n",
            "convert        \t[PAD]     \tconvert\n",
            "that           \t[PAD]     \tthat\n",
            "co2            \t[PAD]     \tco2\n",
            "back           \t[PAD]     \tback\n",
            "into           \t[PAD]     \tinto\n",
            "fuel           \t,         \tfuel,\n",
            "to             \t[PAD]     \tto\n",
            "drive          \t[PAD]     \tdrive\n",
            "this           \t[PAD]     \tthis\n",
            "process        \t/         \tprocess/\n",
            "so             \t[PAD]     \tso\n",
            "in             \t[PAD]     \tin\n",
            "a              \t[PAD]     \ta\n",
            "short          \t[PAD]     \tshort\n",
            "period         \t[PAD]     \tperiod\n",
            "of             \t[PAD]     \tof\n",
            "time           \t,         \ttime,\n",
            "we             \t[PAD]     \twe\n",
            "think          \t[PAD]     \tthink\n",
            "that           \t[PAD]     \tthat\n",
            "we             \t[PAD]     \twe\n",
            "might          \t[PAD]     \tmight\n",
            "be             \t[PAD]     \tbe\n",
            "able           \t[PAD]     \table\n",
            "to             \t[PAD]     \tto\n",
            "increase       \t[PAD]     \tincrease\n",
            "what           \t[PAD]     \twhat\n",
            "the            \t[PAD]     \tthe\n",
            "basic          \t[PAD]     \tbasic\n",
            "question       \t[PAD]     \tquestion\n",
            "is             \t[PAD]     \tis\n",
            "of, what       \t[PAD]     \tof,what\n",
            "is             \t[PAD]     \tis\n",
            "life /         \t,         \tlife/,\n",
            "we're          \t[PAD]     \twe're\n",
            "truly          \t,         \ttruly,\n",
            "you            \t[PAD]     \tyou\n",
            "know           \t,         \tknow,\n",
            "have           \t[PAD]     \thave\n",
            "modest         \t[PAD]     \tmodest\n",
            "goals          \t[PAD]     \tgoals\n",
            "of             \t[PAD]     \tof\n",
            "replacing      \t[PAD]     \treplacing\n",
            "the            \t[PAD]     \tthe\n",
            "whole          \t[PAD]     \twhole\n",
            "petrol         \t[PAD]     \tpetrol\n",
            "chemical       \t[PAD]     \tchemical\n",
            "industry       \t/         \tindustry/\n",
            "yeah           \t/         \tyeah/\n",
            "if             \t[PAD]     \tif\n",
            "you            \t[PAD]     \tyou\n",
            "can't          \t[PAD]     \tcan't\n",
            "do             \t[PAD]     \tdo\n",
            "that           \t[PAD]     \tthat\n",
            "at             \t[PAD]     \tat\n",
            "ted            \t,         \tted,\n",
            "where          \t[PAD]     \twhere\n",
            "can            \t[PAD]     \tcan\n",
            "you            \t/         \tyou/\n",
            "become         \t[PAD]     \tbecome\n",
            "a              \t[PAD]     \ta\n",
            "major          \t[PAD]     \tmajor\n",
            "source         \t[PAD]     \tsource\n",
            "of             \t[PAD]     \tof\n",
            "energy         \t/         \tenergy/\n",
            "but            \t[PAD]     \tbut\n",
            "also           \t,         \talso,\n",
            "we're          \t[PAD]     \twe're\n",
            "now            \t[PAD]     \tnow\n",
            "working        \t[PAD]     \tworking\n",
            "on             \t[PAD]     \ton\n",
            "using          \t[PAD]     \tusing\n",
            "these          \t[PAD]     \tthese\n",
            "same           \t[PAD]     \tsame\n",
            "tools          \t[PAD]     \ttools\n",
            "to             \t[PAD]     \tto\n",
            "come           \t[PAD]     \tcome\n",
            "up             \t[PAD]     \tup\n",
            "with           \t[PAD]     \twith\n",
            "instant        \t[PAD]     \tinstant\n",
            "sets           \t[PAD]     \tsets\n",
            "of             \t[PAD]     \tof\n",
            "vaccines       \t/         \tvaccines/\n",
            "you've         \t[PAD]     \tyou've\n",
            "seen           \t[PAD]     \tseen\n",
            "this           \t[PAD]     \tthis\n",
            "year           \t[PAD]     \tyear\n",
            "with           \t[PAD]     \twith\n",
            "flu            \t,         \tflu,\n",
            "we're          \t[PAD]     \twe're\n",
            "always         \t[PAD]     \talways\n",
            "a              \t[PAD]     \ta\n",
            "year           \t[PAD]     \tyear\n",
            "behind         \t[PAD]     \tbehind\n",
            "and            \t[PAD]     \tand\n",
            "a              \t[PAD]     \ta\n",
            "dollar         \t[PAD]     \tdollar\n",
            "short          \t[PAD]     \tshort\n",
            "when           \t[PAD]     \twhen\n",
            "it             \t[PAD]     \tit\n",
            "comes          \t[PAD]     \tcomes\n",
            "to             \t[PAD]     \tto\n",
            "the            \t[PAD]     \tthe\n",
            "right          \t[PAD]     \tright\n",
            "vaccine        \t/         \tvaccine/\n",
            "i              \t[PAD]     \ti\n",
            "think          \t[PAD]     \tthink\n",
            "that           \t[PAD]     \tthat\n",
            "can            \t[PAD]     \tcan\n",
            "be             \t[PAD]     \tbe\n",
            "changed        \t[PAD]     \tchanged\n",
            "by             \t[PAD]     \tby\n",
            "building       \t[PAD]     \tbuilding\n",
            "combinatorial  \t[PAD]     \tcombinatorial\n",
            "vaccines       \t[PAD]     \tvaccines\n",
            "in             \t[PAD]     \tin\n",
            "advance        \t/         \tadvance/\n",
            "here's         \t[PAD]     \there's\n",
            "what           \t[PAD]     \twhat\n",
            "the            \t[PAD]     \tthe\n",
            "future         \t[PAD]     \tfuture\n",
            "may            \t[PAD]     \tmay\n",
            "begin          \t[PAD]     \tbegin\n",
            "to             \t[PAD]     \tto\n",
            "look           \t[PAD]     \tlook\n",
            "like           \t[PAD]     \tlike\n",
            "with           \t[PAD]     \twith\n",
            "changing       \t,         \tchanging,\n",
            "now            \t,         \tnow,\n",
            "the            \t[PAD]     \tthe\n",
            "evolutionary   \t[PAD]     \tevolutionary\n",
            "tree           \t,         \ttree,\n",
            "speeding       \t[PAD]     \tspeeding\n",
            "up             \t[PAD]     \tup\n",
            "evolution      \t[PAD]     \tevolution\n",
            "with           \t[PAD]     \twith\n",
            "synthetic      \t[PAD]     \tsynthetic\n",
            "bacteria       \t,         \tbacteria,\n",
            "archea         \t,         \tarchea,\n",
            "and            \t[PAD]     \tand\n",
            "eventually     \t[PAD]     \teventually\n",
            "eukaryotes     \t/         \teukaryotes/\n",
            "we're          \t[PAD]     \twe're\n",
            "a              \t[PAD]     \ta\n",
            "ways           \t[PAD]     \tways\n",
            "away           \t[PAD]     \taway\n",
            "from           \t[PAD]     \tfrom\n",
            "improving      \t[PAD]     \timproving\n",
            "people         \t/         \tpeople/\n",
            "our            \t[PAD]     \tour\n",
            "goal           \t[PAD]     \tgoal\n",
            "is             \t[PAD]     \tis\n",
            "just           \t[PAD]     \tjust\n",
            "to             \t[PAD]     \tto\n",
            "make           \t[PAD]     \tmake\n",
            "sure           \t[PAD]     \tsure\n",
            "that           \t[PAD]     \tthat\n",
            "we             \t[PAD]     \twe\n",
            "have           \t[PAD]     \thave\n",
            "a              \t[PAD]     \ta\n",
            "chance         \t[PAD]     \tchance\n",
            "to             \t[PAD]     \tto\n",
            "survive        \t[PAD]     \tsurvive\n",
            "long           \t[PAD]     \tlong\n",
            "enough         \t[PAD]     \tenough\n",
            "to             \t[PAD]     \tto\n",
            "maybe          \t[PAD]     \tmaybe\n",
            "do             \t[PAD]     \tdo\n",
            "that           \t/         \tthat/\n",
            "thank          \t[PAD]     \tthank\n",
            "you            \t[PAD]     \tyou\n",
            "very           \t[PAD]     \tvery\n",
            "much           \t/         \tmuch/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OverflowError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-76546143b4ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{tokenizer.decode(e):15}\\t{tokenizer.decode(target2id[ta]):10}\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3347\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3348\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3349\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3350\u001b[0m         )\n\u001b[1;32m   3351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOverflowError\u001b[0m: out of range integral type conversion attempted"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(encoded_texts[1][2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE3Sd5VWMI1F",
        "outputId": "68aa9ff6-e23f-43cf-83dc-e6c46ec44823"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] you know i've talked about some of these projects before about the human genome and what that might mean and discovering new sets of genes we're actually starting at a new point we've been digitizing biology and now we're trying to go from that digital code into a new phase of biology with designing and synthesizing life so we've always been trying to ask big questions /, what is life / is something that i think many biologists have been trying to understand at various levels we've tried various approaches paring it down to minimal components we've been digitizing it now for almost 20 years when we sequenced the human genome it was going from the analog world of biology into the digital world of the computer now we're trying to ask can we regenerate life or can we create new life out of this digital universe this is the map of a small organism mycoplasma genitalium that has the smallest genome for a species that can self replicate in the laboratory and we've been trying to just see if we can come up with an even smaller genome we're able to knock out on the order of a hundred genes out of the 500 or so that are here but when we look at its metabolic map it's relatively simple compared to ours trust me this is simple but when we look at all the genes that we can knock out one at a time it's very unlikely that this would yield a living cell so we decided the only way forward was to actually synthesize this chromosome so we could vary the components to ask some of these most fundamental questions and so we started down the road of, can we synthesize a chromosome / can chemistry permit making these really large molecules where we've never been before and if we do can we boot up a chromosome a chromosome by the way is just a piece of inert chemical material so our pace of digitizing life has been increasing at an exponential pace our ability to write the genetic code has been moving pretty slowly but has been increasing and our latest point would put it on now an exponential curve we started this over 15 years ago it took several stages in fact starting with a bioethical review before we did the first experiments but it turns out synthesizing dna is very difficult there's tens of thousands of machines around the world that make small pieces of dna 30 to 50 letters in length and it's a degenerate process so the longer you make the piece the more errors there are so we had to create a new method for putting these little pieces together and correct all the errors and this was our first attempt starting with the digital information of the genome of phi x 174 it's a small virus that kills bacteria we designed the pieces went through our error correction and had a dna molecule of about 5, 000 letters the exciting phase came when we took this piece of inert chemical and put it in the bacteria and the bacteria started to read this genetic code made the viral particles the viral particles then were released from the cells then came back and killed the e coli i was talking to the oil industry recently and i said they clearly understood that model they laughed more than you guys are and so we think this is a situation where the software can actually build its own hardware in a biological system but we wanted to go much larger we wanted to build the entire bacterial chromosome it's over 580, 000 letters of genetic code so we thought we'd build them in cassettes the size of the viruses so we could actually vary the cassettes to understand what the actual components of a living cell are design is critical and if you're starting with digital information in the computer that digital information has to be really accurate when we first sequenced this genome in 1995 the standard of accuracy was one error per 10, 000 base pairs we actually found on resequencing it 30 errors had we used that original sequence it never would have been able to be booted up part of the design is designing pieces that are 50 letters long that have to overlap with all the other 50 - letter pieces to build smaller sub units we have to design so they can go together we design unique elements into this you may have read that we put watermarks in think of this we have a four letter genetic code a c g and t triplets of that letter those letters code for roughly 20 amino acids that there's a single letter designation for each of the amino acids so we can use the genetic code to write out words sentences thoughts initially all we did was autograph it some people were disappointed there was not poetry we designed these pieces so we can just chew back with enzymes there's enzymes that repair them and put them together and we started making pieces starting with pieces that were five to 7, 000 letters fit those together to make 24, 000 - letter pieces then put sets of those going up to 72, 000 at each stage we grew up these pieces in abundance so we could sequence them because we're trying to create a process that's extremely robust that you can see in a minute we're trying to get to the point of automation so this looks like a basketball playoff when we get into these really large pieces over 100, 000 base pairs they won't any longer grow readily in e coli it exhausts all the modern tools of molecular biology and so we turned to other mechanisms we knew there's a mechanism called homologous recombination that biology uses to repair dna that can put pieces together here's an example of it there's an organism called deinococcus radiodurans that can take three millions rads of radiation you can see in the top panel its chromosome just gets blown apart 12 to 24 hours later it put it back together exactly as it was before we have thousands of organisms that can do this these organisms can be totally desiccated they can live in a vacuum i am absolutely certain that life can exist in outer space move around find a new aqueous environment in fact nasa has shown a lot of this is out there here's an actual micrograph of the molecule we built using these processes actually just using yeast mechanisms with the right design of the pieces we put them in yeast puts them together automatically this is not an electron micrograph this is just a regular photomicrograph it's such a large molecule we can see it with a light microscope these are pictures over about a six second period so this is the publication we had just a short while ago this is over 580, 000 letters of genetic code it's the largest molecule ever made by humans of a defined structure it's over 300 million molecular weight if we printed out at a 10 font with no spacing it takes 142 pages just to print this genetic code well how do we boot up a chromosome how do we activate this obviously with a virus it's pretty simple it's much more complicated dealing with bacteria it's also simpler when you go into eukaryotes like ourselves you can just pop out the nucleus and pop in another one and that's what you've all heard about with cloning with bacteria archaea the chromosome is integrated into the cell but we recently showed that we can do a complete transplant of a chromosome from one cell to another and activate it we purified a chromosome from one microbial species roughly these two are as distant as human and mice we added a few extra genes so we could select for this chromosome we digested it with enzymes to kill all the proteins and it was pretty stunning when we put this in the cell and you'll appreciate our very sophisticated graphics here the new chromosome went into the cell in fact we thought this might be as far as it went but we tried to design the process a little bit further this is a major mechanism of evolution right here we find all kinds of species that have taken up a second chromosome or a third one from somewhere adding thousands of new traits in a second to that species so people who think of evolution as just one gene changing at a time have missed much of biology there's enzymes called restriction enzymes that actually digest dna the chromosome that was in the cell doesn't have one the cell the chromosome we put in does it got expressed and it recognized the other chromosome as foreign material chewed it up and so we ended up just with the cell with the new chromosome it turned blue because of the genes we put in it and with a very short period of time all the characteristics of one species were lost and it converted totally into the new species based on the new software that we put in the cell all the proteins changed the membranes changed when we read the genetic code it's exactly what we had transferred in so this may sound like genomic alchemy but we can by moving the software dna around change things quite dramatically now i've argued this is not genesis this is building on three and a half billion years of evolution and i've argued that we're about to perhaps create a new version of the cambrian explosion where there's massive new speciation based on this digital design why do this i think this is pretty obvious in terms of some of the needs we're about to go from six and a half to 9 billion people over the next 40 years to put it in context for myself i was born in 1946 there's now three people on the planet for every one of us that existed in 1946 within 40 years there'll be four we have trouble feeding providing fresh clean water medicines fuel for the six and a half billion it's going to be a stretch to do it for nine we use over 5 billion tons of coal 30 billion plus barrels of oil that's a hundred million barrels a day when we try to think of biological processes or any process to replace that it's going to be a huge challenge then of course there's all that co2 from this material that ends up in the atmosphere we now from our discovery around the world have a database with about 20 million genes and i like to think of these as the design components of the future the electronics industry only had a dozen or so components and look at the diversity that came out of that we're limited here primarily by a biological reality and our imagination we now have techniques because of these rapid methods of synthesis to do what we're calling combinatorial genomics we have the ability now to build a large robot that can make a million chromosomes a day when you think of processing these 20 million different genes or trying to optimize processes to produce octane or to produce pharmaceuticals new vaccines we can change just with a small team do more molecular biology than the last 20 years of all science and it's just standard selection we can select for viability chemical or fuel production vaccine production et cetera this is a screen snapshot of some true design software that we're working on to actually be able to sit down and design species in the computer you know we don't know necessarily what it'll look like we know exactly what their genetic code looks like we're focusing on now fourth generation fuels you've seen recently corn to ethanol is just a bad experiment we have second - and third generation fuels that will be coming out relatively soon that are sugar to much higher value fuels like octane or different types of butanol but the only way we think that biology can have a major impact without further increasing the cost of food and limiting its availability is if we start with co2 as its feedstock and so we're working with designing cells to go down this road and we think we'll have the first fourth generation fuels in about 18 months sunlight and co2 is one method but in our discovery around the world we have all kinds of other methods this is an organism we described in 1996 it lives in the deep ocean about a mile and a half deep almost at boiling water temperatures it takes co2 to methane using molecular hydrogen as its energy source we're looking to see if we can take captured co2 which can easily be piped to sites convert that co2 back into fuel to drive this process so in a short period of time we think that we might be able to increase what the basic question is of, what is life / we're truly you know have modest goals of replacing the whole petrol chemical industry yeah if you can't do that at ted where can you become a major source of energy but also we're now working on using these same tools to come up with instant sets of vaccines you've seen this year with flu we're always a year behind and a dollar short when it comes to the right vaccine i think that can be changed by building combinatorial vaccines in advance here's what the future may begin to look like with changing now the evolutionary tree speeding up evolution with synthetic bacteria archea and eventually eukaryotes we're a ways away from improving people our goal is just to make sure that we have a chance to survive long enough to maybe do that thank you very much [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/src/neural_punctuator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0WrMxPUQ5_8",
        "outputId": "ebd7edf9-6276-4fbf-8063-178440eebe4c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/src/neural_punctuator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd trainers/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YQYxEzDRES2",
        "outputId": "d532b6db-39a3-4600-f49c-986b58973665"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/src/neural_punctuator/trainers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python BertPunctuatorTrainer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLOszRa4RKfF",
        "outputId": "6afcbd7b-e15b-48b4-c9c8-0b033bde0dd8"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"BertPunctuatorTrainer.py\", line 6, in <module>\n",
            "    from neural_punctuator.base.BaseTrainer import BaseTrainer\n",
            "ModuleNotFoundError: No module named 'neural_punctuator'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL5YQycGR1rQ",
        "outputId": "ec906b2f-ab8b-4bca-f07a-fd857dcbb1d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dotmap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P6sWPvlSA69",
        "outputId": "b7221f2c-3289-4d04-a56a-76583c1feb8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dotmap in /usr/local/lib/python3.7/dist-packages (1.3.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPxxhGm7THZV",
        "outputId": "dbd63941-95a5-43e6-fea8-05bb2d5bfc12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==0.24.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiNdbaxkXFie",
        "outputId": "7bd09a7b-848a-4adb-b254-a8063163ac48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x77oL_SPR3IF",
        "outputId": "2da1e80e-d407-4e01-bc2c-c7c75f9365cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2022-07-07 06:33:38,777 INFO      Epoch #0\n",
            "100% 17/17 [00:09<00:00,  1.72it/s, loss=0.615, grads=1.41]\n",
            "100% 9/9 [00:01<00:00,  8.16it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.848     0.100     0.178     14504\n",
            "      period      0.001     0.500     0.002         6\n",
            "   separator      0.050     0.636     0.093       925\n",
            "       comma      0.113     0.015     0.026      1171\n",
            "\n",
            "    accuracy                          0.124     16606\n",
            "   macro avg      0.253     0.312     0.075     16606\n",
            "weighted avg      0.752     0.124     0.163     16606\n",
            "\n",
            "2022-07-07 06:33:49,842 INFO      Macro precision is: 0.2530400339381257\n",
            "2022-07-07 06:33:49,847 INFO      Macro recall is 0.3124379811240858\n",
            "2022-07-07 06:33:49,852 INFO      Macro f-score is 0.07472660921096573\n",
            "2022-07-07 06:33:49,877 INFO      AUC is: 0.5820175788746071\n",
            "2022-07-07 06:33:55,075 INFO      Epoch #1\n",
            "100% 17/17 [00:06<00:00,  2.45it/s, loss=0.508, grads=1.47]\n",
            "100% 9/9 [00:01<00:00,  8.12it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.868     0.823     0.845     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.045     0.139     0.068       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.727     16606\n",
            "   macro avg      0.228     0.241     0.228     16606\n",
            "weighted avg      0.761     0.727     0.742     16606\n",
            "\n",
            "2022-07-07 06:34:03,205 INFO      Macro precision is: 0.22831933895389694\n",
            "2022-07-07 06:34:03,212 INFO      Macro recall is 0.2407218698290127\n",
            "2022-07-07 06:34:03,220 INFO      Macro f-score is 0.22838004429651917\n",
            "2022-07-07 06:34:03,257 INFO      AUC is: 0.5893719158870899\n",
            "2022-07-07 06:34:09,497 INFO      Epoch #2\n",
            "100% 17/17 [00:07<00:00,  2.42it/s, loss=0.443, grads=0.42]\n",
            "100% 9/9 [00:01<00:00,  7.98it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.998     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.080     0.002     0.004       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.872     16606\n",
            "   macro avg      0.238     0.250     0.234     16606\n",
            "weighted avg      0.767     0.872     0.814     16606\n",
            "\n",
            "2022-07-07 06:34:17,710 INFO      Macro precision is: 0.2383523309812436\n",
            "2022-07-07 06:34:17,717 INFO      Macro recall is 0.25016133480419195\n",
            "2022-07-07 06:34:17,724 INFO      Macro f-score is 0.2339945649873437\n",
            "2022-07-07 06:34:17,764 INFO      AUC is: 0.57736215290529\n",
            "2022-07-07 06:34:25,273 INFO      Epoch #3\n",
            "100% 17/17 [00:07<00:00,  2.40it/s, loss=0.439, grads=0.32]\n",
            "100% 9/9 [00:01<00:00,  8.03it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.999     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.872     16606\n",
            "   macro avg      0.218     0.250     0.233     16606\n",
            "weighted avg      0.763     0.872     0.814     16606\n",
            "\n",
            "2022-07-07 06:34:33,520 INFO      Macro precision is: 0.2183147422369611\n",
            "2022-07-07 06:34:33,526 INFO      Macro recall is 0.24963803088803088\n",
            "2022-07-07 06:34:33,533 INFO      Macro f-score is 0.23292804528933064\n",
            "2022-07-07 06:34:33,569 INFO      AUC is: 0.5550349345346567\n",
            "2022-07-07 06:34:41,466 INFO      Epoch #4\n",
            "100% 17/17 [00:07<00:00,  2.40it/s, loss=0.386, grads=0.288]\n",
            "100% 9/9 [00:01<00:00,  7.94it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.999     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.873     16606\n",
            "   macro avg      0.218     0.250     0.233     16606\n",
            "weighted avg      0.763     0.873     0.814     16606\n",
            "\n",
            "2022-07-07 06:34:49,761 INFO      Macro precision is: 0.21833192720260336\n",
            "2022-07-07 06:34:49,767 INFO      Macro recall is 0.2497931605074462\n",
            "2022-07-07 06:34:49,773 INFO      Macro f-score is 0.2330053379638562\n",
            "2022-07-07 06:34:49,809 INFO      AUC is: 0.5432678024274056\n",
            "2022-07-07 06:34:57,095 INFO      Epoch #5\n",
            "100% 17/17 [00:07<00:00,  2.39it/s, loss=0.407, grads=0.227]\n",
            "100% 9/9 [00:01<00:00,  7.96it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     1.000     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.873     16606\n",
            "   macro avg      0.218     0.250     0.233     16606\n",
            "weighted avg      0.763     0.873     0.814     16606\n",
            "\n",
            "2022-07-07 06:35:05,399 INFO      Macro precision is: 0.2183452804047949\n",
            "2022-07-07 06:35:05,404 INFO      Macro recall is 0.2499138168781026\n",
            "2022-07-07 06:35:05,410 INFO      Macro f-score is 0.2330654235653432\n",
            "2022-07-07 06:35:05,445 INFO      AUC is: 0.5365051069217042\n",
            "2022-07-07 06:35:13,260 INFO      Epoch #6\n",
            "100% 17/17 [00:07<00:00,  2.38it/s, loss=0.396, grads=0.207]\n",
            "100% 9/9 [00:01<00:00,  7.89it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.999     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.873     16606\n",
            "   macro avg      0.218     0.250     0.233     16606\n",
            "weighted avg      0.763     0.873     0.814     16606\n",
            "\n",
            "2022-07-07 06:35:21,623 INFO      Macro precision is: 0.21833955898301\n",
            "2022-07-07 06:35:21,630 INFO      Macro recall is 0.24986210700496414\n",
            "2022-07-07 06:35:21,637 INFO      Macro f-score is 0.23303967590508648\n",
            "2022-07-07 06:35:21,681 INFO      AUC is: 0.5345741407658094\n",
            "2022-07-07 06:35:29,406 INFO      Epoch #7\n",
            "100% 17/17 [00:07<00:00,  2.39it/s, loss=0.387, grads=0.23]\n",
            "100% 9/9 [00:01<00:00,  7.88it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     1.000     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.873     16606\n",
            "   macro avg      0.218     0.250     0.233     16606\n",
            "weighted avg      0.763     0.873     0.814     16606\n",
            "\n",
            "2022-07-07 06:35:37,732 INFO      Macro precision is: 0.21834718708589326\n",
            "2022-07-07 06:35:37,736 INFO      Macro recall is 0.24993105350248207\n",
            "2022-07-07 06:35:37,740 INFO      Macro f-score is 0.23307400501510964\n",
            "2022-07-07 06:35:37,764 INFO      AUC is: 0.5282819174813094\n",
            "2022-07-07 06:35:43,525 INFO      Epoch #8\n",
            "100% 17/17 [00:07<00:00,  2.40it/s, loss=0.423, grads=0.295]\n",
            "100% 9/9 [00:01<00:00,  7.88it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.996     0.931     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.045     0.003     0.006       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.870     16606\n",
            "   macro avg      0.230     0.250     0.234     16606\n",
            "weighted avg      0.765     0.870     0.813     16606\n",
            "\n",
            "2022-07-07 06:35:51,802 INFO      Macro precision is: 0.22951134044993607\n",
            "2022-07-07 06:35:51,806 INFO      Macro recall is 0.24975937672366244\n",
            "2022-07-07 06:35:51,810 INFO      Macro f-score is 0.23414103083340176\n",
            "2022-07-07 06:35:51,834 INFO      AUC is: 0.529587644445408\n",
            "2022-07-07 06:35:57,399 INFO      Epoch #9\n",
            "100% 17/17 [00:07<00:00,  2.40it/s, loss=0.4, grads=0.181]\n",
            "100% 9/9 [00:01<00:00,  7.85it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.999     0.932     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.873     16606\n",
            "   macro avg      0.218     0.250     0.233     16606\n",
            "weighted avg      0.763     0.873     0.814     16606\n",
            "\n",
            "2022-07-07 06:36:05,673 INFO      Macro precision is: 0.21833001868257698\n",
            "2022-07-07 06:36:05,678 INFO      Macro recall is 0.24977592388306674\n",
            "2022-07-07 06:36:05,682 INFO      Macro f-score is 0.23299675209827314\n",
            "2022-07-07 06:36:05,707 INFO      AUC is: 0.5372397706434838\n",
            "2022-07-07 06:36:11,707 INFO      Epoch #10\n",
            "100% 17/17 [00:07<00:00,  2.39it/s, loss=0.402, grads=0.433]\n",
            "100% 9/9 [00:01<00:00,  7.80it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.996     0.930     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.016     0.001     0.002       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.870     16606\n",
            "   macro avg      0.222     0.249     0.233     16606\n",
            "weighted avg      0.763     0.870     0.813     16606\n",
            "\n",
            "2022-07-07 06:36:20,021 INFO      Macro precision is: 0.22235160937136175\n",
            "2022-07-07 06:36:20,025 INFO      Macro recall is 0.24923607280750137\n",
            "2022-07-07 06:36:20,030 INFO      Macro f-score is 0.23310718313008746\n",
            "2022-07-07 06:36:20,054 INFO      AUC is: 0.5423171358566147\n",
            "2022-07-07 06:36:25,684 INFO      Epoch #11\n",
            "100% 17/17 [00:07<00:00,  2.39it/s, loss=0.384, grads=0.308]\n",
            "100% 9/9 [00:01<00:00,  7.77it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       empty      0.873     0.997     0.931     14504\n",
            "      period      0.000     0.000     0.000         6\n",
            "   separator      0.000     0.000     0.000       925\n",
            "       comma      0.000     0.000     0.000      1171\n",
            "\n",
            "    accuracy                          0.871     16606\n",
            "   macro avg      0.218     0.249     0.233     16606\n",
            "weighted avg      0.763     0.871     0.813     16606\n",
            "\n",
            "2022-07-07 06:36:33,998 INFO      Macro precision is: 0.21828200483091786\n",
            "2022-07-07 06:36:34,004 INFO      Macro recall is 0.24922435190292333\n",
            "2022-07-07 06:36:34,008 INFO      Macro f-score is 0.2327292042235385\n",
            "2022-07-07 06:36:34,033 INFO      AUC is: 0.5337287738593341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from neural_punctuator.utils.data import get_config_from_yaml\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "torch.manual_seed(69)\n",
        "np.random.seed(69)\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/src/neural_punctuator/dataset/\""
      ],
      "metadata": {
        "id": "yBewE9BwSAYk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_config_from_yaml('/content/drive/MyDrive/src/neural_punctuator/configs/config-bert-base-uncased-unfreeze.yaml')\n",
        "config.trainer.load_model = \"bert-base-uncased-epoch-1.pth\""
      ],
      "metadata": {
        "id": "NJcX-QP5aZKN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path + 'test_texts_2012.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.readlines()"
      ],
      "metadata": {
        "id": "XoTXuzGTbPFC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_text[:1000])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8UkXNeCbwrB",
        "outputId": "4ae74ada-0ab3-4c44-e1cc-406c7dce160e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['You know, cadaver dissection is the traditional way of learning human anatomy. For students, it\\'s quite an experience, but for a school, it could be very difficult or expensive to maintain. So we learned the majority of anatomic classes taught, they do not have a cadaver dissection lab. Maybe those reasons, or depending on where you are, cadavers may not be easily available. So to address this, we developed with a Dr. Brown in Stanford: virtual dissection table. So we call this Anatomage Table. So with this Anatomage Table, students can experience the dissection without a human cadaver. And the table form is important, and since it\\'s touch-interactive, just like the way they do dissections in the lab, or furthermore just the way a surgeon operates on a patient you can literally interact with your table. Our digital body is one-to-one life size, so this is exactly the way students will see the real anatomy. I\\'m going to do some demonstrations. As you can see, I use my finger to interact with my digital body. I\\'m going to do some cuts. I can cut any way I want to, so I cut right here. Then it\\'s going to show inside. And I can change my cut to see different parts. Maybe I can cut there, see the brain, and I can change my cut. You can see some internal organs. So we call this the slicer mode. OK, I\\'m going to do another cut. Right there. This shows a lot of internal structures. So if I want to see the back side, I can flip and see from behind. Like this. So if these images are uncomfortable to you or disturbing to you, that means we did the right job. So our doctors said these are eye candies. So instead of just butchering the body, I\\'d like to do more clinically meaningful dissections. What I\\'m going to do is I\\'m going to peel off all the skin, muscles and bones, just to see a few internal organs. Right here. Let\\'s say I\\'m going to cut the liver right here. OK. Let\\'s say I\\'m interested in looking at the heart. I\\'m going to do some surgery here. I\\'m going to cut some veins, arteries. Oops! ... You don\\'t want to hear \"oops\" in real surgery. But fortunately, our digital man has \"undo.\" OK. All right then. Let me zoom in. I\\'m going to make a cut right there. And then you can see the inside of the heart. You can see the atrium and the ventricles, how blood flows to our arteries and veins. Just like this, students can isolate anybody and dissect any way you want to. It doesn\\'t have to be always dissection. Since it\\'s digital, we can do reverse dissection. So let me show you, I\\'m going to start with the skeletal structure, and I can add a few internal organs. Yep. Maybe I can add quickly this way. And I can build muscles gradually, just like that. We can see tendons and muscles. Wish I could build my muscle this fast. And this is another way to learn anatomy. Another thing I can show you is, more often than not, doctors get to meet patients in X-ray form. So, Anatomage Table shows exactly how the anatomy will appear in X-ray. You can also interact with your X-ray, and also if you want, you can compare with how anatomy would appear in X-ray, too. So when you are done, just bring back the body and then it\\'s ready for another session. It looks like our table also can transform gender, too. It\\'s a female now. So this is Anatomage Table. Thank you.\\n', 'Hi, my name is Frank, and I collect secrets. It all started with a crazy idea in November of 2004. I printed up 3,000 self-addressed postcards, just like this. They were blank on one side, and on the other side I listed some simple instructions. I asked people to anonymously share an artful secret they\\'d never told anyone before. And I handed out these postcards randomly on the streets of Washington, D.C., not knowing what to expect. But soon the idea began spreading virally. People began to buy their own postcards and make their own postcards. I started receiving secrets in my home mailbox, not just with postmarks from Washington, D.C., but from Texas, California, Vancouver, New Zealand, Iraq. Soon my crazy idea didn\\'t seem so crazy. PostSecret.com is the most visited advertisement-free blog in the world. And this is my postcard collection today. You can see my wife struggling to stack a brick of postcards on a pyramid of over a half-million secrets. What I\\'d like to do now is share with you a very special handful of secrets from that collection, starting with this one. \"I found these stamps as a child, and I have been waiting all my life to have someone to send them to. I never did have someone.\" Secrets can take many forms. They can be shocking or silly or soulful. They can connect us to our deepest humanity or with people we\\'ll never meet. Maybe one of you sent this one in. I don\\'t know. This one does a great job of demonstrating the creativity that people have when they make and mail me a postcard. This one obviously was made out of half a Starbucks cup with a stamp and my home address written on the other side. \"Dear Birthmother, I have great parents. I\\'ve found love. I\\'m happy.\" Secrets can remind us of the countless human dramas, of frailty and heroism, playing out silently in the lives of people all around us even now. \"Everyone who knew me before 9/11 believes I\\'m dead.\" \"I used to work with a bunch of uptight religious people, so sometimes I didn\\'t wear panties, and just had a big smile and chuckled to myself.\" This next one takes a little explanation before I share it with you. I love to speak on college campuses and share secrets and the stories with students. And sometimes afterwards I\\'ll stick around and sign books and take photos with students. And this next postcard was made out of one of those photos. And I should also mention that, just like today, at that PostSecret event, I was using a wireless microphone. \"Your mic wasn\\'t off during sound check. We all heard you pee.\" This was really embarrassing when it happened, until I realized it could have been worse. Right. You know what I\\'m saying. \"Inside this envelope is the ripped up remains of a suicide note I didn\\'t use. I feel like the happiest person on Earth \" \"One of these men is the father of my son. He pays me a lot to keep it a secret.\" \"That Saturday when you wondered where I was, well, I was getting your ring. It\\'s in my pocket right now.\" I had this postcard posted on the PostSecret blog two years ago on Valentine\\'s Day. It was the very bottom, the last secret in the long column. And it hadn\\'t been up for more than a couple hours before I received this exuberant email from the guy who mailed me this postcard. And he said, \"Frank, I\\'ve got to share with you this story that just played out in my life.\" He said, \"My knees are still shaking.\" He said, \"For three years, my girlfriend and I, we\\'ve made it this Sunday morning ritual to visit the PostSecret blog together and read the secrets out loud. I read some to her, she reads some to me.\" He says, \"It\\'s really brought us closer together through the years. And so when I discovered that you had posted my surprise proposal to my girlfriend at the very bottom, I was beside myself. And I tried to act calm, not to give anything away. And just like every Sunday, we started reading the secrets out loud to each other.\" He said, \"But this time it seemed like it was taking her forever to get through each one.\" But she finally did. She got to that bottom secret, his proposal to her. And he said, \"She read it once and then she read it again.\" And she turned to him and said, \"Is that our cat?\" And when she saw him, he was down on one knee, he had the ring out. He popped the question, she said yes. It was a very happy ending. So I emailed him back and I said, \"Please share with me an image, something, that I can share with the whole PostSecret community and let everyone know your fairy tale ending.\" And he emailed me this picture. \"I found your camera at Lollapalooza this summer. I finally got the pictures developed and I\\'d love to give them to you.\" This picture never got returned back to the people who lost it, but this secret has impacted many lives, starting with a student up in Canada named Matty. Matty was inspired by that secret to start his own website, a website called IFoundYourCamera. Matty invites people to mail him digital cameras that they\\'ve found, memory sticks that have been lost with orphan photos. And Matty takes the pictures off these cameras and posts them on his website every week. And people come to visit to see if they can identify a picture they\\'ve lost or help somebody else get the photos back to them that they might be desperately searching for. This one\\'s my favorite. Matty has found this ingenious way to leverage the kindness of strangers. And it might seem like a simple idea, and it is, but the impact it can have on people\\'s lives can be huge. Matty shared with me an emotional email he received from the mother in that picture. \"That\\'s me, my husband and son. The other pictures are of my very ill grandmother. Thank you for making your site. These pictures mean more to me than you know. My son\\'s birth is on this camera. He turns four tomorrow.\" Every picture that you see there and thousands of others have been returned back to the person who lost it -- sometimes crossing oceans, sometimes going through language barriers. This is the last postcard I have to share with you today. \"When people I love leave voicemails on my phone I always save them in case they die tomorrow and I have no other way of hearing their voice ever again.\" When I posted this secret, dozens of people sent voicemail messages from their phones, sometimes ones they\\'d been keeping for years, messages from family or friends who had died. They said that by preserving those voices and sharing them, it helped them keep the spirit of their loved ones alive. One young girl posted the last message she ever heard from her grandmother. Secrets can take many forms. They can be shocking or silly or soulful. They can connect us with our deepest humanity or with people we\\'ll never meet again. First saved voice message. It\\'s somebody\\'s birthday today Somebody\\'s birthday today The candles are lighted on somebody\\'s cake And we\\'re all invited for somebody\\'s sake You\\'re 21 years old today. Have a real happy birthday, and I love you. I\\'ll say bye for now. Thank you.\\n', \"I call myself a body architect. I trained in classical ballet and have a background in architecture and fashion. As a body architect, I fascinate with the human body and explore how I can transform it. I worked at Philips Electronics in the far-future design research lab, looking 20 years into the future. I explored the human skin, and how technology can transform the body. I worked on concepts like an electronic tattoo, which is augmented by touch, or dresses that blushed and shivered with light. I started my own experiments. These were the low-tech approaches to the high-tech conversations I was having. These are Q-tips stuck to my roommate with wig glue. I started a collaboration with a friend of mine, Bart Hess -- he doesn't normally look like this -- and we used ourselves as models. We transformed our apartments into our laboratories, and worked in a very spontaneous and immediate way. We were creating visual imagery provoking human evolution. Whilst I was at Philips, we discussed this idea of a maybe technology, something that wasn't either switched on or off, but in between. A maybe that could take the form of a gas or a liquid. And I became obsessed with this idea of blurring the perimeter of the body, so you couldn't see where the skin ended and the near environment started. I set up my studio in the red-light district and obsessively wrapped myself in plumbing tubing, and found a way to redefine the skin and create this dynamic textile. I was introduced to Robyn, the Swedish pop star, and she was also exploring how technology coexists with raw human emotion. And she talked about how technology with these new feathers, this new face paint, this punk, the way that we identify with the world, and we made this music video. I'm fascinated with the idea of what happens when you merge biology with technology, and I remember reading about this idea of being able to reprogram biology, in the future, away from disease and aging. And I thought about this concept of, imagine if we could reprogram our own body odor, modify and biologically enhance it, and how would that change the way that we communicate with each other? Or the way that we attract sexual partners? And would we revert back to being more like animals, more primal modes of communication? I worked with a synthetic biologist, and I created a swallowable perfume, which is a cosmetic pill that you eat and the fragrance comes out through the skin's surface when you perspire. It completely blows apart the way that perfume is, and provides a whole new format. It's perfume coming from the inside out. It redefines the role of skin, and our bodies become an atomizer. I've learned that there's no boundaries, and if I look at the evolution of my work i can see threads and connections that make sense. But when I look towards the future, the next project is completely unknown and wide open. I feel like I have all these ideas existing embedded inside of me, and it's these conversations and these experiences that connect these ideas, and they kind of instinctively come out. As a body architect, I've created this limitless and boundless platform for me to discover whatever I want. And I feel like I've just got started. So here's to another day at the office.\\n\", 'Last January, my company, Fark.com, was sued along with Yahoo, MSN, Reddit, AOL, TechCrunch and others by a company called Gooseberry Natural Resources. Gooseberry owned a patent for the creation and distribution of news releases via email. Now it may seem kind of strange that such a thing can actually be patented, but it does happen all the time. Take something already being done and patent it for an emerging technology -- like phone calls on the internet or video listings for TV shows or radio but for cellphones, and so on. The problem with these patents is that the mechanisms are obscure and the patent system is dysfunctional, and as a result, most of these lawsuits end in settlements. And because these settlements are under a non-disclosure agreement, no one knows what the terms were. And as a result, the patent troll can claim that they won the case. In the case of Gooseberry Natural Resources, this patent on emailing news releases had sort of a fatal flaw as it pertained to myself, and that was that in the mainstream media world there is only one definition for news release, and it turns out that is press release -- as in P.R. Now my company, Fark, deals with news, ostensibly, and as a result we were not in violation of this patent. So case closed, right? Wrong. One of the major problems with patent law is that, in the case that when you are sued by a patent troll, the burden of proof that you did not infringe on the patent is actually on the defendant, which means you have to prove that you do not infringe on the patent they\\'re suing you on. And this can take quite a while. You need to know that the average patent troll defense costs two million dollars and takes 18 months when you win. That is your best case outcome when you get sued by a patent troll. Now I had hoped to team up with some of these larger companies in order to defend against this lawsuit, but one-by-one they settled out of the case, even though -- and this is important -- none of these companies infringed on this patent -- not a one of them. And they started settling out. The reason they settled out is because it\\'s cheaper to settle than to fight the lawsuit -- clearly, two million dollars cheaper in some cases, and much worse if you actually lose. It would also constitute a massive distraction for management of a company, especially a small eight-man shop like my company. Six months into the lawsuit, we finally reached the discovery phase. And in discovery phase, we asked the patent troll to please provide screenshots of Fark where the infringement of their patent was actually occurring. Now perhaps it\\'s because no such screenshots actually existed, but suddenly Gooseberry wanted to settle. Their attorney: \"Ah, yes. My company\\'s having a reorganization on our end.\" Never mind the fact that the address led to a strip mall somewhere in Northern L.A. with no employees. \"And we\\'d like to go ahead and close this out. So would you mind giving us your best and final offer?\" My response: \"How about nothing?!\" We didn\\'t have high hopes for that outcome. But they settled. No counter offer. Now, as mentioned before, one of the reasons I can talk to you about this is because there\\'s no non-disclosure agreement on this case. Now how did that happen? Well during the settlement process, when we received our copy, I struck it. My attorney said, \"Nah, no chance of that working.\" It came back signed. Now why? You can call them. They\\'re not under NDA either. Now what did I learn from this case? Well, three things. First of all, if you can, don\\'t fight the patent, fight the infringement. Patents are very difficult to overturn. Infringement is a lot easier to disprove. Secondly, make it clear from the beginning that either you have no money at all or that you would rather spend money with your attorney fighting the troll than actually giving them the money. Now the reason this works is because patent trolls are paid a percentage of what they\\'re able to recover in settlements. If it becomes clear to them that they cannot recover any money, they become less interested in pursuing the case. Finally, make sure that you can tell them that you will make this process as annoying and as painful and as difficult as possible for them. Now this is a tactic that patent trolls are supposed to use on people to get their way. It turns out, because they\\'re paid on contingency, it works really, really well in reverse. Don\\'t forget that. So what does all this mean? Well to sum up, it boils down to one thing: Don\\'t negotiate with terrorists. Patent trolls have done more damage to the United States economy than any domestic or foreign terrorist organization in history every year. And what do they do with that money? They plow it right back into filing more troll lawsuits. Now this is the point in the Talk where I\\'m supposed to come up with some kind of a solution for the patent system. And the problem with that is that there are two very large industry groups that have different outcomes in mind for the patent system. The health care industry would like stronger protections for inventors. The hi-tech industry would like stronger protections for producers. And these goals aren\\'t necessarily diametrically opposed, but they are at odds. And as a result, patent trolls can kind of live in the space in between. So unfortunately I\\'m not smart enough to have a solution for the patent troll problem. However, I did have this idea, and it was kind of good. And I thought, \"I should patent this.\" Behold, patent infringement via mobile device -- defined as a computer which is not stationary. My solution: award me this patent and I will troll them out of existence. Thank you.\\n', 'I was born in Den Bosch, where the painter Hieronymus Bosch named himself after. And so I\\'ve always been very fond of this painter who lived and worked in the 15th century. And what is interesting about him in relation to morality is that he lived at a time where religion\\'s influence was waning, and he was sort of wondering, I think, what would happen with society if there was no religion or if there was less religion. And so he painted this famous painting, \"The Garden of Earthly Delights,\" which some have interpreted as being humanity before the Fall, or being humanity without any Fall at all. And so it makes you wonder, what would happen if we hadn\\'t tasted the fruit of knowledge, so to speak, and what kind of morality would we have? Much later, as a student, I went to a very different garden, a zoological garden in Arnhem where we keep chimpanzees. This is me at an early age with a baby chimpanzee. And I discovered there that the chimpanzees are very power hungry and wrote a book about it. And at that time the focus in a lot of animal research was on aggression and competition. I painted a whole picture of the animal kingdom, and humanity included, was that deep down we are competitors, we are aggressive, we\\'re all out for our own profit basically. This is the launch of my book. I\\'m not sure how well the chimpanzees read it, but they surely seemed interested in the book. Now in the process of doing all this work on power and dominance and aggression and so on, I discovered that chimpanzees reconcile after fights. And so what you see here is two males who have had a fight. They ended up in a tree, and one of them holds out a hand to the other. And about a second after I took the picture, they came together in the fork of the tree and they kissed and embraced each other. Now this is very interesting because at the time everything was about competition and aggression, and so it wouldn\\'t make any sense. The only thing that matters is that you win or that you lose. But why would you reconcile after a fight? That doesn\\'t make any sense. This is the way bonobos do it. Bonobos do everything with sex. And so they also reconcile with sex. But the principle is exactly the same. The principle is that you have a valuable relationship that is damaged by conflict, so you need to do something about it. So my whole picture of the animal kingdom, and including humans also, started to change at that time. So we have this image in political science, economics, the humanities, philosophy for that matter, that man is a wolf to man. And so deep down our nature\\'s actually nasty. I think it\\'s a very unfair image for the wolf. The wolf is, after all, a very cooperative animal. And that\\'s why many of you have a dog at home, which has all these characteristics also. And it\\'s really unfair to humanity, because humanity is actually much more cooperative and empathic than given credit for. So I started getting interested in those issues and studying that in other animals. So these are the pillars of morality. If you ask anyone, \"What is morality based on?\" these are the two factors that always come out. One is reciprocity, and associated with it is a sense of justice and a sense of fairness. And the other one is empathy and compassion. And human morality is more than this, but if you would remove these two pillars, there would be not much remaining I think. And so they\\'re absolutely essential. So let me give you a few examples here. This is a very old video from the Yerkes Primate Center where they train chimpanzees to cooperate. So this is already about a hundred years ago that we were doing experiments on cooperation. What you have here is two young chimpanzees who have a box, and the box is too heavy for one chimp to pull in. And of course, there\\'s food on the box. Otherwise they wouldn\\'t be pulling so hard. And so they\\'re bringing in the box. And you can see that they\\'re synchronized. You can see that they work together, they pull at the same moment. It\\'s already a big advance over many other animals who wouldn\\'t be able to do that. And now you\\'re going to get a more interesting picture, because now one of the two chimps has been fed. So one of the two is not really interested in the task anymore. Now look at what happens at the very end of this. He takes basically everything. So there are two interesting parts about this. One is that the chimp on the right has a full understanding he needs the partner -- so a full understanding of the need for cooperation. The second one is that the partner is willing to work even though he\\'s not interested in the food. Why would that be? Well that probably has to do with reciprocity. There\\'s actually a lot of evidence in primates and other animals that they return favors. So he will get a return favor at some point in the future. And so that\\'s how this all operates. We do the same task with elephants. Now with elephants, it\\'s very dangerous to work with elephants. Another problem with elephants is that you cannot make an apparatus that is too heavy for a single elephant. Now you can probably make it, but it\\'s going to be a pretty flimsy apparatus I think. And so what we did in that case -- we do these studies in Thailand for Josh Plotnik -- is we have an apparatus around which there is a rope, a single rope. And if you pull on this side of the rope, the rope disappears on the other side. So two elephants need to pick it up at exactly the same time and pull. Otherwise nothing is going to happen and the rope disappears. And the first tape you\\'re going to see is two elephants who are released together arrive at the apparatus. The apparatus is on the left with food on it. And so they come together, they arrive together, they pick it up together and they pull together. So it\\'s actually fairly simple for them. There they are. And so that\\'s how they bring it in. But now we\\'re going to make it more difficult. Because the whole purpose of this experiment is to see how well they understand cooperation. Do they understand that as well as the chimps, for example? And so what we do in the next step is we release one elephant before the other, and that elephant needs to be smart enough to stay there and wait and not pull at the rope -- because if he pulls at the rope, it disappears and the whole test is over. Now this elephant does something illegal that we did not teach it. But it shows the understanding that he has, because he puts his big foot on the rope, stands on the rope and waits there for the other, and then the other is going to do all the work for him. So it\\'s what we call freeloading. But it shows the intelligence that the elephants have. They develop several of these alternative techniques that we did not approve of necessarily. So the other elephant is now coming and is going to pull it in. Now look at the other. The other doesn\\'t forget to eat, of course. This was the cooperation, reciprocity part. Now something on empathy. Empathy is my main topic at the moment of research. And empathy has sort of two qualities. One is the understanding part of it. This is just a regular definition: the ability to understand and share the feelings of another. And the emotional part. And so empathy has basically two channels. One is the body channel. If you talk with a sad person, you\\'re going to adopt a sad expression and a sad posture, and before you know it you feel sad. And that\\'s sort of the body channel of emotional empathy, which many animals have. Your average dog has that also. That\\'s actually why people keep mammals in the home and not turtles or snakes or something like that who don\\'t have that kind of empathy. And then there\\'s a cognitive channel, which is more that you can take the perspective of somebody else. And that\\'s more limited. There\\'s few animals -- I think elephants and apes can do that kind of thing -- but there are very few animals who can do that. So synchronization, which is part of that whole empathy mechanism is a very old one in the animal kingdom. And in humans, of course, we can study that with yawn contagion. Humans yawn when others yawn. And it\\'s related to empathy. It activates the same areas in the brain. Also, we know that people who have a lot of yawn contagion are highly empathic. People who have problems with empathy, such as autistic children, they don\\'t have yawn contagion. So it is connected. And we study that in our chimpanzees by presenting them with an animated head. So that\\'s what you see on the upper-left, an animated head that yawns. And there\\'s a chimpanzee watching, an actual real chimpanzee watching a computer screen on which we play these animations. So yawn contagion that you\\'re probably all familiar with -- and maybe you\\'re going to start yawning soon now -- is something that we share with other animals. And that\\'s related to that whole body channel of synchronization that underlies empathy and that is universal in the mammals basically. Now we also study more complex expressions. This is consolation. This is a male chimpanzee who has lost a fight and he\\'s screaming, and a juvenile comes over and puts an arm around him and calms him down. That\\'s consolation. It\\'s very similar to human consolation. And consolation behavior, it\\'s empathy driven. Actually the way to study empathy in human children is to instruct a family member to act distressed, and then they see what young children do. And so it is related to empathy, and that\\'s the kind of expressions we look at. We also recently published an experiment you may have heard about. It\\'s on altruism and chimpanzees where the question is, do chimpanzees care about the welfare of somebody else? And for decades it had been assumed that only humans can do that, that only humans worry about the welfare of somebody else. Now we did a very simple experiment. We do that on chimpanzees that live in Lawrenceville, in the field station of Yerkes. And so that\\'s how they live. And we call them into a room and do experiments with them. In this case, we put two chimpanzees side-by-side. and one has a bucket full of tokens, and the tokens have different meanings. One kind of token feeds only the partner who chooses, the other one feeds both of them. So this is a study we did with Vicky Horner. And here you have the two color tokens. So they have a whole bucket full of them. And they have to pick one of the two colors. You will see how that goes. So if this chimp makes the selfish choice, which is the red token in this case, he needs to give it to us. So we pick it up, we put it on a table where there\\'s two food rewards, but in this case only the one on the right gets food. The one on the left walks away because she knows already. that this is not a good test for her. Then the next one is the pro-social token. So the one who makes the choices -- that\\'s the interesting part here -- for the one who makes the choices, it doesn\\'t really matter. So she gives us now a pro-social token and both chimps get fed. So the one who makes the choices always gets a reward. So it doesn\\'t matter whatsoever. And she should actually be choosing blindly. But what we find is that they prefer the pro-social token. So this is the 50 percent line that\\'s the random expectation. And especially if the partner draws attention to itself, they choose more. And if the partner puts pressure on them -- so if the partner starts spitting water and intimidating them -- then the choices go down. It\\'s as if they\\'re saying, \"If you\\'re not behaving, I\\'m not going to be pro-social today.\" And this is what happens without a partner, when there\\'s no partner sitting there. And so we found that the chimpanzees do care about the well-being of somebody else -- especially, these are other members of their own group. So the final experiment that I want to mention to you is our fairness study. And so this became a very famous study. And there\\'s now many more, because after we did this about 10 years ago, it became very well known. And we did that originally with capuchin monkeys. And I\\'m going to show you the first experiment that we did. It has now been done with dogs and with birds and with chimpanzees. But with Sarah Brosnan we started out with capuchin monkeys. So what we did is we put two capuchin monkeys side-by-side. Again, these animals, they live in a group, they know each other. We take them out of the group, put them in a test chamber. And there\\'s a very simple task that they need to do. And if you give both of them cucumber for the task, the two monkeys side-by-side, they\\'re perfectly willing to do this 25 times in a row. So cucumber, even though it\\'s only really water in my opinion, but cucumber is perfectly fine for them. Now if you give the partner grapes -- the food preferences of my capuchin monkeys correspond exactly with the prices in the supermarket -- and so if you give them grapes -- it\\'s a far better food -- then you create inequity between them. So that\\'s the experiment we did. Recently we videotaped it with new monkeys who\\'d never done the task, thinking that maybe they would have a stronger reaction, and that turned out to be right. The one on the left is the monkey who gets cucumber. The one on the right is the one who gets grapes. The one who gets cucumber, note that the first piece of cucumber is perfectly fine. The first piece she eats. Then she sees the other one getting grape, and you will see what happens. So she gives a rock to us. That\\'s the task. And we give her a piece of cucumber and she eats it. The other one needs to give a rock to us. And that\\'s what she does. And she gets a grape and she eats it. The other one sees that. She gives a rock to us now, gets, again, cucumber. She tests a rock now against the wall. She needs to give it to us. And she gets cucumber again. So this is basically the Wall Street protest that you see here. Let me tell you -- I still have two minutes left, let me tell you a funny story about this. This study became very famous and we got a lot of comments, especially anthropologists, economists, philosophers. They didn\\'t like this at all. Because they had decided in their minds, I believe, that fairness is a very complex issue and that animals cannot have it. And so one philosopher even wrote us that it was impossible that monkeys had a sense of fairness because fairness was invented during the French Revolution. Now another one wrote a whole chapter saying that he would believe it had something to do with fairness if the one who got grapes would refuse the grapes. Now the funny thing is that Sarah Brosnan, who\\'s been doing this with chimpanzees, had a couple of combinations of chimpanzees where, indeed, the one who would get the grape would refuse the grape until the other guy also got a grape. So we\\'re getting very close to the human sense of fairness. And I think philosophers need to rethink their philosophy for awhile. So let me summarize. I believe there\\'s an evolved morality. I think morality is much more than what I\\'ve been talking about, but it would be impossible without these ingredients that we find in other primates, which are empathy and consolation, pro-social tendencies and reciprocity and a sense of fairness. And so we work on these particular issues to see if we can create a morality from the bottom up, so to speak, without necessarily God and religion involved, and to see how we can get to an evolved morality. And I thank you for your attention.\\n', 'I\\'m a process engineer. I know all about boilers and incinerators and fabric filters and cyclones and things like that, but I also have Marfan syndrome. This is an inherited disorder. And in 1992 I participated in a genetic study and found to my horror, as you can see from the slide, that my ascending aorta was not in the normal range, the green line at the bottom. Everyone in here will be between 3.2 and 3.6 cm. I was already up at 4.4. And as you can see, my aorta dilated progressively, and I got closer and closer to the point where surgery was going to be necessary. The surgery on offer was pretty gruesome -- anesthetize you, open your chest, put you on an artificial heart and lung machine, drop your body temperature to about 18 centigrade, stop your heart, cut the aorta out, replace it with a plastic valve and a plastic aorta, and, most importantly, commit you to a lifetime of anticoagulation therapy, normally warfarin. The thought of the surgery was not attractive. The thought of the warfarin was really quite frightening. So I said to myself, I\\'m an engineer, I\\'m in R and D, this is just a plumbing problem. I can do this. I can change this. So I set out to change the entire treatment for aortic dilation. The project aim is really quite simple. The only real problem with the ascending aorta in people with Marfan syndrome is it lacks some tensile strength. So the possibility exists to simply externally wrap the pipe. And it would remain stable and operate quite happily. If your high-pressure hose pipe, or your high-pressure hydraulic line, bulges a little, you just wrap some tape around the outside of it. It really is that simple in concept, though not in execution. The great advantage of an external support for me was that I could retain all of my own bits, all of my own endothelium and valves, and not need any anticoagulation therapy. So where do we start? Well this is a sagittal slice through me. You could see in the middle that device, that little structure, squeezing out. Now that\\'s a left ventricle pushing blood up through the aortic valve -- you can see two of the leaflets of the aortic valve working there -- up into the ascending aorta. And it\\'s that part, the ascending aorta, which dilates and ultimately bursts, which, of course, is fatal. We started by organizing image acquisition from magnetic resonance imaging machines and CT imaging machines from which to make a model of the patient\\'s aorta. This is a model of my aorta. I\\'ve got a real one in my pocket, if anyone would like to look at it and play with it. You can see, it\\'s quite a complex structure. It has a funny trilobal shape at the bottom, which contains the aortic valve. It then comes back into a round form and then tapers and curves off. So it\\'s quite a difficult structure to produce. This, like I say, is a CAD model of me, and this is one of the later CAD models. We went through an iterative process of producing better and better models. When we produced that model we turn it into a solid plastic model, as you can see, using a rapid prototyping technique, another engineering technique. We then use that former to manufacture a perfectly bespoke porous textile mesh, which takes the shape of the former and perfectly fits the aorta. So this is absolutely personalized medicine at its best really. Every patient we do has an absolutely bespoke implant. Once you\\'ve made it, the installation\\'s quite easy. John Pepper, bless his heart, professor of cardiothoracic surgery -- never done it before in his life -- he put the first one in, didn\\'t like it, took it out, put the second one in. Happy, away I went. Four and a half hours on the table and everything was done. So the surgical implantation actually was the easiest part. If you compare our new treatment to the existing alternative, the so-called composite aortic root graft, there are one of two startling comparisons, which I\\'m sure will be clear to all of you. Two hours to install one of our devices compared to six hours for the existing treatment. The existing treatment requires, as I\\'ve said, the heart and lung bypass machine and it requires a total body cooling. We don\\'t need any of that; we work on a beating heart. He opens you up, he accesses the aorta while your heart is beating, all at the right temperature. No breaking into your circulatory system. So it really is great. But for me, absolutely the best point is there is no anticoagulation therapy required. I don\\'t take any drugs at all other than recreational ones that I would choose to take. And in fact, if you speak to people who are on long-term warfarin, it is a serious compromise to your quality of life. And even worse, it inevitably foreshortens your life. Likewise, if you have the artificial valve option, you\\'re committed to antibiotic therapy whenever you have any intrusive medical treatment at all. Even trips to the dentist require that you take antibiotics, in case you get an internal infection on the valve. Again, I don\\'t have any of that, so I\\'m entirely free. My aorta is fixed, I haven\\'t got to worry about it, which is a rebirth for me. Back to the theme of the presentation: In multidisciplinary research, how on earth does a process engineer used to working with boilers end up producing a medical device which transforms his own life? Well the answer to that is a multidisciplinary team. This is a list of the core team. And as you can see, there are not only two principal technical disciplines there, medicine and engineering, but also there are various specialists from within those two disciplines. John Pepper there was the cardiac surgeon who did the actual work on me, but everyone else there had to contribute one way or another. Raad Mohiaddin, medical radiologist: We had to get good quality images from which to make the CAD model. Warren Thornton, who still does all our CAD models for us, had to write a bespoke piece of CAD code to produce this model from this really rather difficult input data set. There are some barriers to this though. There are some problems with it. Jargon is a big one. I would think no one in this room understands those four first jargon points there. The engineers amongst you will recognize rapid prototyping and CAD. The medics amongst you, if there are any, will recognize the first two. But there will be nobody else in this room that understands all of those four words. Taking the jargon out was very important to ensure that everyone in the team understood exactly what was meant when a particular phrase was used. Our disciplinary conventions were funny as well. We took a lot of horizontal slice images through me, produced those slices and then used those to build a CAD model. And the very first CAD model we made, the surgeons were playing with the plastic model, couldn\\'t quite figure it out. And then we realized that it was actually a mirror image of the real aorta. And it was a mirror image because in the real world we always look down on plans, plans of houses or streets or maps. In the medical world they look up at plans. So the horizontal images were all an inversion. So one needs to be careful with disciplinary conventions. Everyone needs to understand what is assumed and what is not assumed. Institutional barriers were another serious headache in the project. The Brompton Hospital was taken over by Imperial College\\'s School of Medicine, and there are some seriously bad relationship problems between the two organizations. I was working with Imperial and the Brompton, and this generated some serious problems with the project, really problems that shouldn\\'t exist. Research and ethics committee: If you want to do anything new in surgery, you have to get a license from your local research and ethics. I\\'m sure it\\'s the same in Poland. There will be some form of equivalent, which licenses new types of surgery. We didn\\'t only have the bureaucratic problems associated with that, was also had professional jealousies. There were people on the research and ethics committee who really didn\\'t want to see John Pepper succeed again, because he\\'s so successful. And they made extra problems for us. Bureaucratic problems: Ultimately when you have a new treatment you have to have a guidance note going out for all of the hospitals in the country. In the U.K. we have the National Institute for Clinical Excellence, NICE. You\\'ll have an equivalent in Poland, no doubt. We had to get past the NICE problem. We now have a great clinical guidance out on the Net. So any of the hospitals interested can come along, read the NICE report get in touch with us and then get doing it themselves. Funding barriers: Another big area to be concerned with. A big problem with understanding one of those perspectives: When we first approached one of the big U.K. charitable organizations that funds this kind of stuff, what they were looking at was essentially an engineering proposal. They didn\\'t understand it; they were doctors, they were next to God. It must be rubbish. They binned it. So in the end I went to private investors and I just gave up on it. But most R and D is going to be institutionally funded, by the Polish Academy of Sciences or the Engineering and Physical Sciences Research Council or whatever, and you need to get past those people. Jargon is a huge problem when you\\'re trying to work across disciplines, because in an engineering world, we all understand CAD and R.P. -- not in the medical world. I suppose ultimately the funding bureaucrats have really got to get their act together. They\\'ve really got to start talking to each other, and they\\'ve got to exercise a bit of imagination, if that\\'s not too much to ask -- which it probably is. I\\'ve coined a phrase \"obstructive conservatism.\" So many people in the medical world don\\'t want to change, particularly not when some jumped-up engineer has come along with the answer. They don\\'t want to change. They simply want to do whatever they\\'ve done before. And in fact, there are many surgeons in the U.K. still waiting for one of our patients to have some sort of episode, so that they can say, \"Ah, I told you that was no good.\" We\\'ve actually got 30 patients. I\\'m at seven and a half years. We\\'ve got 90 post-op patient years between us, and we haven\\'t had a single problem. And still, there are people in the U.K. saying, \"Yeah, that external aortic root, yeah, it\\'ll never work, you know.\" It really is a problem. It really is a problem. I\\'m sure everyone in this room has come across arrogance amongst medics, doctors, surgeons at some point. The middle point is simply the way that the doctors protect themselves. \"Yeah, well of course, I\\'m looking after my patient.\" I think it\\'s not good, but there you are, that\\'s my view. Egos, of course, again, a huge problem If you\\'re working in a multidisciplinary team, you\\'ve got to give your guys the benefit of the doubt. You\\'ve got to express support for them. Tom Treasure, professor of cardiothoracic surgery: incredible guy. Dead easy to give him respect. Him giving me respect? Slightly different. That\\'s all the bad news. The good news is the benefits are stonkingly huge. Translate that one. I bet they can\\'t. When you have a group of people who have had a different professional training, a different professional experience, they not only have a different knowledge base, but they have a different perspective on everything. And if you can bring those guys together and you can get them talking and understanding each other, the results can be spectacular. You can find novel solutions, really novel solutions, that have never been looked at before very, very quickly and easily. You can shortcut huge amounts of work simply by using the extended knowledge base you have. And as a result, it\\'s an entirely different use of the technology and the knowledge around you. The result of all this is that you can get incredibly quick progress on incredibly small budgets. I\\'m so embarrassed at how cheap it was to get from my idea to me being implanted that I\\'m not prepared to tell you what it cost. Because I suspect there are absolutely standard surgical treatments probably in the USA which cost more for a one-off patient than the cost of us getting from my dream to my reality. That\\'s all I want to say, and I\\'ve got three minutes left. So Heather\\'s going to like me. If you have any questions, please come up and talk to me later on. It would be a pleasure to speak with you. Many thanks.\\n', 'Just a moment ago, my daughter Rebecca texted me for good luck. Her text said, \"Mom, you will rock.\" I love this. Getting that text was like getting a hug. I embody the central paradox. I\\'m a woman who loves getting texts who\\'s going to tell you that too many of them can be a problem. Actually that reminder of my daughter brings me to the beginning of my story. 1996, when I gave my first TEDTalk, Rebecca was five years old and she was sitting right there in the front row. I had just written a book that celebrated our life on the internet and I was about to be on the cover of Wired magazine. In those heady days, we were experimenting with chat rooms and online virtual communities. We were exploring different aspects of ourselves. And then we unplugged. I was excited. And, as a psychologist, what excited me most was the idea that we would use what we learned in the virtual world about ourselves, about our identity, to live better lives in the real world. Now fast-forward to 2012. I\\'m back here on the TED stage again. My daughter\\'s 20. She\\'s a college student. She sleeps with her cellphone, so do I. And I\\'ve just written a new book, but this time it\\'s not one that will get me on the cover of Wired magazine. So what happened? I\\'m still excited by technology, but I believe, and I\\'m here to make the case, that we\\'re letting it take us places that we don\\'t want to go. Over the past 15 years, I\\'ve studied technologies of mobile communication and I\\'ve interviewed hundreds and hundreds of people, young and old, about their plugged in lives. And what I\\'ve found is that our little devices, those little devices in our pockets, are so psychologically powerful that they don\\'t only change what we do, they change who we are. Some of the things we do now with our devices are things that, only a few years ago, we would have found odd or disturbing, but they\\'ve quickly come to seem familiar, just how we do things. So just to take some quick examples: People text or do email during corporate board meetings. They text and shop and go on Facebook during classes, during presentations, actually during all meetings. People talk to me about the important new skill of making eye contact while you\\'re texting. People explain to me that it\\'s hard, but that it can be done. Parents text and do email at breakfast and at dinner while their children complain about not having their parents\\' full attention. But then these same children deny each other their full attention. This is a recent shot of my daughter and her friends being together while not being together. And we even text at funerals. I study this. We remove ourselves from our grief or from our revery and we go into our phones. Why does this matter? It matters to me because I think we\\'re setting ourselves up for trouble -- trouble certainly in how we relate to each other, but also trouble in how we relate to ourselves and our capacity for self-reflection. We\\'re getting used to a new way of being alone together. People want to be with each other, but also elsewhere -- connected to all the different places they want to be. People want to customize their lives. They want to go in and out of all the places they are because the thing that matters most to them is control over where they put their attention. So you want to go to that board meeting, but you only want to pay attention to the bits that interest you. And some people think that\\'s a good thing. But you can end up hiding from each other, even as we\\'re all constantly connected to each other. A 50-year-old business man lamented to me that he feels he doesn\\'t have colleagues anymore at work. When he goes to work, he doesn\\'t stop by to talk to anybody, he doesn\\'t call. And he says he doesn\\'t want to interrupt his colleagues because, he says, \"They\\'re too busy on their email.\" But then he stops himself and he says, \"You know, I\\'m not telling you the truth. I\\'m the one who doesn\\'t want to be interrupted. I think I should want to, but actually I\\'d rather just do things on my Blackberry.\" Across the generations, I see that people can\\'t get enough of each other, if and only if they can have each other at a distance, in amounts they can control. I call it the Goldilocks effect: not too close, not too far, just right. But what might feel just right for that middle-aged executive can be a problem for an adolescent who needs to develop face-to-face relationships. An 18-year-old boy who uses texting for almost everything says to me wistfully, \"Someday, someday, but certainly not now, I\\'d like to learn how to have a conversation.\" When I ask people \"What\\'s wrong with having a conversation?\" People say, \"I\\'ll tell you what\\'s wrong with having a conversation. It takes place in real time and you can\\'t control what you\\'re going to say.\" So that\\'s the bottom line. Texting, email, posting, all of these things let us present the self as we want to be. We get to edit, and that means we get to delete, and that means we get to retouch, the face, the voice, the flesh, the body -- not too little, not too much, just right. Human relationships are rich and they\\'re messy and they\\'re demanding. And we clean them up with technology. And when we do, one of the things that can happen is that we sacrifice conversation for mere connection. We short-change ourselves. And over time, we seem to forget this, or we seem to stop caring. I was caught off guard when Stephen Colbert asked me a profound question, a profound question. He said, \"Don\\'t all those little tweets, don\\'t all those little sips of online communication, add up to one big gulp of real conversation?\" My answer was no, they don\\'t add up. Connecting in sips may work for gathering discreet bits of information, they may work for saying, \"I\\'m thinking about you,\" or even for saying, \"I love you,\" -- I mean, look at how I felt when I got that text from my daughter -- but they don\\'t really work for learning about each other, for really coming to know and understand each other. And we use conversations with each other to learn how to have conversations with ourselves. So a flight from conversation can really matter because it can compromise our capacity for self-reflection. For kids growing up, that skill is the bedrock of development. Over and over I hear, \"I would rather text than talk.\" And what I\\'m seeing is that people get so used to being short-changed out of real conversation, so used to getting by with less, that they\\'ve become almost willing to dispense with people altogether. So for example, many people share with me this wish, that some day a more advanced version of Siri, the digital assistant on Apple\\'s iPhone, will be more like a best friend, someone who will listen when others won\\'t. I believe this wish reflects a painful truth that I\\'ve learned in the past 15 years. That feeling that no one is listening to me is very important in our relationships with technology. That\\'s why it\\'s so appealing to have a Facebook page or a Twitter feed -- so many automatic listeners. And the feeling that no one is listening to me make us want to spend time with machines that seem to care about us. We\\'re developing robots, they call them sociable robots, that are specifically designed to be companions -- to the elderly, to our children, to us. Have we so lost confidence that we will be there for each other? During my research I worked in nursing homes, and I brought in these sociable robots that were designed to give the elderly the feeling that they were understood. And one day I came in and a woman who had lost a child was talking to a robot in the shape of a baby seal. It seemed to be looking in her eyes. It seemed to be following the conversation. It comforted her. And many people found this amazing. But that woman was trying to make sense of her life with a machine that had no experience of the arc of a human life. That robot put on a great show. And we\\'re vulnerable. People experience pretend empathy as though it were the real thing. So during that moment when that woman was experiencing that pretend empathy, I was thinking, \"That robot can\\'t empathize. It doesn\\'t face death. It doesn\\'t know life.\" And as that woman took comfort in her robot companion, I didn\\'t find it amazing; I found it one of the most wrenching, complicated moments in my 15 years of work. But when I stepped back, I felt myself at the cold, hard center of a perfect storm. We expect more from technology and less from each other. And I ask myself, \"Why have things come to this?\" And I believe it\\'s because technology appeals to us most where we are most vulnerable. And we are vulnerable. We\\'re lonely, but we\\'re afraid of intimacy. And so from social networks to sociable robots, we\\'re designing technologies that will give us the illusion of companionship without the demands of friendship. We turn to technology to help us feel connected in ways we can comfortably control. But we\\'re not so comfortable. We are not so much in control. These days, those phones in our pockets are changing our minds and hearts because they offer us three gratifying fantasies. One, that we can put our attention wherever we want it to be; two, that we will always be heard; and three, that we will never have to be alone. And that third idea, that we will never have to be alone, is central to changing our psyches. Because the moment that people are alone, even for a few seconds, they become anxious, they panic, they fidget, they reach for a device. Just think of people at a checkout line or at a red light. Being alone feels like a problem that needs to be solved. And so people try to solve it by connecting. But here, connection is more like a symptom than a cure. It expresses, but it doesn\\'t solve, an underlying problem. But more than a symptom, constant connection is changing the way people think of themselves. It\\'s shaping a new way of being. The best way to describe it is, I share therefore I am. We use technology to define ourselves by sharing our thoughts and feelings even as we\\'re having them. So before it was: I have a feeling, I want to make a call. Now it\\'s: I want to have a feeling, I need to send a text. The problem with this new regime of \"I share therefore I am\" is that, if we don\\'t have connection, we don\\'t feel like ourselves. We almost don\\'t feel ourselves. So what do we do? We connect more and more. But in the process, we set ourselves up to be isolated. How do you get from connection to isolation? You end up isolated if you don\\'t cultivate the capacity for solitude, the ability to be separate, to gather yourself. Solitude is where you find yourself so that you can reach out to other people and form real attachments. When we don\\'t have the capacity for solitude, we turn to other people in order to feel less anxious or in order to feel alive. When this happens, we\\'re not able to appreciate who they are. It\\'s as though we\\'re using them as spare parts to support our fragile sense of self. We slip into thinking that always being connected is going to make us fell less alone. But we\\'re at risk, because actually it\\'s the opposite that\\'s true. If we\\'re not able to be alone, we\\'re going to be more lonely. And if we don\\'t teach our children to be alone, they\\'re only going to know When I spoke at TED in 1996, reporting on my studies of the early virtual communities, I said, \"Those who make the most of their lives on the screen come to it in a spirit of self-reflection.\" And that\\'s what I\\'m calling for here, now: reflection and, more than that, a conversation about where our current use of technology may be taking us, what it might be costing us. We\\'re smitten with technology. And we\\'re afraid, like young lovers, that too much talking might spoil the romance. But it\\'s time to talk. We grew up with digital technology and so we see it as all grown up. But it\\'s not, it\\'s early days. There\\'s plenty of time for us to reconsider how we use it, how we build it. I\\'m not suggesting that we turn away from our devices, just that we develop a more self-aware relationship with them, with each other and with ourselves. I see some first steps. Start thinking of solitude as a good thing. Make room for it. Find ways to demonstrate this as a value to your children. Create sacred spaces at home -- the kitchen, the dining room -- and reclaim them for conversation. Do the same thing at work. At work, we\\'re so busy communicating that we often don\\'t have time to think, we don\\'t have time to talk, about the things that really matter. Change that. Most important, we all really need to listen to each other, including to the boring bits. Because it\\'s when we stumble or hesitate or lose our words that we reveal ourselves to each other. Technology is making a bid to redefine human connection -- how we care for each other, how we care for ourselves -- but it\\'s also giving us the opportunity to affirm our values and our direction. I\\'m optimistic. We have everything we need to start. We have each other. And we have the greatest chance of success if we recognize our vulnerability. That we listen when technology says it will take something complicated and promises something simpler. So in my work, I hear that life is hard, relationships are filled with risk. And then there\\'s technology -- simpler, hopeful, optimistic, ever-young. It\\'s like calling in the cavalry. An ad campaign promises that online and with avatars, you can \"Finally, love your friends love your body, love your life, online and with avatars.\" We\\'re drawn to virtual romance, to computer games that seem like worlds, to the idea that robots, robots, will someday be our true companions. We spend an evening on the social network instead of going to the pub with friends. But our fantasies of substitution have cost us. Now we all need to focus on the many, many ways technology can lead us back to our real lives, our own bodies, our own communities, our own politics, our own planet. They need us. Let\\'s talk about how we can use digital technology, the technology of our dreams, to make this life the life we can love. Thank you.\\n', 'I got my start in writing and research as a surgical trainee, as someone who was a long ways away from becoming any kind of an expert at anything. So the natural question you ask then at that point is, how do I get good at what I\\'m trying to do? And it became a question of, how do we all get good at what we\\'re trying to do? It\\'s hard enough to learn to get the skills, try to learn all the material you have to absorb at any task you\\'re taking on. I had to think about how I sew and how I cut, but then also how I pick the right person to come to an operating room. And then in the midst of all this came this new context for thinking about what it meant to be good. In the last few years we realized we were in the deepest crisis of medicine\\'s existence due to something you don\\'t normally think about when you\\'re a doctor concerned with how you do good for people, which is the cost of health care. There\\'s not a country in the world that now is not asking whether we can afford what doctors do. The political fight that we\\'ve developed has become one around whether it\\'s the government that\\'s the problem or is it insurance companies that are the problem. And the answer is yes and no; it\\'s deeper than all of that. The cause of our troubles is actually the complexity that science has given us. And in order to understand this, I\\'m going to take you back a couple of generations. I want to take you back to a time when Lewis Thomas was writing in his book, \"The Youngest Science.\" Lewis Thomas was a physician-writer, one of my favorite writers. And he wrote this book to explain, among other things, what it was like to be a medical intern at the Boston City Hospital in the pre-penicillin year of 1937. It was a time when medicine was cheap and very ineffective. If you were in a hospital, he said, it was going to do you good only because it offered you some warmth, some food, shelter, and maybe the caring attention of a nurse. Doctors and medicine made no difference at all. That didn\\'t seem to prevent the doctors from being frantically busy in their days, as he explained. What they were trying to do was figure out whether you might have one of the diagnoses for which they could do something. And there were a few. You might have a lobar pneumonia, for example, and they could give you an antiserum, an injection of rabid antibodies to the bacterium streptococcus, if the intern sub-typed it correctly. If you had an acute congestive heart failure, they could bleed a pint of blood from you by opening up an arm vein, giving you a crude leaf preparation of digitalis and then giving you oxygen by tent. If you had early signs of paralysis and you were really good at asking personal questions, you might figure out that this paralysis someone has is from syphilis, in which case you could give this nice concoction of mercury and arsenic -- as long as you didn\\'t overdose them and kill them. Beyond these sorts of things, a medical doctor didn\\'t have a lot that they could do. This was when the core structure of medicine was created -- what it meant to be good at what we did and how we wanted to build medicine to be. It was at a time when what was known you could know, you could hold it all in your head, and you could do it all. If you had a prescription pad, if you had a nurse, if you had a hospital that would give you a place to convalesce, maybe some basic tools, you really could do it all. You set the fracture, you drew the blood, you spun the blood, looked at it under the microscope, you plated the culture, you injected the antiserum. This was a life as a craftsman. As a result, we built it around a culture and set of values that said what you were good at was being daring, at being courageous, at being independent and self-sufficient. Autonomy was our highest value. Go a couple generations forward to where we are, though, and it looks like a completely different world. We have now found treatments for nearly all of the tens of thousands of conditions that a human being can have. We can\\'t cure it all. We can\\'t guarantee that everybody will live a long and healthy life. But we can make it possible for most. But what does it take? Well, we\\'ve now discovered 4,000 medical and surgical procedures. We\\'ve discovered 6,000 drugs that I\\'m now licensed to prescribe. And we\\'re trying to deploy this capability, town by town, to every person alive -- in our own country, let alone around the world. And we\\'ve reached the point where we\\'ve realized, as doctors, we can\\'t know it all. We can\\'t do it all by ourselves. There was a study where they looked at how many clinicians it took to take care of you if you came into a hospital, as it changed over time. And in the year 1970, it took just over two full-time equivalents of clinicians. it took basically the nursing time and then just a little bit of time for a doctor who more or less checked in on you once a day. By the end of the 20th century, it had become more than 15 clinicians for the same typical hospital patient -- specialists, physical therapists, the nurses. We\\'re all specialists now, even the primary care physicians. Everyone just has a piece of the care. But holding onto that structure we built around the daring, independence, self-sufficiency of each of those people has become a disaster. We have trained, hired and rewarded people to be cowboys. But it\\'s pit crews that we need, pit crews for patients. There\\'s evidence all around us: 40 percent of our coronary artery disease patients in our communities receive incomplete or inappropriate care. 60 percent of our asthma, stroke patients receive incomplete or inappropriate care. Two million people come into hospitals and pick up an infection they didn\\'t have because someone failed to follow the basic practices of hygiene. Our experience as people who get sick, need help from other people, is that we have amazing clinicians that we can turn to -- hardworking, incredibly well-trained and very smart -- that we have access to incredible technologies that give us great hope, but little sense that it consistently all comes together for you from start to finish in a successful way. There\\'s another sign that we need pit crews, and that\\'s the unmanageable cost of our care. Now we in medicine, I think, are baffled by this question of cost. We want to say, \"This is just the way it is. This is just what medicine requires.\" When you go from a world where you treated arthritis with aspirin, that mostly didn\\'t do the job, to one where, if it gets bad enough, we can do a hip replacement, a knee replacement that gives you years, maybe decades, without disability, a dramatic change, well is it any surprise that that $40,000 hip replacement replacing the 10-cent aspirin is more expensive? It\\'s just the way it is. But I think we\\'re ignoring certain facts that tell us something about what we can do. As we\\'ve looked at the data about the results that have come as the complexity has increased, we found that the most expensive care is not necessarily the best care. And vice versa, the best care often turns out to be the least expensive -- has fewer complications, the people get more efficient at what they do. And what that means is there\\'s hope. Because [if] to have the best results, you really needed the most expensive care in the country, or in the world, well then we really would be talking about rationing who we\\'re going to cut off from Medicare. That would be really our only choice. But when we look at the positive deviants -- the ones who are getting the best results at the lowest costs -- we find the ones that look the most like systems are the most successful. That is to say, they found ways to get all of the different pieces, all of the different components, to come together into a whole. Having great components is not enough, and yet we\\'ve been obsessed in medicine with components. We want the best drugs, the best technologies, the best specialists, but we don\\'t think too much about how it all comes together. It\\'s a terrible design strategy actually. There\\'s a famous thought experiment that touches exactly on this that said, what if you built a car from the very best car parts? Well it would lead you to put in Porsche brakes, a Ferrari engine, a Volvo body, a BMW chassis. And you put it all together and what do you get? A very expensive pile of junk that does not go anywhere. And that is what medicine can feel like sometimes. It\\'s not a system. Now a system, however, when things start to come together, you realize it has certain skills for acting and looking that way. Skill number one is the ability to recognize success and the ability to recognize failure. When you are a specialist, you can\\'t see the end result very well. You have to become really interested in data, unsexy as that sounds. One of my colleagues is a surgeon in Cedar Rapids, Iowa, and he got interested in the question of, well how many CT scans did they do for their community in Cedar Rapids? He got interested in this because there had been government reports, newspaper reports, journal articles saying that there had been too many CT scans done. He didn\\'t see it in his own patients. And so he asked the question, \"How many did we do?\" and he wanted to get the data. It took him three months. No one had asked this question in his community before. And what he found was that, for the 300,000 people in their community, in the previous year they had done 52,000 CT scans. They had found a problem. Which brings us to skill number two a system has. Skill one, find where your failures are. Skill two is devise solutions. I got interested in this when the World Health Organization came to my team asking if we could help with a project to reduce deaths in surgery. The volume of surgery had spread around the world, but the safety of surgery had not. Now our usual tactics for tackling problems like these are to do more training, give people more specialization or bring in more technology. Well in surgery, you couldn\\'t have people who are more specialized and you couldn\\'t have people who are better trained. And yet we see unconscionable levels of death, disability that could be avoided. And so we looked at what other high-risk industries do. We looked at skyscraper construction, we looked at the aviation world, and we found that they have technology, they have training, and then they have one other thing: They have checklists. I did not expect to be spending a significant part of my time as a Harvard surgeon worrying about checklists. And yet, what we found were that these were tools to help make experts better. We got the lead safety engineer for Boeing to help us. Could we design a checklist for surgery? Not for the lowest people on the totem pole, but for the folks who were all the way around the chain, the entire team including the surgeons. And what they taught us was that designing a checklist to help people handle complexity actually involves more difficulty than I had understood. You have to think about things like pause points. You need to identify the moments in a process when you can actually catch a problem before it\\'s a danger and do something about it. You have to identify that this is a before-takeoff checklist. And then you need to focus on the killer items. An aviation checklist, like this one for a single-engine plane, isn\\'t a recipe for how to fly a plane, it\\'s a reminder of the key things that get forgotten or missed if they\\'re not checked. So we did this. We created a 19-item two-minute checklist for surgical teams. We had the pause points immediately before anesthesia is given, immediately before the knife hits the skin, immediately before the patient leaves the room. And we had a mix of dumb stuff on there -- making sure an antibiotic is given in the right time frame because that cuts the infection rate by half -- and then interesting stuff, because you can\\'t make a recipe for something as complicated as surgery. Instead, you can make a recipe for how to have a team that\\'s prepared for the unexpected. And we had items like making sure everyone in the room had introduced themselves by name at the start of the day, because you get half a dozen people or more who are sometimes coming together as a team for the very first time that day that you\\'re coming in. We implemented this checklist in eight hospitals around the world, deliberately in places from rural Tanzania to the University of Washington in Seattle. We found that after they adopted it the complication rates fell 35 percent. It fell in every hospital it went into. The death rates fell 47 percent. This was bigger than a drug. And that brings us to skill number three, the ability to implement this, to get colleagues across the entire chain to actually do these things. And it\\'s been slow to spread. This is not yet our norm in surgery -- let alone making checklists to go onto childbirth and other areas. There\\'s a deep resistance because using these tools forces us to confront that we\\'re not a system, forces us to behave with a different set of values. Just using a checklist requires you to embrace different values from the ones we\\'ve had, like humility, discipline, teamwork. This is the opposite of what we were built on: independence, self-sufficiency, autonomy. I met an actual cowboy, by the way. I asked him, what was it like to actually herd a thousand cattle across hundreds of miles? How did you do that? And he said, \"We have the cowboys stationed at distinct places all around.\" They communicate electronically constantly, and they have protocols and checklists for how they handle everything -- -- from bad weather to emergencies or inoculations for the cattle. Even the cowboys are pit crews now. And it seemed like time that we become that way ourselves. Making systems work is the great task of my generation of physicians and scientists. But I would go further and say that making systems work, whether in health care, education, climate change, making a pathway out of poverty, is the great task of our generation as a whole. In every field, knowledge has exploded, but it has brought complexity, it has brought specialization. And we\\'ve come to a place where we have no choice but to recognize, as individualistic as we want to be, complexity requires group success. We all need to be pit crews now. Thank you.\\n', 'People are living longer and societies are getting grayer. You hear about it all the time. You read about it in your newspapers. You hear about it on your television sets. Sometimes I\\'m concerned that we hear about it so much that we\\'ve come to accept longer lives with a kind of a complacency, even ease. But make no mistake, longer lives can and, I believe, will improve quality of life at all ages. Now to put this in perspective, let me just zoom out for a minute. More years were added to average life expectancy in the 20th century than all years added across all prior millennia of human evolution combined. In the blink of an eye, we nearly doubled the length of time that we\\'re living. So if you ever feel like you don\\'t have this aging thing quite pegged, don\\'t kick yourself. It\\'s brand new. And because fertility rates fell across that very same period that life expectancy was going up, that pyramid that has always represented the distribution of age in the population, with many young ones at the bottom winnowed to a tiny peak of older people who make it and survive to old age is being reshaped into a rectangle. And now, if you\\'re the kind of person who can get chills from population statistics, these are the ones that should do it. Because what that means is that for the first time in the history of the species, the majority of babies born in the Developed World are having the opportunity to grow old. How did this happen? Well we\\'re no genetically hardier than our ancestors were 10,000 years ago. This increase in life expectancy is the remarkable product of culture -- the crucible that holds science and technology and wide-scale changes in behavior that improve health and well-being. Through cultural changes, our ancestors largely eliminated early death so that people can now live out their full lives. Now there are problems associated with aging -- diseases, poverty, loss of social status. It\\'s hardly time to rest on our laurels. But the more we learn about aging, the clearer it becomes that a sweeping downward course is grossly inaccurate. Aging brings some rather remarkable improvements -- increased knowledge, expertise -- and emotional aspects of life improve. That\\'s right, older people are happy. They\\'re happier than middle-aged people, and younger people certainly. Study after study is coming to the same conclusion. The CDC recently conducted a survey where they asked respondents simply to tell them whether they experienced significant psychological distress in the previous week. And fewer older people answered affirmatively to that question than middle-aged people, and younger people as well. And a recent Gallup poll asked participants how much stress and worry and anger they had experienced the previous day. And stress, worry, anger all decrease with age. Now social scientists call this the paradox of aging. After all, aging is not a piece of cake. So we\\'ve asked all sorts of questions to see if we could undo this finding. We\\'ve asked whether it may be that the current generations of older people are and always have been the greatest generations. That is that younger people today may not typically experience these improvements as they grow older. We\\'ve asked, well maybe older people are just trying to put a positive spin on an otherwise depressing existence. But the more we\\'ve tried to disavow this finding, the more evidence we find to support it. Years ago, my colleagues and I embarked on a study where we followed the same group of people over a 10-year period. Originally the sample was aged 18 to 94. And we studied whether and how their emotional experiences changed as they grew older. Our participants would carry electronic pagers for a week at a time, and we\\'d page them throughout the day and evenings at random times. And every time we paged them we\\'d ask them to answer several questions -- On a one to seven scale, how happy are you right now? How sad are you right now? How frustrated are you right now? -- so that we could get a sense of the kinds of emotions and feelings they were having in their day-to-day lives. And using this intense study of individuals, we find that it\\'s not one particular generation that\\'s doing better than the others, but the same individuals over time come to report relatively greater positive experience. Now you see this slight downturn at very advanced ages. And there is a slight downturn. But at no point does it return to the levels we see in early adulthood. Now it\\'s really too simplistic to say that older people are \"happy.\" In our study, they are more positive, but they\\'re also more likely than younger people to experience mixed emotions -- sadness at the same time you experience happiness; you know, that tear in the eye when you\\'re smiling at a friend. And other research has shown that older people seem to engage with sadness more comfortably. They\\'re more accepting of sadness than younger people are. And we suspect that this may help to explain why older people are better than younger people at solving hotly-charged emotional conflicts and debates. Older people can view injustice with compassion, but not despair. And all things being equal, older people direct their cognitive resources, like attention and memory, to positive information more than negative. If we show older, middle-aged, younger people images, like the ones you see on the screen, and we later ask them to recall all the images that they can, older people, but not younger people, remember more positive images than negative images. We\\'ve asked older and younger people to view faces in laboratory studies, some frowning, some smiling. Older people look toward the smiling faces and away from the frowning, angry faces. In day-to-day life, this translates into greater enjoyment and satisfaction. But as social scientists, we continue to ask about possible alternatives. We\\'ve said, well maybe older people report more positive emotions because they\\'re cognitively impaired. We\\'ve said, could it be that positive emotions are simply easier to process than negative emotions, and so you switch to the positive emotions? Maybe our neural centers in our brain are degraded such that we\\'re unable to process negative emotions anymore. But that\\'s not the case. The most mentally sharp older adults are the ones who show this positivity effect the most. And under conditions where it really matters, older people do process the negative information just as well as the positive information. So how can this be? Well in our research, we\\'ve found that these changes are grounded fundamentally in the uniquely human ability to monitor time -- not just clock time and calendar time, but lifetime. And if there\\'s a paradox of aging, it\\'s that recognizing that we won\\'t live forever changes our perspective on life in positive ways. When time horizons are long and nebulous, as they typically are in youth, people are constantly preparing, trying to soak up all the information they possibly can, taking risks, exploring. We might spend time with people we don\\'t even like because it\\'s somehow interesting. We might learn something unexpected. We go on blind dates. You know, after all, if it doesn\\'t work out, there\\'s always tomorrow. People over 50 don\\'t go on blind dates. As we age, our time horizons grow shorter and our goals change. When we recognize that we don\\'t have all the time in the world, we see our priorities most clearly. We take less notice of trivial matters. We savor life. We\\'re more appreciative, more open to reconciliation. We invest in more emotionally important parts of life, and life gets better, so we\\'re happier day-to-day. But that same shift in perspective leads us to have less tolerance than ever for injustice. By 2015, there will be more people in the United States over the age of 60 than under 15. What will happen to societies that are top-heavy with older people? The numbers won\\'t determine the outcome. Culture will. If we invest in science and technology and find solutions for the real problems that older people face and we capitalize on the very real strengths of older people, then added years of life can dramatically improve quality of life at all ages. Societies with millions of talented, emotionally stable citizens who are healthier and better educated than any generations before them, armed with knowledge about the practical matters of life and motivated to solve the big issues can be better societies than we have ever known. My father, who is 92, likes to say, \"Let\\'s stop talking only about how to save the old folks and start talking about how to get them to save us all.\" Thank you.\\n', 'So I want to talk today about money and happiness, which are two things that a lot of us spend a lot of our time thinking about, either trying to earn them or trying to increase them. And a lot of us resonate with this phrase. So we see it in religions and self-help books, that money can\\'t buy happiness. And I want to suggest today that, in fact, that\\'s wrong. I\\'m at a business school, so that\\'s what we do. So that\\'s wrong, and, in fact, if you think that, you\\'re actually just not spending it right. So that instead of spending it the way you usually spend it, maybe if you spent it differently, that might work a little bit better. And before I tell you the ways that you can spend it that will make you happier, let\\'s think about the ways we usually spend it that don\\'t, in fact, make us happier. We had a little natural experiment. So CNN, a little while ago, wrote this interesting article on what happens to people when they win the lottery. It turns out people think when they win the lottery their lives are going to be amazing. This article\\'s about how their lives get ruined. So what happens when people win the lottery is, number one, they spend all the money and go into debt, and number two, all of their friends and everyone they\\'ve ever met find them and bug them for money. And it ruins their social relationships, in fact. So they have more debt and worse friendships than they had before they won the lottery. What was interesting about the article was people started commenting on the article, readers of the thing. And instead of talking about how it had made them realize that money doesn\\'t lead to happiness, everyone instantly started saying, \"You know what I would do if I won the lottery ... ?\" and fantasizing about what they\\'d do. And here\\'s just two of the ones we saw that are just really interesting to think about. One person wrote in, \"When I win, I\\'m going to buy my own little mountain and have a little house on top.\" And another person wrote, \"I would fill a big bathtub with money and get in the tub while smoking a big fat cigar and sipping a glass of champagne.\" This is even worse now: \"Then I\\'d have a picture taken and dozens of glossies made. Anyone begging for money or trying to extort from me would receive a copy of the picture and nothing else.\" And so many of the comments were exactly of this type, where people got money and, in fact, it made them antisocial. So I told you that it ruins people\\'s lives and that their friends bug them. It also, money often makes us feel very selfish and we do things only for ourselves. Well maybe the reason that money doesn\\'t make us happy is that we\\'re always spending it on the wrong things, and in particular, that we\\'re always spending it on ourselves. And we thought, I wonder what would happen if we made people spend more of their money on other people. So instead of being antisocial with your money, what if you were a little more prosocial with your money? And we thought, let\\'s make people do it and see what happens. So let\\'s have some people do what they usually do and spend money on themselves, and let\\'s make some people give money away, and measure their happiness and see if, in fact, they get happier. So the first way that we did this. On one Vancouver morning, we went out on the campus at University of British Columbia and we approached people and said, \"Do you want to be in an experiment?\" They said, \"Yes.\" We asked them how happy they were, and then we gave them an envelope. And one of the envelopes had things in it that said, \"By 5:00 pm today, spend this money on yourself.\" So we gave some examples of what you could spend it on. Other people, in the morning, got a slip of paper that said, \"By 5:00 pm today, spend this money on somebody else.\" Also inside the envelope was money. And we manipulated how much money we gave them. So some people got this slip of paper and five dollars. Some people got this slip of paper and 20 dollars. We let them go about their day. They did whatever they wanted to do. We found out that they did in fact spend it in the way that we asked them to. We called them up at night and asked them, \"What\\'d you spend it on, and how happy do you feel now?\" What did they spend it on? Well these are college undergrads, so a lot of what they spent it on for themselves were things like earrings and makeup. One woman said she bought a stuffed animal for her niece. People gave money to homeless people. Huge effect here of Starbucks. So if you give undergraduates five dollars, it looks like coffee to them and they run over to Starbucks and spend it as fast as they can. But some people bought a coffee for themselves, the way they usually would, but other people said that they bought a coffee for somebody else. So the very same purchase, just targeted toward yourself or targeted toward somebody else. What did we find when we called them back at the end of the day? People who spent money on other people got happier. People who spent money on themselves, nothing happened. It didn\\'t make them less happy, it just didn\\'t do much for them. And the other thing we saw is the amount of money doesn\\'t matter that much. So people thought that 20 dollars would be way better than five dollars. In fact, it doesn\\'t matter how much money you spent. What really matters is that you spent it on somebody else rather than on yourself. We see this again and again when we give people money to spend on other people instead of on themselves. Of course, these are undergraduates in Canada -- not the world\\'s most representative population. They\\'re also fairly wealthy and affluent and all these other sorts of things. We wanted to see if this holds true everywhere in the world or just among wealthy countries. So we went, in fact, to Uganda and ran a very similar experiment. So imagine, instead of just people in Canada, we said, \"Name the last time you spent money on yourself or other people. Describe it. How happy did it make you?\" Or in Uganda, \"Name the last time you spent money on yourself or other people and describe that.\" And then we asked them how happy they are again. And what we see is sort of amazing because there\\'s human universals on what you do with your money and then real cultural differences on what you do as well. So for example, one guy from Uganda says this. He said, \"I called a girl I wished to love.\" They basically went out on a date, and he says at the end that he didn\\'t \"achieve\" her up till now. Here\\'s a guy from Canada. Very similar thing. \"I took my girlfriend out for dinner. We went to a movie, we left early, and then went back to her room for ... \" only cake -- just a piece of cake. Human universal -- so you spend money on other people, you\\'re being nice to them. Maybe you have something in mind, maybe not. But then we see extraordinary differences. So look at these two. This is a woman from Canada. We say, \"Name a time you spent money on somebody else.\" She says, \"I bought a present for my mom. I drove to the mall in my car, bought a present, gave it to my mom.\" Perfectly nice thing to do. It\\'s good to get gifts for people that you know. Compare that to this woman from Uganda. \"I was walking and met a long-time friend whose son was sick with malaria. They had no money, they went to a clinic and I gave her this money.\" This isn\\'t $10,000, it\\'s the local currency. So it\\'s a very small amount of money, in fact. But enormously different motivations here. This is a real medical need, literally a life-saving donation. Above, it\\'s just kind of, I bought a gift for my mother. What we see again though is that the specific way that you spend on other people isn\\'t nearly as important as the fact that you spend on other people in order to make yourself happy, which is really quite important. So you don\\'t have to do amazing things with your money to make yourself happy. You can do small, trivial things and yet still get these benefits from doing this. These are only two countries. We also wanted to go even broader and look at every country in the world if we could to see what the relationship is between money and happiness. We got data from the Gallup Organization, which you know from all the political polls that have been happening lately. They ask people, \"Did you donate money to charity recently?\" and they ask them, \"How happy are you with your life in general?\" And we can see what the relationship is between those two things. Are they positively correlated? Giving money makes you happy. Or are they negatively correlated? On this map, green will mean they\\'re positively correlated and red means they\\'re negatively correlated. And you can see, the world is crazily green. So in almost every country in the world where we have this data, people who give money to charity are happier people that people who don\\'t give money to charity. I know you\\'re all looking at that red country in the middle. I would be a jerk and not tell you what it is, but in fact, it\\'s Central African Republic. You can make up stories. Maybe it\\'s different there for some reason or another. Just below that to the right is Rwanda though, which is amazingly green. So almost everywhere we look we see that giving money away makes you happier than keeping it for yourself. What about your work life, which is where we spend all the rest of our time when we\\'re not with the people we know. We decided to infiltrate some companies and do a very similar thing. So these are sales teams in Belgium. They work in teams; they go out and sell to doctors and try to get them to buy drugs. So we can look and see how well they sell things as a function of being a member of a team. Some teams, we give people on the team some money for themselves and say, \"Spend it however you want on yourself,\" just like we did with the undergrads in Canada. But other teams we say, \"Here\\'s 15 euro. Spend it on one of your teammates this week. Buy them something as a gift or a present and give it to them. And then we can see, well now we\\'ve got teams that spend on themselves and we\\'ve got these prosocial teams who we give money to make the team a little bit better. The reason I have a ridiculous pinata there is one of the teams pooled their money and bought a pinata, and they all got around and smashed the pinata and all the candy fell out and things like that. A very silly, trivial thing to do, but think of the difference on a team that didn\\'t do that at all, that got 15 euro, put it in their pocket, maybe bought themselves a coffee, or teams that had this prosocial experience where they all bonded together to buy something and do a group activity. What we see is that, in fact, the teams that are prosocial sell more stuff than the teams that only got money for themselves. And one way to think about it is for every 15 euro you give people for themselves, they put it in their pocket, they don\\'t do anything different than they did before. You don\\'t get any money from that. You actually lose money because it doesn\\'t motivate them to perform any better. But when you give them 15 euro to spend on their teammates, they do so much better on their teams that you actually get a huge win on investing this kind of money. And I realize that you\\'re probably thinking to yourselves, this is all fine, but there\\'s a context that\\'s incredibly important for public policy and I can\\'t imagine it would work there. And basically that if he doesn\\'t show me that it works here, I don\\'t believe anything he said. And I know what you\\'re all thinking about are dodgeball teams. This was a huge criticism that we got to say, if you can\\'t show it with dodgeball teams, this is all stupid. So we went out and found these dodgeball teams and infiltrated them. And we did the exact same thing as before. So some teams, we give people on the team money, they spend it on themselves. Other teams, we give them money to spend on their dodgeball teammates. The teams that spend money on themselves are just the same winning percentages as they were before. The teams that we give the money to spend on each other, they become different teams and, in fact, they dominate the league by the time they\\'re done. Across all of these different contexts -- your personal life, you work life, even silly things like intramural sports -- we see spending on other people has a bigger return for you than spending on yourself. And so I\\'ll just say, I think if you think money can\\'t buy happiness you\\'re not spending it right. The implication is not you should buy this product instead of that product and that\\'s the way to make yourself happier. It\\'s in fact, that you should stop thinking about which product to buy for yourself and try giving some of it to other people instead. And we luckily have an opportunity for you. DonorsChoose.org is a non-profit for mainly public school teachers in low-income schools. They post projects, so they say, \"I want to teach Huckleberry Finn to my class and we don\\'t have the books,\" or \"I want a microscope to teach my students science and we don\\'t have a microscope.\" You and I can go on and buy it for them. The teacher writes you a thank you note. The kids write you a thank you note. Sometimes they send you pictures of them using the microscope. It\\'s an extraordinary thing. Go to the website and start yourself on the process of thinking, again, less about \"How can I spend money on myself?\" and more about \"If I\\'ve got five dollars or 15 dollars, what can I do to benefit other people?\" Because ultimately when you do that, you\\'ll find that you\\'ll benefit yourself much more. Thank you.\\n', \"Have you ever wondered what is inside your dental plaque? Probably not, but people like me do. I'm an archeological geneticist at the Center for Evolutionary Medicine at the University of Zurich, and I study the origins and evolution of human health and disease by conducting genetic research on the skeletal and mummified remains of ancient humans. And through this work, I hope to better understand the evolutionary vulnerabilities of our bodies, so that we can improve and better manage our health in the future. There are different ways to approach evolutionary medicine, and one way is to extract human DNA from ancient bones. And from these extracts, we can reconstruct the human genome at different points in time and look for changes that might be related to adaptations, risk factors and inherited diseases. But this is only one half of the story. The most important health challenges today are not caused by simple mutations in our genome, but rather result from a complex and dynamic interplay between genetic variation, diet, microbes and parasites and our immune response. All of these diseases have a strong evolutionary component that directly relates to the fact that we live today in a very different environment than the ones in which our bodies evolved. And in order to understand these diseases, we need to move past studies of the human genome alone and towards a more holistic approach to human health in the past. But there are a lot of challenges for this. And first of all, what do we even study? Skeletons are ubiquitous; they're found all over the place. But of course, all of the soft tissue has decomposed, and the skeleton itself has limited health information. Mummies are a great source of information, except that they're really geographically limited and limited in time as well. Coprolites are fossilized human feces, and they're actually extremely interesting. You can learn a lot about ancient diet and intestinal disease, but they are very rare. So to address this problem, I put together a team of international researchers in Switzerland, Denmark and the U.K. to study a very poorly studied, little known material that's found on people everywhere. It's a type of fossilized dental plaque that is called officially dental calculus. Many of you may know it by the term tartar. It's what the dentist cleans off your teeth every time that you go in for a visit. And in a typical dentistry visit, you may have about 15 to 30 milligrams removed. But in ancient times before tooth brushing, up to 600 milligrams might have built up on the teeth over a lifetime. And what's really important about dental calculus is that it fossilizes just like the rest of the skeleton, it's abundant in quantity before the present day and it's ubiquitous worldwide. We find it in every population around the world at all time periods going back tens of thousands of years. And we even find it in neanderthals and animals. And so previous studies had only focused on microscopy. They'd looked at dental calculus under a microscope, and what they had found was things like pollen and plant starches, and they'd found muscle cells from animal meats and bacteria. And so what my team of researchers, what we wanted to do, is say, can we apply genetic and proteomic technology to go after DNA and proteins, and from this can we get better taxonomic resolution to really understand what's going on? And what we found is that we can find many commensal and pathogenic bacteria that inhabited the nasal passages and mouth. We also have found immune proteins related to infection and inflammation and proteins and DNA related to diet. But what was surprising to us, and also quite exciting, is we also found bacteria that normally inhabit upper respiratory systems. So it gives us virtual access to the lungs, which is where many important diseases reside. And we also found bacteria that normally inhabit the gut. And so we can also now virtually gain access to this even more distant organ system that, from the skeleton alone, has long decomposed. And so by applying ancient DNA sequencing and protein mass spectrometry technologies to ancient dental calculus, we can generate immense quantities of data that then we can use to begin to reconstruct a detailed picture of the dynamic interplay between diet, infection and immunity thousands of years ago. So what started out as an idea, is now being implemented to churn out millions of sequences that we can use to investigate the long-term evolutionary history of human health and disease, right down to the genetic code of individual pathogens. And from this information we can learn about how pathogens evolve and also why they continue to make us sick. And I hope I have convinced you of the value of dental calculus. And as a final parting thought, on behalf of future archeologists, I would like to ask you to please think twice before you go home and brush your teeth.\\n\"]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    text = text.replace('!', '.')\n",
        "    text = text.replace(':', ',')\n",
        "    text = text.replace('--', ',')\n",
        "    text = text.replace('-', ',')\n",
        "    text = text.replace(';', '.')\n",
        "    text = text.replace(' ,', ',')\n",
        "    text = text.replace('♫', '')\n",
        "    text = text.replace('...', '')\n",
        "\n",
        "    text = re.sub(r'--\\s?--', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    text = re.sub(r'\\s+\\?', '?', text)\n",
        "    text = re.sub(r'\\s+,', ',', text)\n",
        "    text = re.sub(r'\\.[\\s+\\.]+', '. ', text)\n",
        "    \n",
        "    text = re.sub(r',\\s?,', ',', text)\n",
        "    \n",
        "    return text.strip().lower()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    text = clean_text(text)\n",
        "    \n",
        "    text = text.replace('.', '')\n",
        "    text = text.replace(',', '')\n",
        "    text = text.replace('?', '')\n",
        "    \n",
        "    return text.lower()"
      ],
      "metadata": {
        "id": "D_St90fub8xL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_test = remove_punctuation(raw_text[0])\n",
        "print(test_test[:1000])\n",
        "print()\n",
        "print(raw_text[0][:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXqIQidxcQjZ",
        "outputId": "d9b8385c-14bf-4d22-819a-05820f014a1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you know cadaver dissection is the traditional way of learning human anatomy for students it's quite an experience but for a school it could be very difficult or expensive to maintain so we learned the majority of anatomic classes taught they do not have a cadaver dissection lab maybe those reasons or depending on where you are cadavers may not be easily available so to address this we developed with a dr brown in stanford virtual dissection table so we call this anatomage table so with this anatomage table students can experience the dissection without a human cadaver and the table form is important and since it's touchinteractive just like the way they do dissections in the lab or furthermore just the way a surgeon operates on a patient you can literally interact with your table our digital body is onetoone life size so this is exactly the way students will see the real anatomy i'm going to do some demonstrations as you can see i use my finger to interact with my digital body i'm goi\n",
            "\n",
            "You know, cadaver dissection is the traditional way of learning human anatomy. For students, it's quite an experience, but for a school, it could be very difficult or expensive to maintain. So we learned the majority of anatomic classes taught, they do not have a cadaver dissection lab. Maybe those reasons, or depending on where you are, cadavers may not be easily available. So to address this, we developed with a Dr. Brown in Stanford: virtual dissection table. So we call this Anatomage Table. So with this Anatomage Table, students can experience the dissection without a human cadaver. And the table form is important, and since it's touch-interactive, just like the way they do dissections in the lab, or furthermore just the way a surgeon operates on a patient you can literally interact with your table. Our digital body is one-to-one life size, so this is exactly the way students will see the real anatomy. I'm going to do some demonstrations. As you can see, I use my finger to interact\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QtQlbGcciv6",
        "outputId": "2c46e706-2d0c-4bd0-c081-652161cb1563"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 18.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ppAIv9cnUh",
        "outputId": "e9dd7a5d-1038-4454-86b3-17d8286b7f4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=a8127570acbe22835ce24a4f0d9744522862b0bc638c96e6f59d135ffdd434f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSAGDUTpeb_z",
        "outputId": "7c2b4bed-5c46-40f7-f6e5-a3b6974dc730"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neural_punctuator.models.BertPunctuator import BertPunctuator\n",
        "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')\n",
        "model = BertPunctuator(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBlFhUB9cXrB",
        "outputId": "dd3c36e0-ee7c-4276-8022-02424c62530b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')\n",
        "torch.cuda.set_device(device)"
      ],
      "metadata": {
        "id": "fNRe8ZDZicJS"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device);"
      ],
      "metadata": {
        "id": "4EVn-KxQikQB"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neural_punctuator.utils.io import load\n",
        "load(model, None, config)"
      ],
      "metadata": {
        "id": "S4IArkp9imQ_"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9JBLdPUzioXX",
        "outputId": "cba9bbe9-d4d8-47a9-e58d-4c67f8751ab8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer.encode(test_test, padding=True, pad_to_multiple_of=512)\n",
        "len(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFuSaAhvjnck",
        "outputId": "4c8136d7-cc80-445b-974e-50cbc30f37a1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(encoded).view(-1, 512).to(device)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0xrH8o5jqZH",
        "outputId": "42130219-1d58-4a67-8d35-de7850a7cbf5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnemm8lxo-eu",
        "outputId": "c79e1753-1de0-43e1-feec-d30c27268e09"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(x)\n"
      ],
      "metadata": {
        "id": "xkuaZo0sjrpk"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "wteD976gm4k8",
        "outputId": "4dda79f3-fd7f-4cb4-ee0a-42746ed03be8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-bf59575affe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "output = output.argmax(-1)[0].detach().cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "QX5zMoLTmCIL",
        "outputId": "ee949cff-ac6a-4f99-9fab-f2af602f36dc"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-94574586a419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'argmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0jseo_PyJm1",
        "outputId": "a22a7bc4-b989-4011-c5d0-134e7cb5edc9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1.2536, -1.3449, -1.4188, -1.5514],\n",
              "          [-1.5243, -1.1447, -1.2355, -1.7533],\n",
              "          [-1.3753, -1.4654, -1.2468, -1.4748],\n",
              "          ...,\n",
              "          [-1.4809, -1.2118, -1.2945, -1.6051],\n",
              "          [-1.4391, -1.3773, -1.2205, -1.5347],\n",
              "          [-1.3244, -1.3735, -1.3114, -1.5541]],\n",
              " \n",
              "         [[-1.2006, -1.3172, -1.6269, -1.4501],\n",
              "          [-1.2367, -1.4653, -1.3346, -1.5355],\n",
              "          [-1.4051, -1.4550, -1.1497, -1.5870],\n",
              "          ...,\n",
              "          [-1.4385, -1.4595, -1.4340, -1.2310],\n",
              "          [-1.3288, -1.4757, -1.4116, -1.3362],\n",
              "          [-1.3231, -1.3754, -1.4331, -1.4172]]], device='cuda:0',\n",
              "        grad_fn=<LogSoftmaxBackward0>), tensor([[[0.5228],\n",
              "          [0.5283],\n",
              "          [0.4878],\n",
              "          ...,\n",
              "          [0.5424],\n",
              "          [0.5856],\n",
              "          [0.5228]],\n",
              " \n",
              "         [[0.4838],\n",
              "          [0.5265],\n",
              "          [0.5156],\n",
              "          ...,\n",
              "          [0.5387],\n",
              "          [0.5054],\n",
              "          [0.5122]]], device='cuda:0', grad_fn=<SigmoidBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2target = {-1: 0,\n",
        "              9: 1, # .\n",
        "              60: 2, \n",
        "              15: 3,  # ,\n",
        "              -2: -1, # will be masked\n",
        "             }\n",
        "target2id = {value: key for key, value in id2target.items()}"
      ],
      "metadata": {
        "id": "a8RNuBh6mOdC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_output = []\n",
        "\n",
        "for token_id, target in zip(encoded, output):\n",
        "    generated_output.append(token_id)\n",
        "    \n",
        "    token = tokenizer._convert_id_to_token(token_id)\n",
        "    if token == '<pad>':\n",
        "        break\n",
        "    if target > 0:\n",
        "        target_id = target2id[target.item()]\n",
        "        target_token = tokenizer._convert_id_to_token(target_id)\n",
        "        \n",
        "        generated_output.append(target_id)\n",
        "    else:\n",
        "        target_token = \"\"\n",
        "    print(token, target_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "UsVao68DmP4J",
        "outputId": "1a14678d-86fb-452f-afb6-bf96a78b5ddc"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-55583e66d2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgenerated_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: zip argument #2 must support iteration"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(generated_output[1:])"
      ],
      "metadata": {
        "id": "yVge3uu7mW-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SCwGsvY5mXjP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}