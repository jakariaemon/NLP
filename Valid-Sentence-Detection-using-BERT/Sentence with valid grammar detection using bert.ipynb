{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Grammar-checker-bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb572125305449378fdf3e8e74e7fb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9c7bb107c154841ab9fca82e939740a",
              "IPY_MODEL_7f901616d3d94efda95aac415b3d9f02",
              "IPY_MODEL_d023b7928ae041d5b146637bdf436bd9"
            ],
            "layout": "IPY_MODEL_38cfcb2444cb4af2bf4a5b15acf10bcb"
          }
        },
        "f9c7bb107c154841ab9fca82e939740a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8cb176b1924ca5815c16c90f747e3d",
            "placeholder": "​",
            "style": "IPY_MODEL_d3720f48bebe492999d91a396b528b9f",
            "value": "Downloading: 100%"
          }
        },
        "7f901616d3d94efda95aac415b3d9f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a741897e644015bdbb74f0fa2d2aeb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84c7be003c6e4c2d858467ba2c473426",
            "value": 231508
          }
        },
        "d023b7928ae041d5b146637bdf436bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db686be8f014e209b6889a313b6ba24",
            "placeholder": "​",
            "style": "IPY_MODEL_01263c0535044da6a1f9d93ad702aa75",
            "value": " 232k/232k [00:00&lt;00:00, 2.41MB/s]"
          }
        },
        "38cfcb2444cb4af2bf4a5b15acf10bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8cb176b1924ca5815c16c90f747e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3720f48bebe492999d91a396b528b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01a741897e644015bdbb74f0fa2d2aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c7be003c6e4c2d858467ba2c473426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0db686be8f014e209b6889a313b6ba24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01263c0535044da6a1f9d93ad702aa75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27c733d7f2cf4273896b1cffeab35526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe1e31a2340c4bb99e6e5dbfb6dba83a",
              "IPY_MODEL_40ecc9d558da41b49fce5972e26033ac",
              "IPY_MODEL_f93bdb59c8f04724a91342af8601aa49"
            ],
            "layout": "IPY_MODEL_5c0a401a394c4329bc9bc931fa6c9a9c"
          }
        },
        "fe1e31a2340c4bb99e6e5dbfb6dba83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b45d8d9d2d44ba96b75f7b5a4d07fc",
            "placeholder": "​",
            "style": "IPY_MODEL_a185e99325874ad4a4647d3f692a0a73",
            "value": "Downloading: 100%"
          }
        },
        "40ecc9d558da41b49fce5972e26033ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acd457378fe04f39b70c9bde2a99dda2",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d061c27fa1426bbd9b049b1dee73bc",
            "value": 433
          }
        },
        "f93bdb59c8f04724a91342af8601aa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73490ac2fcb646f1bca6428c7f0be928",
            "placeholder": "​",
            "style": "IPY_MODEL_a0b50548f9e848aab2835ace07825e9d",
            "value": " 433/433 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "5c0a401a394c4329bc9bc931fa6c9a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b45d8d9d2d44ba96b75f7b5a4d07fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a185e99325874ad4a4647d3f692a0a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acd457378fe04f39b70c9bde2a99dda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d061c27fa1426bbd9b049b1dee73bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73490ac2fcb646f1bca6428c7f0be928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b50548f9e848aab2835ace07825e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92dcf277af694c77bdc480de61178fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5d2e0764f2047deab5f77e83192a340",
              "IPY_MODEL_f1468baf1a9542bfaaf24c498d398b34",
              "IPY_MODEL_8bf6b652414c46e9a887bba529f368c8"
            ],
            "layout": "IPY_MODEL_28830653cbda475da81a7210738d75c7"
          }
        },
        "c5d2e0764f2047deab5f77e83192a340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1262d4db934402ea9ff4353224662fb",
            "placeholder": "​",
            "style": "IPY_MODEL_a0f3d720088347589379aa19b4d7675f",
            "value": "Downloading: 100%"
          }
        },
        "f1468baf1a9542bfaaf24c498d398b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5eedd13d154a919b9861ca0c997e58",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_186abcdabaf64d62aa2355ea39504880",
            "value": 440473133
          }
        },
        "8bf6b652414c46e9a887bba529f368c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8404b42fc54d67b58d1ed46774bd77",
            "placeholder": "​",
            "style": "IPY_MODEL_3008ad59f71743a78961d3b61d5b16fc",
            "value": " 440M/440M [00:07&lt;00:00, 60.9MB/s]"
          }
        },
        "28830653cbda475da81a7210738d75c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1262d4db934402ea9ff4353224662fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0f3d720088347589379aa19b4d7675f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec5eedd13d154a919b9861ca0c997e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186abcdabaf64d62aa2355ea39504880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee8404b42fc54d67b58d1ed46774bd77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3008ad59f71743a78961d3b61d5b16fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Grammar-checker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## Using Colab for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "outputId": "5faf4042-b471-4b16-d68f-f7abb80a350b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "outputId": "645b1d4b-8000-4e05-dab1-97fb0729b923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "outputId": "8d2bc1c3-a572-4352-f0ed-134d6119dc5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Downloading the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk"
      },
      "source": [
        "We'll use [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect. It was first published in May of 2018, and is one of the tests included in the \"GLUE Benchmark\" on which models like BERT are competing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNVW6xd0T0X"
      },
      "source": [
        "We'll use the `wget` package to download the dataset to the Colab instance's file system. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "outputId": "929dc5cf-0efb-4f55-bd63-9b1cc51c4f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=bd3bacddbab81e335121043b4c2871dcccdc79a2437ed7f41e71b5b079419b8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI"
      },
      "source": [
        "The dataset is hosted on GitHub in this repo: https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "outputId": "516e5591-ed02-471e-cb27-76aa613240bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mKctx-ll2FB"
      },
      "source": [
        "Unzip the dataset to the file system. You can browse the file system of the Colab instance in the sidebar on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "##  Parsing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "outputId": "41263507-58bd-4182-f073-211fccf0c429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "5952            c_13      1         NaN   \n",
              "5423            b_73      1         NaN   \n",
              "5682            c_13      1         NaN   \n",
              "1919            r-67      0           *   \n",
              "3850            ks08      1         NaN   \n",
              "4656            ks08      1         NaN   \n",
              "5117            ks08      1         NaN   \n",
              "3239            l-93      0           *   \n",
              "6275            c_13      1         NaN   \n",
              "5243            kl93      0           *   \n",
              "\n",
              "                                               sentence  \n",
              "5952                     I ordered John drink his beer.  \n",
              "5423           We made enough pudding to last for days.  \n",
              "5682  We keep those censored copies of the book hidd...  \n",
              "1919  The only girl who it bothers me to wear that o...  \n",
              "3850    That they have completed the course is amazing.  \n",
              "4656                He is reputed to be a good scholar.  \n",
              "5117      What we are using is their teaching material.  \n",
              "3239                  Tony broke the wall with the cup.  \n",
              "6275  Alan told me who wanted to seem to be invincible.  \n",
              "5243  It isn't because Sue said anything bad about m...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7d1afed-23d1-40a6-ae6a-1677fb0d2301\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5952</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I ordered John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5423</th>\n",
              "      <td>b_73</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We made enough pudding to last for days.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5682</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We keep those censored copies of the book hidd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1919</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>The only girl who it bothers me to wear that o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3850</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That they have completed the course is amazing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4656</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>He is reputed to be a good scholar.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5117</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What we are using is their teaching material.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3239</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Tony broke the wall with the cup.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6275</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan told me who wanted to seem to be invincible.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5243</th>\n",
              "      <td>kl93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>It isn't because Sue said anything bad about m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7d1afed-23d1-40a6-ae6a-1677fb0d2301')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7d1afed-23d1-40a6-ae6a-1677fb0d2301 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7d1afed-23d1-40a6-ae6a-1677fb0d2301');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzpPi92UAH"
      },
      "source": [
        "The two properties we actually care about are the the `sentence` and its `label`, which is referred to as the \"weather it is grammatically correct or not\" (0=unacceptable, 1=acceptable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "outputId": "0a2fa59c-3af7-40ea-9112-ae363c6d4c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bb572125305449378fdf3e8e74e7fb9f",
            "f9c7bb107c154841ab9fca82e939740a",
            "7f901616d3d94efda95aac415b3d9f02",
            "d023b7928ae041d5b146637bdf436bd9",
            "38cfcb2444cb4af2bf4a5b15acf10bcb",
            "2c8cb176b1924ca5815c16c90f747e3d",
            "d3720f48bebe492999d91a396b528b9f",
            "01a741897e644015bdbb74f0fa2d2aeb",
            "84c7be003c6e4c2d858467ba2c473426",
            "0db686be8f014e209b6889a313b6ba24",
            "01263c0535044da6a1f9d93ad702aa75"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb572125305449378fdf3e8e74e7fb9f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "outputId": "9237426f-ade4-40cc-c035-29e4c0bb8410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "outputId": "a1ecdbd5-2524-4bcf-d8e2-7c5a40d9c457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "outputId": "3b9a25c1-5f13-4a5b-a0ec-f7b5f0d74006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "## Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjzRT1V0zwm"
      },
      "source": [
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "outputId": "220e9b81-d875-4e1c-9fb2-d84ecb01877b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "27c733d7f2cf4273896b1cffeab35526",
            "fe1e31a2340c4bb99e6e5dbfb6dba83a",
            "40ecc9d558da41b49fce5972e26033ac",
            "f93bdb59c8f04724a91342af8601aa49",
            "5c0a401a394c4329bc9bc931fa6c9a9c",
            "00b45d8d9d2d44ba96b75f7b5a4d07fc",
            "a185e99325874ad4a4647d3f692a0a73",
            "acd457378fe04f39b70c9bde2a99dda2",
            "a6d061c27fa1426bbd9b049b1dee73bc",
            "73490ac2fcb646f1bca6428c7f0be928",
            "a0b50548f9e848aab2835ace07825e9d",
            "92dcf277af694c77bdc480de61178fcb",
            "c5d2e0764f2047deab5f77e83192a340",
            "f1468baf1a9542bfaaf24c498d398b34",
            "8bf6b652414c46e9a887bba529f368c8",
            "28830653cbda475da81a7210738d75c7",
            "c1262d4db934402ea9ff4353224662fb",
            "a0f3d720088347589379aa19b4d7675f",
            "ec5eedd13d154a919b9861ca0c997e58",
            "186abcdabaf64d62aa2355ea39504880",
            "ee8404b42fc54d67b58d1ed46774bd77",
            "3008ad59f71743a78961d3b61d5b16fc"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27c733d7f2cf4273896b1cffeab35526"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92dcf277af694c77bdc480de61178fcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers~=2.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "hiEwTN05hnNc",
        "outputId": "f6c046a5-9ac2-463f-e64c-73df1d2e7a1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers~=2.11.0\n",
            "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
            "\u001b[K     |████████████████████████████████| 674 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers~=2.11.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers~=2.11.0) (1.21.6)\n",
            "Collecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=2.11.0) (3.7.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=2.11.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers~=2.11.0) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers~=2.11.0) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers~=2.11.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=2.11.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=2.11.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=2.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=2.11.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=2.11.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=2.11.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=2.11.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=10629f087d4d694a7cf40af6d92016a7736e9c2f440b09d96b18caea02b328e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.21.0\n",
            "    Uninstalling transformers-4.21.0:\n",
            "      Successfully uninstalled transformers-4.21.0\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.7.0 transformers-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "outputId": "539b72fc-e8a7-4e66-fd43-870cd56fe335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## Training our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "outputId": "176f55ef-998c-43af-86ec-5b9a95c9036e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:26.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:39.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:06.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:26.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:39.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:06.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:19.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:26.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:40.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:06.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:40.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:06.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:19.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:31 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "outputId": "84e5d0b6-f258-4739-8887-d3f73e1fc146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.51         0.46           0.82       0:01:20         0:00:03\n",
              "2               0.33         0.43           0.82       0:01:20         0:00:03\n",
              "3               0.22         0.47           0.83       0:01:20         0:00:03\n",
              "4               0.15         0.59           0.83       0:01:20         0:00:03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-872580e0-ad02-483f-9850-bd59a6319a15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.22</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-872580e0-ad02-483f-9850-bd59a6319a15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-872580e0-ad02-483f-9850-bd59a6319a15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-872580e0-ad02-483f-9850-bd59a6319a15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n",
        "\n",
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "outputId": "c39d6eda-753d-466a-de09-7e8ea8f2253c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "## Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "outputId": "79becac1-10ea-400e-830d-02d572373d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "##  Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "outputId": "f4fd593f-56d5-4301-cd78-e7ac5451f299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "outputId": "548ae81b-09d0-4c3c-f5b9-5bf61720d1dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "outputId": "a320aab1-5675-4fde-c032-b0f7b2c71e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUM0UA1qJaVB"
      },
      "source": [
        "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches. \n",
        "\n",
        "Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "outputId": "5e4f9772-013d-4ebd-a3aa-a79b49c681ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "outputId": "51ee20fc-eefe-4ef0-e6ae-89fc79500c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "##  Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "outputId": "b0872b8c-c9bf-474b-e753-eb2ea3a9ec50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ"
      },
      "source": [
        "The following functions will load the model back from disk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPZp77CiNCDj"
      },
      "source": [
        "## Import the saved model and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqLQT5i-C7V-"
      },
      "source": [
        "\n",
        "\n",
        "For running on our local machine(even CPU), we can just import the saved model and play with it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDoyjyA79C9h",
        "outputId": "40dd8315-1ce4-45bc-a162-8de961c3bd88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "output_dir = '/content/model_save'\n",
        "\n",
        "print(output_dir)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model_save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWkQ6THnj5RB",
        "outputId": "ba747dea-b5e0-4c46-d974-af484817af3d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMJA-vA5yXhb",
        "outputId": "5392d0ab-8df7-4925-9318-dbe6b7409d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvmqzSRvnQGh"
      },
      "source": [
        "# Let's check it for a given sentence\n",
        "sent = \"you doing good work\"\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "input_id = encoded_dict['input_ids']\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "attention_mask = encoded_dict['attention_mask']\n",
        "input_id = torch.LongTensor(input_id)\n",
        "attention_mask = torch.LongTensor(attention_mask)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhF1-RCUt_vw"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_loaded = model_loaded.to(device)\n",
        "input_id = input_id.to(device)\n",
        "attention_mask = attention_mask.to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c1trzncpdlr",
        "outputId": "bbfb3658-8f8c-4cf5-cf43-a4e0b36ce942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "logits = outputs[0]\n",
        "index = logits.argmax()\n",
        "if index == 1:\n",
        "  print(\"Gramatically correct\")\n",
        "else:\n",
        "  print(\"Gramatically in-correct\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gramatically in-correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glE2YWqzzVn9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}